keyword,git_name,owner_name,git_url,star_count,forks_count,contributor_count,contributors_list,code_language,last_updated_date,readme_url,readme_text
Responsible+AI,microsoft/responsible-ai-toolbox,microsoft,https://api.github.com/repos/microsoft/responsible-ai-toolbox,756,201,30,"['https://api.github.com/users/imatiach-msft', 'https://api.github.com/users/gaugup', 'https://api.github.com/users/xuke444', 'https://api.github.com/users/zhb000', 'https://api.github.com/users/romanlutz', 'https://api.github.com/users/vinuthakaranth', 'https://api.github.com/users/tongyu-microsoft', 'https://api.github.com/users/gregorybchris', 'https://api.github.com/users/dependabot%5Bbot%5D', 'https://api.github.com/users/RubyZ10', 'https://api.github.com/users/riedgar-ms', 'https://api.github.com/users/csigs', 'https://api.github.com/users/rihorn2', 'https://api.github.com/users/ms-kashyap', 'https://api.github.com/users/mesameki', 'https://api.github.com/users/jamesbchao', 'https://api.github.com/users/ilmarinen', 'https://api.github.com/users/microsoftopensource', 'https://api.github.com/users/JarvisG495', 'https://api.github.com/users/Advitya17', 'https://api.github.com/users/janjagusch', 'https://api.github.com/users/LeJit', 'https://api.github.com/users/yongjiaaaa', 'https://api.github.com/users/hawestra', 'https://api.github.com/users/natalie-isak', 'https://api.github.com/users/alexquach', 'https://api.github.com/users/aminadibi', 'https://api.github.com/users/zhb789', 'https://api.github.com/users/jlema', 'https://api.github.com/users/michaelamoako']",TypeScript,2023-04-09T11:04:16Z,https://raw.githubusercontent.com/microsoft/responsible-ai-toolbox/main/README.md,"['![MIT license](https://img.shields.io/badge/License-MIT-blue.svg)\n', '\n', '![Responsible AI Widgets Python Build](https://img.shields.io/github/actions/workflow/status/microsoft/responsible-ai-toolbox/CI-raiwidgets-pytest.yml?branch=main&label=Responsible%20AI%20Widgets%20Python%20Build)\n', '![UI deployment to test environment](https://img.shields.io/github/actions/workflow/status/microsoft/responsible-ai-toolbox/CD.yml?branch=main&label=UI%20deployment%20to%20test%20environment)\n', '\n', '![PyPI raiwidgets](https://img.shields.io/pypi/v/raiwidgets?label=PyPI%20raiwidgets)\n', '![PyPI responsibleai](https://img.shields.io/pypi/v/responsibleai?label=PyPI%20responsibleai)\n', '![PyPI erroranalysis](https://img.shields.io/pypi/v/erroranalysis?label=PyPI%20erroranalysis)\n', '![PyPI raiutils](https://img.shields.io/pypi/v/raiutils?label=PyPI%20raiutils)\n', '![PyPI rai_test_utils](https://img.shields.io/pypi/v/rai_test_utils?label=PyPI%20rai_test_utils)\n', '\n', '![npm model-assessment](https://img.shields.io/npm/v/@responsible-ai/model-assessment?label=npm%20%40responsible-ai%2Fmodel-assessment)\n', '\n', '# Responsible AI Toolbox\n', 'Responsible AI is an approach to assessing, developing, and deploying AI systems in a safe, trustworthy, and ethical manner, and take responsible decisions and actions.\n', '\n', 'Responsible AI Toolbox is a suite of tools providing a collection of model and data exploration and assessment user interfaces and libraries that enable a better understanding of AI systems. These interfaces and libraries empower developers and stakeholders of AI systems to develop and monitor AI more responsibly, and take better data-driven actions.\n', '\n', '\n', '<p align=""center"">\n', '<img src=""https://raw.githubusercontent.com/microsoft/responsible-ai-widgets/main/img/responsible-ai-toolbox.png"" alt=""ResponsibleAIToolboxOverview"" width=""750""/>\n', '\n', '\n', 'The Toolbox consists of three repositories: \n', '\n', '\xa0\n', '| Repository| Tools Covered  |\n', '|--|--|\n', '| [Responsible-AI-Toolbox Repository](https://github.com/microsoft/responsible-ai-toolbox) (Here) |This repository contains four visualization widgets for model assessment and decision making:<br>1. [Responsible AI dashboard](https://github.com/microsoft/responsible-ai-toolbox#introducing-responsible-ai-dashboard), a single pane of glass bringing together several mature Responsible AI tools from the toolbox for a holistic responsible assessment and debugging of models and making informed business decisions. With this dashboard, you can identify model errors, diagnose why those errors are happening, and mitigate them. Moreover, the causal decision-making capabilities provide actionable insights to your stakeholders and customers.<br>2. [Error Analysis dashboard](https://github.com/microsoft/responsible-ai-toolbox/blob/main/docs/erroranalysis-dashboard-README.md), for identifying model errors and discovering cohorts of data for which the model underperforms. \t<br>3. [Interpretability dashboard](https://github.com/microsoft/responsible-ai-toolbox/blob/main/docs/explanation-dashboard-README.md), for understanding model predictions. This dashboard is powered by InterpretML.<br>4. [Fairness dashboard](https://github.com/microsoft/responsible-ai-toolbox/blob/main/docs/fairness-dashboard-README.md), for understanding model’s fairness issues using various group-fairness metrics across sensitive features and cohorts. This dashboard is powered by Fairlearn. \n', '| [Responsible-AI-Toolbox-Mitigations Repository](https://github.com/microsoft/responsible-ai-toolbox-mitigations) | The Responsible AI Mitigations Library helps AI practitioners explore different measurements and mitigation steps that may be most appropriate when the model underperforms for a given data cohort. The library currently has two modules: <br>1. DataProcessing, which offers mitigation techniques for improving model performance for specific cohorts. <br>2. DataBalanceAnalysis, which provides metrics for diagnosing errors that originate from data imbalance either on class labels or feature values. <br> 3. Cohort: provides classes for handling and managing cohorts, which allows the creation of custom pipelines for each cohort in an easy and intuitive interface. The module also provides techniques for learning different decoupled estimators (models) for different cohorts and combining them in a way that optimizes different definitions of group fairness.|  \n', '[Responsible-AI-Tracker Repository](https://github.com/microsoft/responsible-ai-toolbox-tracker) |Responsible AI Toolbox Tracker is a JupyterLab extension for managing, tracking, and comparing results of machine learning experiments for model improvement. Using this extension, users can view models, code, and visualization artifacts within the same framework enabling therefore fast model iteration and evaluation processes. Main functionalities include: <br>1. Managing and linking model improvement artifacts<br> 2. Disaggregated model evaluation and comparisons<br>3. Integration with the Responsible AI Mitigations library<br>4. Integration with mlflow|\n', ' [Responsible-AI-Toolbox-GenBit Repository](https://github.com/microsoft/responsible-ai-toolbox-genbit) | The Responsible AI Gender Bias (GenBit) Library helps AI practitioners measure gender bias in Natural Language Processing (NLP) datasets. The main goal of GenBit is to analyze your text corpora and compute metrics that give insights into the gender bias present in a corpus.|\n', '\n', '  \n', '\n', '\n', '## Introducing Responsible AI dashboard\n', '\n', '[Responsible AI dashboard](https://github.com/microsoft/responsible-ai-toolbox/blob/main/notebooks/responsibleaidashboard/tour.ipynb) is a single pane of glass, enabling you to easily flow through different stages of model debugging and decision-making. This customizable experience can be taken in a multitude of directions, from analyzing the model or data holistically, to conducting a deep dive or comparison on cohorts of interest, to explaining and perturbing model predictions for individual instances, and to informing users on business decisions and actions.\n', '\n', '\n', '<p align=""center"">\n', '<img src=""https://raw.githubusercontent.com/microsoft/responsible-ai-widgets/main/img/responsible-ai-dashboard.png"" alt=""ResponsibleAIDashboard"" width=""750""/>\n', '\n', '\n', '\n', '\n', 'In order to achieve these capabilities, the dashboard integrates together ideas and technologies from several open-source toolkits in the areas of\n', '\n', '\n', '\n', '- <b>Error Analysis</b> powered by [Error Analysis](https://github.com/microsoft/responsible-ai-widgets/blob/main/docs/erroranalysis-dashboard-README.md), which identifies cohorts of data with higher error rate than the overall benchmark. These discrepancies might occur when the system or model underperforms for specific demographic groups or infrequently observed input conditions in the training data.\n', '- <b>Fairness Assessment</b> powered by [Fairlearn](https://github.com/fairlearn/fairlearn), which identifies which groups of people may be disproportionately negatively impacted by an AI system and in what ways.\n', '\n', ""- <b>Model Interpretability</b> powered by [InterpretML](https://github.com/interpretml/interpret-community), which explains blackbox models, helping users understand their model's global behavior, or the reasons behind individual predictions.\n"", '\n', ""- <b>Counterfactual Analysis</b> powered by [DiCE](https://github.com/interpretml/DiCE), which shows feature-perturbed versions of the same datapoint who would have received a different prediction outcome, e.g., Taylor's loan has been rejected by the model. But they would have received the loan if their income was higher by $10,000.\n"", '\n', '- <b>Causal Analysis</b> powered by [EconML](https://github.com/microsoft/EconML), which focuses on answering What If-style questions to apply data-driven decision-making – how would revenue be affected if a corporation pursues a new pricing strategy? Would a new medication improve a patient’s condition, all else equal?\n', '\n', '- <b>Data Balance</b> powered by [Responsible AI](https://github.com/microsoft/responsible-ai-toolbox/blob/main/docs/databalance-README.md), which helps users gain an overall understanding of their data, identify features receiving the positive outcome more than others, and visualize feature distributions.\n', '\n', 'Responsible AI dashboard is designed to achieve the following goals:\n', '\n', '- To help further accelerate engineering processes in machine learning by enabling practitioners to design customizable workflows and tailor Responsible AI dashboards that best fit with their model assessment and data-driven decision making scenarios.\n', '- To help model developers create end to end and fluid debugging experiences and navigate seamlessly through error identification and diagnosis by using interactive visualizations that identify errors, inspect the data, generate global and local explanations models, and potentially inspect problematic examples.\n', '- To help business stakeholders explore causal relationships in the data and take informed decisions in the real world.\n', '\n', 'This repository contains the Jupyter notebooks with examples to showcase how to use this widget. Get started [here](https://github.com/microsoft/responsible-ai-toolbox/blob/main/notebooks/responsibleaidashboard/getting-started.ipynb).\n', '\n', '\n', '### Installation\n', '\n', 'Use the following pip command to install the Responsible AI Toolbox.\n', '\n', 'If running in jupyter, please make sure to restart the jupyter kernel after installing.\n', '\n', '```\n', 'pip install raiwidgets\n', '```\n', '\n', '\n', '### Responsible AI dashboard Customization\n', '\n', 'The Responsible AI Toolbox’s strength lies in its customizability. It empowers users to design tailored, end-to-end model debugging and decision-making workflows that address their particular needs. Need some inspiration? Here are some examples of how Toolbox components can be put together to analyze scenarios in different ways:\n', '\n', 'Please note that model overview (including fairness analysis) and data explorer components are activated by default!\n', '\xa0\n', '| Responsible AI Dashboard Flow| Use Case  |\n', '|--|--|\n', '| Model Overview -> Error Analysis -> Data Explorer | To identify model errors and diagnose them by understanding the underlying data distribution\n', '| Model Overview -> Fairness Assessment -> Data Explorer | To identify model fairness issues and diagnose them by understanding the underlying data distribution\n', '| Model Overview -> Error Analysis -> Counterfactuals Analysis and What-If | To diagnose errors in individual instances with counterfactual analysis (minimum change to lead to a different model prediction)\n', '| Model Overview -> Data Explorer -> Data Balance | To understand the root cause of errors and fairness issues introduced via data imbalances or lack of representation of a particular data cohort\n', ' | Model Overview -> Interpretability | To diagnose model errors through understanding how the model has made its predictions\n', ' | Data Explorer -> Causal Inference | To distinguish between correlations and causations in the data or decide the best treatments to apply to see a positive outcome\n', '  | Interpretability -> Causal Inference | To learn whether the factors that model has used for decision making has any causal effect on the real-world outcome.\n', ' | Data Explorer -> Counterfactuals Analysis and What-If | To address customer questions about what they can do next time to get a different outcome from an AI.\n', '  | Data Explorer -> Data Balance | To gain an overall understanding of the data, identify features receiving the positive outcome more than others, and visualize feature distributions\n', '\n', '\n', '### Useful Links\n', '\n', '- [Take a tour of Responsible AI Dashboard](https://github.com/microsoft/responsible-ai-toolbox/blob/main/notebooks/responsibleaidashboard/tour.ipynb)\n', '- [Get started](https://github.com/microsoft/responsible-ai-toolbox/blob/main/notebooks/responsibleaidashboard/getting-started.ipynb)\n', '\n', 'Model Debugging Examples:\n', '- [Try the tool: model debugging of a census income prediction model (classification)](https://github.com/microsoft/responsible-ai-toolbox/tree/main/notebooks/responsibleaidashboard/responsibleaidashboard-census-classification-model-debugging.ipynb)\n', '- [Try the tool: model debugging of a housing price prediction model (classification)](https://github.com/microsoft/responsible-ai-toolbox/tree/main/notebooks/responsibleaidashboard/responsibleaidashboard-housing-classification-model-debugging.ipynb)\n', '- [Try the tool: model debugging of a diabetes progression prediction model (regression)](https://github.com/microsoft/responsible-ai-toolbox/tree/main/notebooks/responsibleaidashboard/responsibleaidashboard-diabetes-regression-model-debugging.ipynb)\n', '\n', ' Responsible Decision Making Examples:\n', '- [Try the tool: make decisions for house improvements](https://github.com/microsoft/responsible-ai-toolbox/tree/main/notebooks/responsibleaidashboard/responsibleaidashboard-housing-decision-making.ipynb)\n', '- [Try the tool: provide recommendations to patients using diabetes data](https://github.com/microsoft/responsible-ai-toolbox/tree/main/notebooks/responsibleaidashboard/responsibleaidashboard-diabetes-decision-making.ipynb)\n', '\n', '\n', '\n', '## Supported Models\n', '\n', 'This Responsible AI Toolbox API supports models that are trained on datasets in Python `numpy.ndarray`, `pandas.DataFrame`, `iml.datatypes.DenseData`, or `scipy.sparse.csr_matrix` format.\n', '\n', ""The explanation functions of [Interpret-Community](https://github.com/interpretml/interpret-community) accept both models and pipelines as input as long as the model or pipeline implements a `predict` or `predict_proba` function that conforms to the Scikit convention. If not compatible, you can wrap your model's prediction function into a wrapper function that transforms the output into the format that is supported (predict or predict_proba of Scikit), and pass that wrapper function to your selected interpretability techniques.\n"", '\n', 'If a pipeline script is provided, the explanation function assumes that the running pipeline script returns a prediction. The repository also supports models trained via **PyTorch**, **TensorFlow**, and **Keras** deep learning frameworks.\n', '\n', '## Other Use Cases\n', '\n', 'Tools within the Responsible AI Toolbox can also be used with AI models offered as APIs by providers such as [Azure Cognitive Services](https://azure.microsoft.com/en-us/services/cognitive-services/). To see example use cases, see the folders below:\n', '\n', '- [Cognitive Services Speech to Text Fairness testing](https://github.com/microsoft/responsible-ai-toolbox/tree/main/notebooks/cognitive-services-examples/speech-to-text)\n', '- [Cognitive Services Face Verification Fairness testing](https://github.com/microsoft/responsible-ai-toolbox/tree/main/notebooks/cognitive-services-examples/face-verification)\n', '\n', '## Maintainers\n', '\n', '- [Ke Xu](https://github.com/KeXu444)\n', '- [Roman Lutz](https://github.com/romanlutz)\n', '- [Ilya Matiach](https://github.com/imatiach-msft)\n', '- [Gaurav Gupta](https://github.com/gaugup)\n', '- [Vinutha Karanth](https://github.com/vinuthakaranth)\n', '- [Tong Yu](https://github.com/tongyu-microsoft)\n', '- [Ruby Zhu](https://github.com/RubyZ10)\n', '- [Mehrnoosh Sameki](https://github.com/mesameki)\n']"
Responsible+AI,alexandrainst/responsible-ai,alexandrainst,https://api.github.com/repos/alexandrainst/responsible-ai,57,14,6,"['https://api.github.com/users/nkasenburg', 'https://api.github.com/users/AmaliePauli', 'https://api.github.com/users/KrydenZ', 'https://api.github.com/users/kasperbaynoer', 'https://api.github.com/users/KatrineHJ', 'https://api.github.com/users/agnethe-gron']",,2023-04-04T16:30:50Z,https://raw.githubusercontent.com/alexandrainst/responsible-ai/main/README.md,"['# Responsible AI Knowledge-base\n', '\n', 'This repository is a knowledge-base of different areas of using and developing AI in a responsible way:heart:. Responsible AI includes both the field of explainable and interpretable machine learning, fairness and bias in machine learning, law regulations as well as the aspect of user experience and human centralized AI.  Hence, it is a cross-disciplinary field which includes both the field of computer science and social science. The aim is to achieve systems that are trustworthy, accountable and fair. Therefore, responsible AI should hopefully both interest researchers and practitioners, which includes both developers, system owners/buyers and users :family:.\n', '\n', 'This repo is a collection of links to **research papers, blog post, tools, tutorials, videos and books**. The references are divide into different areas as listed in the table of contents.\n', '\n', '#### Table of contents :open_file_folder:\n', '\n', '|        | | |\n', '| ------------- |:-------------:| -----:|\n', '| [Explainable AI](#explainable-ai)      | [Fairness](#fairness) | [Guidelines & principles](#guide-princip)\n', '| [People & Tech](#people-tech)  | [Policy & Regulation](#pol-reg)      | [User Experience](#ux) |\n', '\n', '<a name=""explainable-ai""></a>\n', '\n', '  ####  Contributions  :raising_hand:\n', '\n', 'We really welcome and appreciates :pray:contributions to make sure this knowledge-base stays relevant. So if you have a link or reference you think should be included then pleas create a pull request. You can also open an issue if you find it easier.\n', '\n', '\n', '\n', '#### Who is behind :construction_worker:\n', '\n', 'The Responsible AI repository is maintained by the [Alexandra Institute](https://alexandra.dk/uk) which is a Danish non-profit company with a mission to create value, growth and welfare in society. The Alexandra Institute is a member of [GTS](https://gts-net.dk/), a network of independent Danish research and technology organisations.\n', '\n', 'The initial work on this repository is conducted under a performance contract allocated to the Alexandra Insitute by the [Danish Ministry of Higher Education and Science](https://ufm.dk/en?set_language=en&cl=en). The project ran in the two years in 2019 and 2020.``\n', '\n', '\n', '\n', '# Explainable AI (XAI)\n', '## Frameworks and Github repos\n', '1. [InterpretML](https://interpret.ml/) - Open source Python framework that combines local and global explanation methods,\n', 'as well as, transparent models, like decision trees, rule based models, and GAMs (Generalized Additive Models), into\n', 'a common API and dashboard.\n', '2. [AI Explainability 360](http://aix360.mybluemix.net/) - Open source Python XAI framework devloped by IBM researchers\n', 'combining different data, local and global explanation methods. Also see there [github page](https://github.com/Trusted-AI/AIX360).\n', '3. [explainX.ai](https://github.com/explainX/explainx) - Open source Python framework that launches an\n', 'interactive dashboard for a model in a single line of code in which a model can be investigated using\n', 'different XAI methods.\n', '4. [Alibi Explain](https://github.com/SeldonIO/alibi) - Open source Pyton XAI framework combining different methods.\n', 'Main focus on counterfactual explanations and SHAP for classification tasks on tabular data or images.\n', '5. [SHAP](https://github.com/slundberg/shap) - THe open source Python framework for generating SHAP explanations. Focused\n', 'on tree based models, but contains the model agnostic KernelSHAP and an implementation for deep neural networks.\n', '6. [Lucid](https://github.com/tensorflow/lucid) - Open source Python framework to explain deep convolutional\n', 'neural networks used on image data (currently only supports Tensforflow 1). Focuses on understanding the\n', 'representations the network has learned.\n', '7. [DeepLIFT](https://github.com/kundajelab/deeplift) - Open source implementation of the DeepLIFT methods for generating\n', 'local feature attributions for deep neural networks.\n', '8. [iNNvestigate](https://github.com/albermax/innvestigate) - Github repository collecting implementations of different\n', 'feature attribution and gradient based explanation methods for deep neural networks.\n', '9. [Skope-rules](https://github.com/scikit-learn-contrib/skope-rules) - Open source Python framework for building rule\n', 'based models.\n', '10. [Yellowbrick](https://www.scikit-yb.org/en/latest/) - Open source Python framework to create different visualizations\n', 'of data and ML models.\n', '11. [Captum](https://captum.ai/) - Open source framework to explain deep learning models created with PyTorch. Includes\n', 'many known XAI algorithms for deep neural networks.\n', '12. [What-If Tool](https://pair-code.github.io/what-if-tool/) - Open source framework from Google to probe the behaviour\n', 'of a trained model.\n', '13. [AllenNLP Interpret](https://allennlp.org/interpret) - Python framework for explaining deep neural networks\n', 'for language processing developed by the Allen Institute for AI.\n', '14. [Dalex](http://dalex.drwhy.ai/) - Part of the DrWhy.AI universe of packages for interpretable and responsible ML.\n', '15. [RuleFit](https://github.com/christophM/rulefit) - Open source python implementation of an interpretable rule ensemble model.\n', '16. [SkopeRules](https://github.com/scikit-learn-contrib/skope-rules) - Open source python package for fitting a rule based model.\n', '17. [ELI5](https://eli5.readthedocs.io/en/latest/index.html) - Open source python package that implements LIME local explanations\n', '    and permutation explanations.\n', '18. [tf-explain](https://github.com/sicara/tf-explain) - Open source framework that implements interpretability methods as Tensorflow 2.x callbacks. Includes\n', 'several known XAI algorithms for deep neural networks.\n', '19. [PAIR - Saliency methods](https://github.com/PAIR-code/saliency) - Framework that collects different gradient based, saliency methods for deep learning model for Tensorflow created by the Google People+AI Research (PAIR) Initiative.\n', '20. [Quantus](https://github.com/understandable-machine-intelligence-lab/quantus) - Toolkit to evaluate XAI methods for neural networks.\n', '21. [Xplique](https://github.com/deel-ai/xplique) - Python library that gathers state of the art of XAI methods for deep neural networks (currently for Tensorflow).\n', '22. [PiML](https://github.com/SelfExplainML/PiML-Toolbox) - Python toolbox for developing interpretable models through low-code interfaces and high-code APIs.\n', '23. [VL-InterpreT](https://github.com/IntelLabs/VL-InterpreT) - Python toolbox for interactive visualizations of the attentions and hidden representations in vision-language transformers (**Note:** currently only link to the paper and live demo available, but no code)\n', '\n', '## Reading material\n', '1. [Ansvarlig AI](https://medium.com/ansvarlig-ai) - Cross-disciplinary medium blog about XAI,\n', 'fairness and responsible AI (in Danish)\n', '2. [Introducing the Model Card Toolkit](https://ai.googleblog.com/2020/07/introducing-model-card-toolkit-for.html) -\n', 'Google blogpost about the Model Card Toolkit that is a framework for reporting about a ML model.\n', '3. [Interpreting Decision Trees and Random Forests](https://engineering.pivotal.io/post/interpreting-decision-trees-and-random-forests/) -\n', 'Blog post about how to interpret and visualize tree based models.\n', '4. [Introducing PDPbox](https://towardsdatascience.com/introducing-pdpbox-2aa820afd312) - Blog post about a python\n', 'package for generating partial dependence plots.\n', '5. [Use SHAP loss values to debug/monitor your model](https://towardsdatascience.com/use-shap-loss-values-to-debug-monitor-your-model-83f7808af40f) -\n', ' Blog post about how to use SHAP explanations to debug and monitoring.\n', '6. [Be careful what you SHAP for…](https://medium.com/@pauldossantos/be-careful-what-you-shap-for-aeccabf3655c) - Blog\n', ' post about the assumption for how and when to use SHAP explanations.\n', '7. [Awesome Interpretable Machine Learning](https://github.com/lopusz/awesome-interpretable-machine-learning) - Collection\n', ' of resources (articles, conferences, frameworks, software, etc.) about interpretable ML.\n', '8. [http://heatmapping.org/](http://heatmapping.org/) - Homepage of the lab behind the LRP (layerwise propagation relevance)\n', ' method with links to tutorials and research articles.\n', '9. [Interpretable Machine Learning](https://christophm.github.io/interpretable-ml-book/) - E-book by Christoph Molnar\n', 'describing and explaining different XAI methods and ways to build intepretable models or methods to interpret them, including\n', 'examples on open available datasets.\n', '10. [Can A.I. Be Taught to Explain Itself?](https://www.nytimes.com/2017/11/21/magazine/can-ai-be-taught-to-explain-itself.html) -\n', 'The New York Times Magazine article about the need of explainable models.\n', '11. [Deconstructing BERT, Part 2: Visualizing the Inner Workings of Attention](https://towardsdatascience.com/deconstructing-bert-part-2-visualizing-the-inner-workings-of-attention-60a16d86b5c1) -\n', 'Blog post about how to interprete a BERT model.\n', '12. [AI Explanations Whitepaper](https://storage.googleapis.com/cloud-ai-whitepapers/AI%20Explainability%20Whitepaper.pdf) -\n', ""Google's whitepaper about Explainable AI.\n"", '13. [Robust-and-Explainable-machine-learning](https://github.com/dongyp13/Robust-and-Explainable-Machine-Learning) -\n', '    Collection of links and articles with respect to robust and explainable machine learning,\n', '    containing mostly deep learning related resources.\n', '14. [Explaining the decisions of XGBoost models using counterfactual examples](https://towardsdatascience.com/explaining-the-decisions-of-xgboost-models-using-counterfactual-examples-fd9c57c83062) - Blog post describing an algorithm of how to compute counterfactual explanations for decision tree ensemble models.\n', '15. [Interpretable K-Means: Clusters Feature Importances](https://towardsdatascience.com/interpretable-k-means-clusters-feature-importances-7e516eeb8d3c) - Blog post describing methods to compute feature importance for K-means clustering, i.e. which feature mostly contributes for a datapoint belonging to a cluster.\n', '16. [Explainable Graph Neural Networks](https://towardsdatascience.com/explainable-graph-neural-networks-cb009c2bc8ea) - Blog post that provides a brief overview of XAI methods for graph neural networks (GNNs).\n', '\n', '## Videos and presentations\n', '1. [ICML 2019 session - Robust statistics and interpretability](https://slideslive.com/38917641/robust-statistics-and-interpretability)\n', '\n', '## Courses\n', '1. [Kaggle - Machine Learning Explainability](https://www.kaggle.com/learn/machine-learning-explainability) -\n', 'Kaggle course about the basics of XAI with example notebooks and exercises.\n', '\n', '## Research articles\n', 'In this section we list research articles related to interpretable ML and explainable AI.\n', '\n', '### Definitions of interpretability\n', '1. A. Weller, ""Transparency: Motivations and Challenges"", [arXiv:1708.01870](https://arxiv.org/abs/1708.01870)\n', '[cs.CY]\n', '2. J. Chang et al., ""[Reading Tea Leaves: How Humans Interpret Topic Models](http://papers.neurips.cc/paper/3700-reading-tea-leaves-how-humans-interpret-topic-models.pdf)"",\n', 'NIPS 2009\n', '3. Z. C. Lipton, ""The Mythos of Model Interpretability"", [arXiv:1606.03490](https://arxiv.org/abs/1606.03490)\n', '[cs.LG]\n', '4. F. Doshi-Velez and B. Kim, ""Towards A Rigorous Science of Interpretable Machine Learning"",\n', '[arXiv:1702.08608](https://arxiv.org/abs/1702.08608) [stat.ML]\n', '\n', '### Review, survey and overview papers\n', '1. G. Vilone and L. Longo, ""Explainable Artificial Intelligence: a Systematic Review"",\n', '[arXiv:2006.00093](https://arxiv.org/abs/2006.00093) [cs.AI]\n', '2. U. Bhatt et al., ""[Explainable Machine Learning in Deployment](https://dl.acm.org/doi/abs/10.1145/3351095.3375624)"",\n', 'FAT*20 648-657, 2020 - Survey about how XAI is used in practice.  The key results are:\n', '    1. XAI methods are mainly used by ML engineers / designers for debugging.\n', '    2. Limitations of the methods are often unclear to those using it.\n', '    3. The goal og why XAI is used in the first place is often unclear or not well defined, which could potentially lead to using the wrong method.\n', '3. L. H. Gilpin, ""[Explaining Explanations: An Overview of Interpretability of Machine Learning](https://doi.org/10.1109/DSAA.2018.00018)"",\n', 'IEEE 5th DSAA 80-89, 2019\n', '4. S. T. Mueller,\n', '""Explanation in Human-AI Systems: A Literature Meta-Review, Synopsis of Key Ideas and Publications, and Bibliography for Explainable AI"",\n', '[arXiv:1902.01876](https://arxiv.org/abs/1902.01876) [cs.AI]\n', '5. R. Guidotti et al., ""[A Survey of Methods for Explaining Black Box Models](https://dl.acm.org/doi/abs/10.1145/3236009)"",\n', 'ACM Computing Surveys, 2018 - Overview of different interpretability methods grouping them after type of method,\n', 'model they explain and type of explanation.\n', '6. M. Du et al., ""[Techniques for interpretable machine learning](https://dl.acm.org/doi/10.1145/3359786)"",\n', 'Communications of the ACM, 2019\n', '7. I. C. Covert et al., Explaining by Removing:A Unified Framework for Model Explanation,\n', '[arXiv:2011.14878](https://arxiv.org/abs/2011.14878) [cs.LG] -\n', '(Mathematical) framework that summarizes 25 feature influence methods.\n', '8. A. Adadi and M. Berrada, ""[Peeking Inside the Black-Box: A Survey on Explainable Artificial Intelligence (XAI)](https://doi.org/10.1109/ACCESS.2018.2870052)"",\n', 'IEEE Access (6) 52138-52160, 2018\n', '9. A. Abdul et al.,\n', '""[Trends and Trajectories for Explainable, Accountable and Intelligible Systems: An HCI Research Agenda](https://dl.acm.org/doi/10.1145/3173574.3174156)"",\n', ""CHI'18 582 1-18, 2018\n"", '10. A. Preece, ""[Asking ‘Why’ in AI: Explainability of intelligent systems – perspectives and challenges](https://onlinelibrary.wiley.com/doi/abs/10.1002/isaf.1422)"",\n', 'Intell Sys Acc Fin Mgmt (25) 63-72, 2018\n', '11. Q. Zhang and S.-C. Zhu,\n', '    ""[Visual Interpretability for Deep Learning: a Survey](https://link.springer.com/article/10.1631/FITEE.1700808)"",\n', '    Technol. Electronic Eng. (19) 27–39, 2018\n', '12. B. Mittelstadt et al.,\n', '    ""[Explaining Explanations in AI](https://dl.acm.org/doi/10.1145/3287560.3287574)"",\n', ""    FAT*'19 279–288, 2019\n"", '13. T. Rojat et al., ""Explainable Artificial Intelligence (XAI) on TimeSeries Data: A Survey"",\n', '    [arXiv:2104.00950](https://arxiv.org/abs/2104.00950) [cs.LG] - Survey paper about XAI methods for models predicting on time series data. \n', '\n', '### Evaluation of XAI\n', 'This section contains articles that describe ways to evaluate explanations and explainable models.\n', '1. S. Mohseni et al., ""A Human-Grounded Evaluation Benchmark for Local Explanations of Machine Learning"",\n', '[arXiv:1801.05075](https://arxiv.org/abs/1801.05075) [cs.HC]\n', '2. J. Huysmans et al.,\n', '""[An empirical evaluation of the comprehensibility of decision table, tree and rule based predictive models](https://www.sciencedirect.com/science/article/abs/pii/S0167923610002368)"",\n', 'Decision Support Systems (51:1) 141-154, 2011\n', '3. F. Poursabzi-Sangdeh et al., ""Manipulating and Measuring Model Interpretability"",\n', '[arXiv:1802.07810](https://arxiv.org/abs/1802.07810) [cs.AI]\n', '4. C. J. Cai et al.,\n', '""[The Effects of Example-Based Explanations in a Machine Learning Interface](https://dl.acm.org/doi/abs/10.1145/3301275.3302289)"",\n', "" IUI'19 258-262, 2019\n"", '5. L. Sixt et al., ""When Explanations Lie: Why Many Modified BP Attributions Fail"",\n', '[arXiv:1912.09818](https://arxiv.org/abs/1912.09818) [cs.LG]\n', '6. Y. Zhang et al.,\n', '""[Effect of confidence and explanation on accuracy and trust calibration in AI-assisted decision making](https://dl.acm.org/doi/abs/10.1145/3351095.3372852)"",\n', ""FAT*'20 295-305, 2020 - Analyses the effect of LIME explanation and confidence score as explanation on trust and human decision performance.\n"", '7. K. Sokol and P. Flach,\n', '""[Explainability fact sheets: a framework for systematic assessment of explainable approaches](https://dl.acm.org/doi/abs/10.1145/3351095.3372870)"",\n', ""FAT*'20 56-67, 2020 - Framework (essentially a list of questions or checklist) to evaluate and document XAI methods.\n"", 'Also includes question that are relevant to the context in which the XAI methods should be employed, i.e. changing the outcome of the assessment based on the context.\n', '8. E. S. Jo and T. Gebru,\n', '""[Lessons from archives: strategies for collecting sociocultural data in machine learning](https://dl.acm.org/doi/abs/10.1145/3351095.3372829)"",\n', ""FAT*'20 306-316, 2020 - Use archives as inspiration of how to collect, curate and annotate data.\n"", '9. J. Adebayo et al., ""Sanity Checks for Saliency Maps"", [arXiv:1810.03292](https://arxiv.org/abs/1810.03292) [cs.CV] - Comparing different saliency map XAI methods for their sensitivity to the input image and weights of the network.\n', '10. H. Kaur et al.,\n', '""[Interpreting Interpretability: Understanding Data Scientists’ Use of Interpretability Tools for Machine Learning](https://dl.acm.org/doi/fullHtml/10.1145/3313831.3376219)"",\n', ""CHI'20 1-14, 2020\n"", '11. P. Hase and M. Bansal, ""Evaluating Explainable AI: Which Algorithmic Explanations Help Users Predict Model Behavior?"", [arXiv:2005.01831](https://arxiv.org/abs/2005.01831) [cs.CL]\n', '12. J. V. Jeyakumar et al.,\n', '    ""[How Can I Explain This to You? An Empirical Study of Deep Neural Network Explanation Methods](https://proceedings.neurips.cc/paper/2020/hash/2c29d89cc56cdb191c60db2f0bae796b-Abstract.html)"",\n', '    33rd NeurIPS, 2020 - The authors evaluate different methods for explaining deep neural networks for end-user preference. Code can be found on [github](https://github.com/nesl/Explainability-Study),\n', '    as well as, their [implementation of an example based explainer](https://github.com/nesl/ExMatchina).\n', '13. S. Jesus et al.,\n', '    ""How can I choose an explainer? An Application-grounded Evaluation of Post-hoc Explanations"", [arXiv:2101.08758](https://arxiv.org/abs/2101.08758) [cs.AI] - Evaluating XAI methods based on an application-grounded approach measuring decision time and accuracy of end-users.\n', '14. M. Nauta et al.,\n', '    ""From Anecdotal Evidence to Quantitative Evaluation Methods: A Systematic Review on Evaluating Explainable AI"", [arXiv:2201.08164](https://arxiv.org/abs/2201.08164) [cs.AI] - Lietrature survey of XAI methods and how they where evaluated in the presented paper.\n', '\n', '### Method to explain data\n', 'This section contains articles that explain datasets, for example by finding representative examples.\n', '1. B. Kim et al.,\n', '   ""[Examples are not Enough, Learn to Criticize! Criticism for Interpretability](https://papers.nips.cc/paper/2016/hash/5680522b8e2bb01943234bce7bf84534-Abstract.html)"",\n', '   NIPS, 2016 - Code can we found on [github](https://github.com/BeenKim/MMD-critic).\n', '\n', '### Explainable models\n', 'This section contains articles that describe models that are explainable or transparent by design.\n', '1. X. Zhang et al.,\n', '   ""[Axiomatic Interpretability for Multiclass Additive Models](https://dl.acm.org/doi/abs/10.1145/3292500.3330898)"",\n', ""   KDD'19 226–234, 2019\n"", '2. T. Kulesza et al.,\n', '   ""[Principles of Explanatory Debugging to Personalize Interactive Machine Learning](https://dl.acm.org/doi/10.1145/2678025.2701399)"",\n', ""   IUI'15 126–137, 2015 - Framework showing how a Naive Bayes method can be trained with user interaction and\n"", '   how to generate explanations for these kinds of models.\n', '3. M. Hind et al.,\n', '   ""[TED: Teaching AI to Explain its Decisions](https://dl.acm.org/doi/abs/10.1145/3306618.3314273)"",\n', ""   AIES'19 123–129, 2019\n"", '4. Y. Lou et al.,\n', '   ""[Accurate Intelligible Models with Pairwise Interactions](https://dl.acm.org/doi/10.1145/2487575.2487579)"",\n', ""   KDD'13 623–631, 2013\n"", '5. C. Chen et al., ""An Interpretable Model with Globally Consistent Explanations for Credit Risk"",\n', '   [arXiv:1811.12615](https://arxiv.org/abs/1811.12615) [cs.LG]\n', '6. C. Chen and C. Rudin,\n', '   ""[An Optimization Approach to Learning Falling Rule Lists](http://proceedings.mlr.press/v84/chen18a.html)"",\n', '   PMLR (84) 604-612, 2018\n', '7. F. Wang and C. Rudin,  ""Falling Rule Lists"",\n', '   [arXiv:1411.5899](https://arxiv.org/abs/1411.5899) [cs.AI]\n', '8. B. Ustun and C. Rudin, ""Supersparse Linear Integer Models for Optimized Medical Scoring Systems"",\n', '   [arXiv:1502.04269](https://arxiv.org/abs/1502.04269) [stat.ML]\n', '8. E. Angelino et al.,\n', '   ""[Learning Certifiably Optimal Rule Lists for Categorical Data](https://dl.acm.org/doi/abs/10.5555/3122009.3290419)"",\n', '   JMLR (18:234) 1-78, 2018\n', '9. H. Lakkaraju et al.,\n', '   ""[Interpretable Decision Sets: A Joint Framework for Description and Prediction](https://dl.acm.org/doi/10.1145/2939672.2939874)"",\n', ""   KDD'16 1675–1684, 2016\n"", '10. K. Shu et al.,\n', '      ""[dEFEND: Explainable Fake News Detection](https://dl.acm.org/doi/10.1145/3292500.3330935)"",\n', ""      KDD'19 395–405, 2019\n"", '11. J. Jung et al., ""Simple Rules for Complex Decisions"",\n', '    [arXiv:1702.04690](https://arxiv.org/abs/1702.04690) [stat.AP]\n', '\n', '### XAI methods to visualize / explain a model\n', 'This section contains articles that are describing methods to globally explain a model.\n', 'Typically, this is done by generating visualizations in one form or the other.\n', '1. B. Ustun et al.,\n', '   ""[Actionable Recourse in Linear Classification](https://dl.acm.org/doi/10.1145/3287560.3287566)"",\n', ""   FAT*'19 Pages 10–19, 2019 - Article describing a method to evaluate actionable variables,\n"", '   i.e. variables a person can impact to change the outcome af a model, of a linear\n', '   classification model.\n', '2. A Datta et al.,\n', '   ""[Algorithmic Transparency via Quantitative Input Influence: Theory and Experiments with Learning Systems](https://ieeexplore.ieee.org/document/7546525)"",\n', '    IEEE SP 598-617, 2016\n', '3. P.Adler et al.,\n', '   ""[Auditing black-box models for indirect influence](https://link.springer.com/article/10.1007/s10115-017-1116-3)"",\n', '   Knowl. Inf. Syst. (54) 95–122, 2018\n', '4. A. Lucic et al.,\n', '   ""[Why Does My Model Fail? Contrastive Local Explanations for Retail Forecasting](https://dl.acm.org/doi/abs/10.1145/3351095.3372824)"",\n', ""   FAT*'20 90–98, 2020 - Presents an explanation to explain failure cases of an ML/AI model.\n"", '   The explanation is presented in form of a feasible range of feature values in which the model works and a trend\n', '   for each feature. Code for the method is available on [github](https://github.com/a-lucic/mc-brp).\n', '5. J. Krause et al.,\n', '   ""[Interacting with Predictions: Visual Inspection of Black-box Machine Learning Models](https://dl.acm.org/doi/10.1145/2858036.2858529)"",\n', ""   CHI'16 5686–5697, 2016\n"", '6. B. Kim et al.,\n', '   ""[Interpretability Beyond Feature Attribution: Quantitative Testing with Concept Activation Vectors (TCAV)](http://proceedings.mlr.press/v80/kim18d.html)"",\n', '   ICML, PMLR (80) 2668-2677, 2018 - Code for the method can be found on [github](https://github.com/tensorflow/tcav).\n', '7. A. Goldstein et al.,\n', '   ""[Peeking Inside the Black Box: Visualizing Statistical Learning with Plots of Individual Conditional Expectation](https://doi.org/10.1080/10618600.2014.907095)"",\n', '   Journal of Computational and Graphical Statistics (24:1) 44-65, 2015\n', '8. J. Wang et al., ""Shapley Flow: A Graph-based Approach to Interpreting Model Predictions"",\n', '   [arXiv:2010.14592](https://arxiv.org/abs/2010.14592) [cs.LG]\n', '\n', '### XAI methods that explain a model through construction of mimicking models\n', 'This section contains articles that are describing methods to explain a model by constructing an inherent\n', 'transparent model that mimics the behaviour of the black-box model.\n', '1. S. Tan et al.,  \n', '   ""[Distill-and-Compare: Auditing Black-Box Models Using Transparent Model Distillation](https://dl.acm.org/doi/abs/10.1145/3278721.3278725)"",\n', ""   AIES'18 303–310, 2018\n"", '2. L. Chu et al., ""Exact and Consistent Interpretation for Piecewise Linear Neural Networks: A Closed Form Solution"",\n', '   [arXiv:1802.06259](https://arxiv.org/abs/1802.06259) [cs.CV]\n', '3. C. Yang et al., ""Global Model Interpretation via Recursive Partitioning"",\n', '   [arXiv:1802.04253](https://arxiv.org/abs/1802.04253) [cs.LG]\n', '4. H. Lakkaraju et al., ""Interpretable & Explorable Approximations of Black Box Models"",\n', '   [arXiv:1707.01154](https://arxiv.org/abs/1707.01154) [cs.AI]\n', '5. Y. Hayashi,\n', '   ""[Synergy effects between grafting and subdivision in Re-RX with J48graft for the diagnosis of thyroid disease](https://www.sciencedirect.com/science/article/abs/pii/S095070511730285X)"",\n', '   Knowledge-Based Systems (131) 170-182, 2017\n', '6. H. F. Tan et al., ""Tree Space Prototypes: Another Look at Making Tree Ensembles Interpretable"",\n', '   [arXiv:1611.07115](https://arxiv.org/abs/1611.07115) [stat.ML]\n', '7. O. Sagi and L. Rokach, \n', '   ""[Approximating XGBoost with an interpretable decision tree](https://www.sciencedirect.com/science/article/abs/pii/S0020025521005272)"", Information Sciences (572) 522-542, 2021 \n', '\n', '### Local XAI methods\n', 'This section contains articles that describe local explanation methods, i.e. methods that generate an explanation\n', 'for a specific outcome of a model.\n', '1. M. T. Ribeiro et al.,\n', '   ""[Anchors: High-Precision Model-Agnostic Explanations](https://homes.cs.washington.edu/~marcotcr/aaai18.pdf)"",\n', '   AAAI Conference on Artificial Intelligence, 2018 -\n', '   The implementation of the method can be found on [github](https://github.com/marcotcr/anchor).\n', '2. A. Shrikumar et al.,\n', '   ""[Learning Important Features Through Propagating Activation Differences](https://dl.acm.org/doi/10.5555/3305890.3306006)"",\n', ""   ICML'17 3145–3153, 2017 - DeepLIFT method for local explanations of deep neural networks.\n"", '3. S. M. Lundberg et al., ""Explainable AI for Trees: From Local Explanations to Global Understanding"",\n', '   [arXiv:1905.04610](https://arxiv.org/abs/1905.04610) [stat.ML]\n', '4. S. M. Lundberg et al.,\n', '   ""[From local explanations to global understanding with explainable AI for trees](https://www.nature.com/articles/s42256-019-0138-9)"",\n', '   Nat. Mach. Intell. (2) 56–67, 2020\n', '5. M. T. Ribeiro et al.,\n', '   [“Why Should I Trust You?” Explaining the Predictions of Any Classifier](https://dl.acm.org/doi/10.1145/2939672.2939778),\n', ""   KDD'16 1135–1144, 2016\n"", '6. D. Slack et al., ""How Much Should I Trust You? Modeling Uncertainty of Black Box Explanations"",\n', '   [arXiv:2008.05030](https://arxiv.org/abs/2008.05030) [cs.LG]\n', '7. S. M. Lundberg and S.-I. Lee,\n', '   ""[A Unified Approach to Interpreting Model Predictions](https://proceedings.neurips.cc/paper/2017/hash/8a20a8621978632d76c43dfd28b67767-Abstract.html)"",\n', '   NIPS, 2017\n', '8. M. Sundararajan and A. Najmi,\n', '   ""[The Many Shapley Values for Model Explanation](http://proceedings.mlr.press/v119/sundararajan20b.html)"",\n', '   ICML (119) 9269-9278, 2020\n', '9. I. E. Kumar et al., ""Problems with Shapley-value-based explanations as feature importance measures"",\n', '   [arXiv:2002.11097](https://arxiv.org/abs/2002.11097) [cs.AI]\n', '10. P. W. Koh and P. Liang, ""Understanding Black-box Predictions via Influence Functions"",\n', '      [arXiv:1703.04730](https://arxiv.org/abs/1703.04730) [stat.ML]\n', '\n', '### Counterfactual explanations\n', 'This section contains articles that describe methods for counterfactual explanations.\n', '1. S. Sharma et al.,\n', '   ""[CERTIFAI: A Common Framework to Provide Explanations and Analyse the Fairness and Robustness of Black-box Models](https://dl.acm.org/doi/10.1145/3375627.3375812)"",\n', ""   AIES'20 166–172, 2020\n"", '2. C. Russell, ""[Efficient Search for Diverse Coherent Explanations](https://dl.acm.org/doi/10.1145/3287560.3287569)"",\n', ""   FAT*'19  20–28, 2019\n"", '3. R. K. Mothilal et al.,\n', '   ""[Explaining Machine Learning Classifiers through Diverse Counterfactual Explanations](https://dl.acm.org/doi/abs/10.1145/3351095.3372850)"",\n', ""   FAT*'20 607–617, 2020 - Code for the method is available on [github](https://github.com/interpretml/DiCE).\n"", '4. S. Barocas et al.,\n', '   ""[The Hidden Assumptions Behind Counterfactual Explanations and Principal Reasons](https://dl.acm.org/doi/abs/10.1145/3351095.3372830)"",\n', ""   FAT*'20  80–89, 2020 - Raises some questions with respect to the use of counterfactual examples as a form of explanation:\n"", '   * Are the changes proposed by the counterfactual example feasible (actionable) for a person to change their outcome?\n', '   * If the changes are performed, what do they affect otherwise, i.e. they might not be favorable in other contexts?\n', '   * Changing one factor might inherently change another factor that actually negatively affects the outcome\n', '     (counterfactual examples can not describe complex relationships between variables)?\n', '\n', '### XAI and user interaction\n', 'This section contains research articles that are looking at the interaction of users with explanations or\n', 'interpretable models.\n', '1. B. Y. Lim and A. K. Dey,\n', '   ""[Assessing Demand for Intelligibility in Context-Aware Applications](https://dl.acm.org/doi/10.1145/1620545.1620576)"",\n', ""   UbiComp'09 195–204, 2009\n"", '2. D. Wang et al.,\n', '   ""[Designing Theory-Driven User-Centric Explainable AI](https://dl.acm.org/doi/10.1145/3290605.3300831)"",\n', ""   CHI'19 (601)  1–15, 2019\n"", '3. M. Narayanan et al.,\n', '   ""How do Humans Understand Explanations from Machine Learning Systems? An Evaluation of the Human-Interpretability of Explanation"",\n', '   [arXiv:1802.00682](https://arxiv.org/abs/1802.00682) [cs.AI]\n', '4. U. Bhatt et al., ""Machine Learning Explainability for External Stakeholders"",\n', '   [arXiv:2007.05408](https://arxiv.org/abs/2007.05408) [cs.CY]\n', '5. V. Lai and C. Tan,\n', '   ""[On Human Predictions with Explanations and Predictions of Machine Learning Models: A Case Study on Deception Detection](https://dl.acm.org/doi/abs/10.1145/3287560.3287590)"",\n', ""   FAT*'19 29–38, 2019\n"", '6. C. Molnar et al., ""Pitfalls to Avoid when Interpreting Machine Learning Models"",\n', '   [arXiv:2007.04131](https://arxiv.org/abs/2007.04131) [stat.ML]\n', '7. A. Preece et al., ""Stakeholders in Explainable AI"",\n', '   [arXiv:1810.00184](https://arxiv.org/abs/1810.00184) [cs.AI]\n', '8. M. Katell et al.,\n', '   ""[Toward Situated Interventions for Algorithmic Equity: Lessons from the Field](https://dl.acm.org/doi/abs/10.1145/3351095.3372874)"",\n', ""   FAT*'20 45–55, 2020 - Presenting a framework for designing ML/AI solutions based on participatory design and co-design methods,\n"", '   which especially focuses on solutions that effect communities, i.e. models employed by municipalities. The framework is applied\n', '   to an example case in which a surveillance tool with an automatic decision system is designed.\n', '9. M. Eiband et al.,\n', '   ""[Bringing Transparency Design into Practice](https://dl.acm.org/doi/10.1145/3172944.3172961)"",\n', ""   IUI'18 211–223, 2018\n"", '\n', '### XAI used in practice\n', 'This section contains research articles where XAI was used as part of an application or used for validation on a system\n', 'deployed in practice.\n', '1. S. Coppers et al.,\n', '   ""[Intellingo: An Intelligible Translation Environment](https://dl.acm.org/doi/10.1145/3173574.3174098)"",\n', ""   CHI'18 (524) 1–13, 2018\n"", '2. H. Tang and P. Eratuuli,\n', '   ""[Package and Classify Wireless Product Features to Their Sales Items and Categories Automatically](https://link.springer.com/chapter/10.1007/978-3-030-29726-8_20)"",\n', '   Machine Learning and Knowledge Extraction. CD-MAKE 2019. LNCS (11713), 2019\n', '\n', '### XAI for deep neural networks\n', 'This section focuses on explainability with respect to deep neural networks (DNNs). This can be methods to explain\n', 'DNNs or methods to build DNNs that can explain themselves.\n', '1. Y. Goyal et al.,\n', '   ""[Counterfactual Visual Explanations](http://pr"
Responsible+AI,romanlutz/ResponsibleAI,romanlutz,https://api.github.com/repos/romanlutz/ResponsibleAI,49,9,3,"['https://api.github.com/users/romanlutz', 'https://api.github.com/users/riedgar-ms', 'https://api.github.com/users/benbyford']",,2023-04-08T18:10:32Z,https://raw.githubusercontent.com/romanlutz/ResponsibleAI/main/README.md,"['The following collection is meant to serve as a reference for engineers, data scientists, and others making decisions about building technological solutions for real-world problems. Hopefully, this will help us avoid repeating mistakes of the past by informing the design of new systems or the decision not to build a technological solution at all.\n', '\n', 'This is a living document, so please send suggestions for additions through ""Issues"" or feel free to send pull requests. If you find any other problems with links or the articles themselves, please also open an ""Issue"".\n', '\n', '# Fairness\n', '\n', '## Lending & Credit approval\n', '\n', '- [Gender Bias Complaints against Apple Card Signal a Dark Side to Fintech](https://hbswk.hbs.edu/item/gender-bias-complaints-against-apple-card-signal-a-dark-side-to-fintech)\n', '- [Exploring Racial Discrimination in Mortgage Lending: A Call for Greater Transparency](https://listwithclever.com/real-estate-blog/racial-discrimination-in-mortgage-lending/)\n', '- [DFS Issues Guidance to Life Insurers on Use of “External Data” in Underwriting Decisions](https://www.jdsupra.com/legalnews/dfs-issues-guidance-to-life-insurers-on-45997/)\n', '\n', '## Hiring\n', '\n', '- [Amazon scraps secret AI recruiting tool that showed bias against women](https://www.reuters.com/article/us-amazon-com-jobs-automation-insight-idUSKCN1MK08G)\n', '- [Automated Employment Discrimination](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3437631)\n', '- [Help wanted: an examination of hiring algorithms, equity, and bias](https://apo.org.au/node/210071)\n', '- [All the Ways Hiring Algorithms Can Introduce Bias](https://hbr.org/2019/05/all-the-ways-hiring-algorithms-can-introduce-bias)\n', '- [Mitigating Bias in Algorithmic Hiring: Evaluating Claims and Practices](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3408010)\n', '- [Help Wanted - An Examination of Hiring Algorithms, Equity, and Bias](https://www.upturn.org/static/reports/2018/hiring-algorithms/files/Upturn%20--%20Help%20Wanted%20-%20An%20Exploration%20of%20Hiring%20Algorithms,%20Equity%20and%20Bias.pdf)\n', '- [Wanted: The ‘perfect babysitter.’ Must pass AI scan for respect and attitude.](https://www.washingtonpost.com/technology/2018/11/16/wanted-perfect-babysitter-must-pass-ai-scan-respect-attitude/)\n', '- [Job Screening Service Halts Facial Analysis of Applicants](https://www.wired.com/story/job-screening-service-halts-facial-analysis-applicants/)\n', '\n', '## Employee evaluation\n', '\n', '- [Houston Schools Must Face Teacher Evaluation Lawsuit](https://www.courthousenews.com/houston-schools-must-face-teacher-evaluation-lawsuit/)\n', '- [How Amazon automatically tracks and fires warehouse workers for ‘productivity’](https://www.theverge.com/2019/4/25/18516004/amazon-warehouse-fulfillment-centers-productivity-firing-terminations)\n', ""- [Court Rules Deliveroo Used 'Discriminatory' Algorithm](https://www.vice.com/en/article/7k9e4e/court-rules-deliveroo-used-discriminatory-algorithm)\n"", '\n', '## Pre-trial risk assessment and criminal sentencing\n', '\n', '- [Machine Bias](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing)\n', '- [How We Analyzed the COMPAS Recidivism Algorithm](https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm)\n', '- [GitHub repository for COMPAS analysis](https://github.com/propublica/compas-analysis)\n', '- [Can you make AI fairer than a judge? Play our courtroom algorithm game](https://www.technologyreview.com/s/613508/ai-fairer-than-judge-criminal-risk-assessment-algorithm/)\n', '    \n', '## Predictive Policing & Other Law Enforcement Use Cases\n', '\n', '- [Dirty Data, Bad Predictions: How Civil Rights Violations Impact Police Data, Predictive Policing Systems, and Justice](https://www.nyulawreview.org/online-features/dirty-data-bad-predictions-how-civil-rights-violations-impact-police-data-predictive-policing-systems-and-justice/)\n', '- [Amazon’s Face Recognition Falsely Matched 28 Members of Congress With Mugshots](https://www.aclu.org/blog/privacy-technology/surveillance-technologies/amazons-face-recognition-falsely-matched-28)\n', '- [The Perpetual Line-Up - Unregulated police face recognition in America](https://www.perpetuallineup.org/)\n', '- [Stuck in a Pattern: Early evidence on ""predictive policing"" and civil rights](https://www.upturn.org/reports/2016/stuck-in-a-pattern/)\n', '- [Crime-prediction tool PredPol amplifies racially biased policing, study shows](https://www.mic.com/articles/156286/crime-prediction-tool-pred-pol-only-amplifies-racially-biased-policing-study-shows#.DZeqQ4LYs)\n', '- [Criminal machine learning](https://callingbullshit.org/case_studies/case_study_criminal_machine_learning.html)\n', '- [The Liar’s Walk - Detecting Deception with Gait and Gesture](http://gamma.cs.unc.edu/GAIT/files/Deception_LSTM.pdf)\n', '- [Federal study confirms racial bias of many facial-recognition systems, casts doubt on their expanding use](https://www.washingtonpost.com/technology/2019/12/19/federal-study-confirms-racial-bias-many-facial-recognition-systems-casts-doubt-their-expanding-use/)\n', '- [Return of physiognomy? Facial recognition study says it can identify criminals from looks alone](https://www.rt.com/news/368307-facial-recognition-criminal-china/)\n', '- [Live facial recognition is tracking kids suspected of being criminals](https://www.technologyreview.com/2020/10/09/1009992/live-facial-recognition-is-tracking-kids-suspected-of-crime/)\n', '\n', '## Admissions\n', '\n', '- [British Medical Journal: A blot on the profession](https://www.bmj.com/content/296/6623/657)\n', '\n', '## School Choice\n', '\n', '- [Custom Software Helps Cities Manage School Choice](https://www.edweek.org/ew/articles/2013/12/04/13algorithm_ep.h33.html)\n', '\n', '## Speech Detection\n', '\n', '- [Oh dear... AI models used to flag hate speech online are, er, racist against black people](https://www.theregister.co.uk/2019/10/11/ai_black_people/)\n', '- [The Risk of Racial Bias in Hate Speech Detection](https://homes.cs.washington.edu/~msap/pdfs/sap2019risk.pdf)\n', '- [Toxicity and Tone Are Not The Same Thing: analyzing the new Google API on toxicity, PerspectiveAPI.](https://medium.com/@carolinesinders/toxicity-and-tone-are-not-the-same-thing-analyzing-the-new-google-api-on-toxicity-perspectiveapi-14abe4e728b3)\n', '- [Voice Is the Next Big Platform, Unless You Have an Accent](https://www.wired.com/2017/03/voice-is-the-next-big-platform-unless-you-have-an-accent/)\n', '- [Google’s speech recognition has a gender bias](https://makingnoiseandhearingthings.com/2016/07/12/googles-speech-recognition-has-a-gender-bias/)\n', '- [Fair Speech report by Stanford Computational Policy Lab](https://fairspeech.stanford.edu/), also covered in [Speech recognition algorithms may also have racial bias](https://arstechnica.com/science/2020/03/speech-recognition-algorithms-may-also-have-racial-bias/)\n', '- [Automated moderation tool from Google rates People of Color and gays as “toxic”](https://algorithmwatch.org/en/story/automated-moderation-perspective-bias/)\n', '- [Someone made an AI that predicted gender from email addresses, usernames. It went about as well as expected](https://www.theregister.com/2020/07/30/genderify_shuts_down/)\n', '\n', '## Image Labelling & Face Recognition\n', '\n', ""- [Google Photos identified two black people as 'gorillas'](https://mashable.com/2015/07/01/google-photos-black-people-gorillas/)\n"", '- [When It Comes to Gorillas, Google Photos Remains Blind](https://www.wired.com/story/when-it-comes-to-gorillas-google-photos-remains-blind/)\n', '- [The viral selfie app ImageNet Roulette seemed fun – until it called me a racist slur](https://www.theguardian.com/technology/2019/sep/17/imagenet-roulette-asian-racist-slur-selfie)\n', ""- [Google Is Investigating Why it Trained Facial Recognition on 'Dark Skinned' Homeless People](https://www.vice.com/en_uk/article/43k7yd/google-is-investigating-why-it-trained-facial-recognition-on-dark-skinned-homeless-people)\n"", '- [Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification](http://proceedings.mlr.press/v81/buolamwini18a/buolamwini18a.pdf)\n', '- [Machines Taught by Photos Learn a Sexist View of Women](https://www.wired.com/story/machines-taught-by-photos-learn-a-sexist-view-of-women/)\n', '- [Tenants sounded the alarm on facial recognition in their buildings. Lawmakers are listening.](https://www.msn.com/en-us/news/politics/tenants-sounded-the-alarm-on-facial-recognition-in-their-buildings-lawmakers-are-listening/ar-BBYnaqB)\n', '- [Google apologizes after its Vision AI produced racist results](https://algorithmwatch.org/en/story/google-vision-racism/)\n', ""- [When AI Sees a Man, It Thinks 'Official.' A Woman? 'Smile'](https://www.wired.com/story/ai-sees-man-thinks-official-woman-smile/)\n"", '\n', '## Public Benefits & Health\n', '\n', '- [A health care algorithm affecting millions is biased against black patients](https://www.theverge.com/2019/10/24/20929337/care-algorithm-study-race-bias-health)\n', '- [What happens when an algorithm cuts your health care](https://www.theverge.com/2018/3/21/17144260/healthcare-medicaid-algorithm-arkansas-cerebral-palsy)\n', '- [China Knows How to Take Away Your Health Insurance](https://www.bloomberg.com/opinion/articles/2019-06-14/china-knows-how-to-take-away-your-health-insurance)\n', '- [Foretelling the Future: A Critical Perspective on the Use of Predictive Analytics in Child Welfare](http://kirwaninstitute.osu.edu/wp-content/uploads/2017/05/ki-predictive-analytics.pdf)\n', '- [There’s no quick fix to find racial bias in health care algorithms](https://www.theverge.com/2019/12/4/20995178/racial-bias-health-care-algorithms-cory-booker-senator-wyden)\n', '- [Health algorithms discriminate against Black patients, also in Switzerland](https://algorithmwatch.ch/en/racial-health-bias/)\n', '\n', '## Ads\n', '\n', '- [Discrimination in Online Ad Delivery](https://arxiv.org/abs/1301.6822)\n', '- [Probing the Dark Side of Google’s Ad-Targeting System](https://www.technologyreview.com/s/539021/probing-the-dark-side-of-googles-ad-targeting-system/)\n', '- [Facebook Engages in Housing Discrimination With Its Ad Practices, U.S. Says](https://www.nytimes.com/2019/03/28/us/politics/facebook-housing-discrimination.html)\n', '- [Facebook Job Ads Raise Concerns About Age Discrimination](https://www.outtengolden.com/facebook-job-ads-raise-concerns-about-age-discrimination-nyt)\n', '- [Facebook Ads Can Still Discriminate Against Women and Older Workers, Despite a Civil Rights Settlement](https://www.propublica.org/article/facebook-ads-can-still-discriminate-against-women-and-older-workers-despite-a-civil-rights-settlement)\n', '- [Women less likely to be shown ads for high-paid jobs on Google, study shows](https://www.theguardian.com/technology/2015/jul/08/women-less-likely-ads-high-paid-jobs-google-study)\n', '- [Algorithms That “Don’t See Color”: Comparing Biases in Lookalike and Special Ad Audiences](https://sapiezynski.com/papers/sapiezynski2019algorithms.pdf)\n', '- [Facebook is letting job advertisers target only men](https://www.propublica.org/article/facebook-is-letting-job-advertisers-target-only-men)\n', '- [Facebook (Still) Letting Housing Advertisers Exclude Users by Race](https://www.propublica.org/article/facebook-advertising-discrimination-housing-race-sex-national-origin)\n', '\n', '## Search\n', '\n', '- [Algorithms of Oppression: How Search Engines reinforce racism](http://algorithmsofoppression.com/)\n', '- [Bias already exists in search engine results, and it’s only going to get worse](https://www.technologyreview.com/s/610275/meet-the-woman-who-searches-out-search-engines-bias-against-women-and-minorities/)\n', '- [Truth in pictures: What Google image searches tell us about inequality at work](https://www.diversityemployers.com/blog/2017/05/truth-in-pictures-what-google-image-searches-tell-us-about-inequality-at-work/)\n', '\n', '## Translations\n', '\n', '- [Google Translate might have a gender problem](https://mashable.com/2017/11/30/google-translate-sexism/)\n', '\n', '## Jury Selection\n', '\n', '- [The Big Data Jury](https://scholarship.law.nd.edu/ndlr/vol91/iss3/2/)\n', '\n', '## Dating\n', '\n', '- [Coffee Meets Bagel: The Online Dating Site That Helps You Weed Out The Creeps](https://www.laweekly.com/coffee-meets-bagel-the-online-dating-site-that-helps-you-weed-out-the-creeps/)\n', '- [The Biases we feed to Tinder algorithms](https://www.diggitmagazine.com/articles/biases-we-feed-tinder-algorithms)\n', '- [Redesign dating apps to lessen racial bias, study recommends](http://news.cornell.edu/stories/2018/09/redesign-dating-apps-lessen-racial-bias-study-recommends)\n', '\n', '## Word Embeddings\n', '\n', 'Word Embeddings may affect many of the categories above through applications that use them.\n', '- [Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings](https://papers.nips.cc/paper/6228-man-is-to-computer-programmer-as-woman-is-to-homemaker-debiasing-word-embeddings.pdf)\n', '\n', '## Gerrymandering\n', '\n', '- [When drawing a line is hard](https://medium.com/equal-future/when-drawing-a-line-is-hard-8d92d30c9044)\n', '\n', '## Recommender systems\n', '\n', '- [Why is TikTok creating filter bubbles based on your race?](https://www.wired.co.uk/article/tiktok-filter-bubbles)\n', '\n', '## Picking areas for improved service\n', '\n', '- [Amazon Doesn’t Consider the Race of Its Customers. Should It?](https://www.bloomberg.com/graphics/2016-amazon-same-day/)\n', '\n', '# Safety\n', '\n', '## Self-driving cars\n', '\n', '- [Remember the Uber self-driving car that killed a woman crossing the street? The AI had no clue about jaywalkers](https://www.theregister.co.uk/2019/11/06/uber_self_driving_car_death/)\n', '- [Franken-algorithms: The Deadly Consequences of Unpredictable Code](https://getpocket.com/explore/item/franken-algorithms-the-deadly-consequences-of-unpredictable-code)\n', '\n', '## Weaponized AI\n', '\n', '- [Google employee protest: Now Google backs off Pentagon drone AI project](https://www.zdnet.com/article/google-employee-protests-now-google-backs-off-pentagon-drone-ai-project/)\n', '- [Google Wants to Do Business With the Military—Many of Its Employees Don’t](https://www.bloomberg.com/features/2019-google-military-contract-dilemma/)\n', '\n', '## Health\n', '\n', '- Model interpretability in Medicine\n', '  - [Intelligible Models for HealthCare: Predicting Pneumonia Risk and Hospital 30-day Readmission](http://people.dbmi.columbia.edu/noemie/papers/15kdd.pdf) shows importance of model interpretability for such critical decisions.\n', ""  - [Rich Caruana--Friends Don't Let Friends Release Black Box Models in Medicine](https://www.youtube.com/watch?v=iyGh46NA8tk)\n"", '- [IBM pitched its Watson supercomputer as a revolution in cancer care. It’s nowhere close](https://www.statnews.com/2017/09/05/watson-ibm-cancer/)\n', '- [International evaluation of an AI system for breast cancer screening](https://deepmind.com/research/publications/International-evaluation-of-an-artificial-intelligence-system-to-identify-breast-cancer-in-screening-mammography) - [This thread examines the issues with the problem setting.](https://twitter.com/VPrasadMDMPH/status/1212840987363442689?s=20)\n', '\n', '# Privacy\n', '\n', '## Machine Learning-based privacy attacks\n', '\n', '- [Privacy Attacks on Machine Learning Models](https://www.infoq.com/articles/privacy-attacks-machine-learning-models/)\n', '\n', '## Lending\n', '\n', '- [The new lending game, post-demonetisation](https://tech.economictimes.indiatimes.com/news/technology/the-new-lending-game-post-demonetisation/56367457)\n', '- [Perpetual Debt in the Silicon Savannah](http://bostonreview.net/class-inequality-global-justice/kevin-p-donovan-emma-park-perpetual-debt-silicon-savannah)\n', '\n', '## Work\n', '\n', '- [Woman fired after disabling work app that tracked her movements 24/7](https://www.theverge.com/2015/5/13/8597081/worker-gps-fired-myrna-arias-xora)\n', '- [Limitless Worker Surveillance](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2746211)\n', '\n', '## Prison tech\n', '\n', '- [Prison tech company is questioned for retaining ‘voice prints’ of people presumed innocent](https://theappeal.org/jails-across-the-u-s-are-extracting-the-voice-prints-of-people-presumed-innocent/)\n', '\n', '## Location data\n', '\n', '- [Twelve Million Phones, One Dataset, Zero Privacy](https://www.nytimes.com/interactive/2019/12/19/opinion/location-tracking-cell-phone.html) shines a light on data privacy (or the lack thereof). That same data may be used to for ML as well.\n', '- [Tenants sounded the alarm on facial recognition in their buildings. Lawmakers are listening.](https://www.msn.com/en-us/news/politics/tenants-sounded-the-alarm-on-facial-recognition-in-their-buildings-lawmakers-are-listening/ar-BBYnaqB)\n', '- [Face for sale: Leaks and lawsuits blight Russia facial recognition](https://www.reuters.com/article/us-russia-privacy-lawsuit-feature-trfn/face-for-sale-leaks-and-lawsuits-blight-russia-facial-recognition-idUSKBN27P10U)\n', '\n', '## Social media & dating\n', '\n', '- [OkCupid Study Reveals the Perils of Big-Data Science](https://www.wired.com/2016/05/okcupid-study-reveals-perils-big-data-science/)\n', '- [“We Are the Product”: Public Reactions to Online Data Sharing and Privacy Controversies in the Media](https://cmci.colorado.edu/~cafi5706/CHI2018_FieslerHallinan.pdf)\n', '\n', '## Basic anonymization as an insufficient measure\n', '\n', '- [“Anonymized” data really isn’t—and here’s why not](https://arstechnica.com/tech-policy/2009/09/your-secrets-live-online-in-databases-of-ruin/)\n', '\n', '## Health\n', '\n', '- [Health Insurers Are Vacuuming Up Details About You — And It Could Raise Your Rates](https://www.npr.org/sections/health-shots/2018/07/17/629441555/health-insurers-are-vacuuming-up-details-about-you-and-it-could-raise-your-rates)\n', '- [How Your Medical Data Fuels a Hidden Multi-Billion Dollar Industry](https://time.com/4588104/medical-data-industry/)\n', ""- [23andMe's Pharma Deals Have Been the Plan All Along](https://www.wired.com/story/23andme-glaxosmithkline-pharma-deal/)\n"", '- [If You Want Life Insurance, Think Twice Before Getting A Genetic Test](https://www.fastcompany.com/3055710/if-you-want-life-insurance-think-twice-before-getting-genetic-testing)\n', '- [Medical Start-up Invited Millions Of Patients To Write Reviews They May Not Realize Are Public. Some Are Explicit.](https://www.forbes.com/sites/kashmirhill/2013/10/21/practice-fusion-patient-privacy-explicit-reviews/#2918de354ae3)\n', '- [Help Desk: Can your medical records become marketing? We investigate a reader’s suspicious ‘patient portal.’](https://www.washingtonpost.com/technology/2019/10/22/help-desk-can-your-medical-records-become-marketing-we-investigate-readers-suspicious-patient-portal/)\n', '- [Is your pregnancy app sharing your intimate data with your boss?](https://www.washingtonpost.com/technology/2019/04/10/tracking-your-pregnancy-an-app-may-be-more-public-than-you-think/)\n', '- [Data Crisis: Who Owns Your Medical Records?](https://www.sandiegomagazine.com/San-Diego-Magazine/October-2016/Top-Doctors-2016-Innovation-in-Health-and-Medicine/Data-Crisis-Who-Owns-Your-Medical-Records/)\n', ""- [This Bluetooth Tampon Is the Smartest Thing You Can Put In Your Vagina](https://gizmodo.com/this-bluetooth-tampon-is-the-smartest-thing-you-can-put-1777044090) didn't mention the privacy concerns of such a device. [This Twitter comment adds the necessary comment.](https://twitter.com/DrRanjanaDas/status/1213940445245509671?s=20) \n"", '\n', '## Face Recognition\n', '\n', '- [Clearview AI: We Are ‘Working to Acquire All U.S. Mugshots’ From Past 15 Years](https://onezero.medium.com/clearview-ai-we-are-working-to-acquire-all-u-s-mugshots-from-past-15-years-645d92319f33)\n', '- [Face for sale: Leaks and lawsuits blight Russia facial recognition](https://www.reuters.com/article/us-russia-privacy-lawsuit-feature-trfn/face-for-sale-leaks-and-lawsuits-blight-russia-facial-recognition-idUSKBN27P10U)\n', '\n', '## Supply of goods\n', '\n', '- [Grocers Stopped Stockpiling Food. Then Came Coronavirus.](https://www.wsj.com/articles/grocers-stopped-stockpiling-food-then-came-coronavirus-11584982605)\n', '\n', '\n', '# Anti-Money Laundering\n', '\n', '- [Trusting Machine Learning in Anti-Money Laundering: A Risk-Based Approach](http://www.caspian.co.uk/rba/RBA.pdf)\n', '\n', '\n', '# General resources about Responsible AI\n', '\n', 'Many of the books and articles in this area cover a wide range of topics. Below is a list of a few of them, sorted alphabetically by title:\n', '\n', '- [A Hippocratic Oath for artificial intelligence practitioners](https://techcrunch.com/2018/03/14/a-hippocratic-oath-for-artificial-intelligence-practitioners/) by [Oren Etzioni](https://allenai.org/team/orene/)\n', '- [Algorithms, Correcting Biases](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3300171) by [Cass Sunstein](https://hls.harvard.edu/faculty/directory/10871/Sunstein)\n', '- [Algorithms of Oppression - How Search Engines Reinforce Racism](http://algorithmsofoppression.com/) by [Safiya Umoja Noble](https://safiyaunoble.com/)\n', '- [Artificial Unintelligence - How Computers Misunderstand the World](https://mitpress.mit.edu/books/artificial-unintelligence) by [Meredith Broussard](https://merbroussard.github.io/)\n', '- [Automating Inequality: How High-Tech Tools Profile, Police, and Punish the Poor](https://us.macmillan.com/books/9781250074317) by [Virginia Eubanks](https://virginia-eubanks.com/)\n', ""- [Big Data's Disparate Impact](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2477899) by [Solon Barocas](http://solon.barocas.org/) and [Andrew D. Selbst](https://andrewselbst.com/)\n"", '- [Datasheets for Datasets](https://arxiv.org/abs/1803.09010) by [Timnit Gebru](http://ai.stanford.edu/~tgebru/) et al.\n', '- [Design Justice](https://design-justice.pubpub.org/) by [Sasha Costanza-Chock](https://www.schock.cc/)\n', '- [Fairness and Abstraction in Sociotechnical Systems](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3265913) by [Andrew D. Selbst](https://andrewselbst.com/), [danah boyd](https://www.danah.org/), [Sorelle Friedler](http://sorelle.friedler.net/), [Suresh Venkatasubramanian](http://www.cs.utah.edu/~suresh/), [Janet Vertesi](https://janet.vertesi.com/)\n', '- [Fairness and machine learning - Limitations and Opportunities](https://fairmlbook.org/) by [Solon Barocas](http://solon.barocas.org/), [Moritz Hardt](https://mrtz.org/), [Arvind Narayanan](http://randomwalker.info/)\n', ""- [How I'm fighting bias in algorithms](https://www.ted.com/talks/joy_buolamwini_how_i_m_fighting_bias_in_algorithms?language=en) by [Joy Buolamwini](https://www.poetofcode.com/)\n"", '- [Race after Technology](https://www.ruhabenjamin.com/race-after-technology) by [Ruha Benjamin](https://www.ruhabenjamin.com)\n', '- [Interpretable Machine Learning](https://christophm.github.io/interpretable-ml-book/) by [Christoph Molnar](https://christophm.github.io/)\n', '- [Tech Ethics Curriculum](https://docs.google.com/spreadsheets/d/1jWIrA8jHz5fYAW4h9CkUD8gKS5V98PDJDymRf8d9vKI/edit#gid=1174187227) by [Casey Fiesler](https://caseyfiesler.com/)\n', '- [The Measure and Mismeasure of Fairness: A Critical Review of Machine Learning](https://5harad.com/papers/fair-ml.pdf) by [Sam Corbett-Davis](https://samcorbettdavies.com/) and [Sharad Goel](https://5harad.com/)\n', ""- [Weapons of Math Destruction](https://weaponsofmathdestructionbook.com/) by [Cathy O'Neil](https://mathbabe.org/)\n""]"
Responsible+AI,microsoft/robustlearn,microsoft,https://api.github.com/repos/microsoft/robustlearn,168,11,5,"['https://api.github.com/users/jindongwang', 'https://api.github.com/users/dependabot%5Bbot%5D', 'https://api.github.com/users/qianlanwyd', 'https://api.github.com/users/microsoftopensource', 'https://api.github.com/users/XixuHu']",Python,2023-04-09T19:14:55Z,https://raw.githubusercontent.com/microsoft/robustlearn/main/README.md,"['# robustlearn\n', '\n', 'Latest research in robust machine learning, including adversarial/backdoor attack and defense, out-of-distribution (OOD) generalization, and safe transfer learning.\n', '\n', 'Hosted projects:\n', '- **Diversify** (ICLR 2023, #OOD):\n', '  - [Code](./diversify/) | [Out-of-distribution Representation Learning for Time Series Classification](https://arxiv.org/abs/2209.07027)\n', '- **MARC** (ACML 2022, #Long-tail): \n', '  - [Code](./marc/) | [Margin Calibration for Long-Tailed Visual Recognition](https://arxiv.org/abs/2112.07225)\n', '- **ChatGPT robustness** (arXiv 2023, #OOD #Adversarial): \n', '  - [Code](./chatgpt-robust/) | [On the Robustness of ChatGPT: An Adversarial and Out-of-distribution Perspective](https://arxiv.org/abs/2302.12095)\n', '- Stay tuned for more upcoming projects!\n', '\n', 'You can clone or download this repo. Then, go to the project folder that you are interested to run and develop your research.\n', '\n', '## Contributing\n', '\n', 'This project welcomes contributions and suggestions.  Most contributions require you to agree to a\n', 'Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\n', 'the rights to use your contribution. For details, visit https://cla.opensource.microsoft.com.\n', '\n', 'When you submit a pull request, a CLA bot will automatically determine whether you need to provide\n', 'a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions\n', 'provided by the bot. You will only need to do this once across all repos using our CLA.\n', '\n', 'This project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\n', 'For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\n', 'contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n', '\n', '## Trademarks\n', '\n', 'This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft \n', 'trademarks or logos is subject to and must follow \n', ""[Microsoft's Trademark & Brand Guidelines](https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general).\n"", 'Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship.\n', ""Any use of third-party trademarks or logos are subject to those third-party's policies.\n""]"
Responsible+AI,Azure/Azureml-ResponsibleAI-Preview,Azure,https://api.github.com/repos/Azure/Azureml-ResponsibleAI-Preview,17,6,3,"['https://api.github.com/users/minthigpen', 'https://api.github.com/users/gaugup', 'https://api.github.com/users/microsoftopensource']",Python,2022-11-22T19:35:35Z,https://raw.githubusercontent.com/Azure/Azureml-ResponsibleAI-Preview/main/README.md,"['# [Deprecated] Azure Machine Learning Responsible AI Toolbox - Private Preview\n', '\n', '❗ **DO NOT USE THESE DOCS:* This repo has been deprecated, for the updated private preview docs please see here: https://github.com/Azure/RAI-vNext-Preview\n', '\n', 'Welcome to the private preview for the new Responsible AI toolbox in Azure Machine Learning (AzureML) SDK and studio. The following is a guide for you to onboard to the new capabilities. For questions, please contact mithigpe@microsoft.com.\n', '\n', '## What is this new feature?\n', '\n', 'AzureML currently supports both [model explanations](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-machine-learning-interpretability-aml) and [model fairness](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-machine-learning-fairness-aml) in public preview. As we expand our offerings under Responsible AI tools for AzureML users, this new feature brings pre-existing features and brand new offerings under one-stop-shop SDK package and studio UI dashboard:\n', '- Error Analysis (new): view and understand the error distributions of your model over your dataset via a decision tree map or heat map visualization.\n', '- Data Explorer: explore your dataset by feature sets and other metrics such as predicted Y or true Y\n', '- Model Statistics: explore the distribution of your model outcomes and performance metrics\n', '- Interpretability: view the aggregate and individual feature importances across your model and dataset\n', ""- Counterfactual Example What-If's (new): create automatically generated diverse sets of counterfactual examples for each datapoint that is minimally perturbed in order to switch its predicted class or output. Also create your own counterfactual datapoint by perturbing feature values manually to observe the new outcome of your model prediction.\n"", '- Causal Analysis (new): view the aggregate and individual causal effects of *treatment features* (features which you are interested in controlling to affect the outcome) on the outcome in order to make informed real-life business decisions. See recommended treatment policies for segmentations of your population for features in your dataset to see its effect on your real-life outcome. \n', '\n', 'This new feature offers users a new powerful and robust toolkit for understanding your model and data in order to develop your machine learning models responsibly, now all in one place and integrated with your AzureML workspace.\n', '\n', '❗ **Please note:** This initial version of the Responsible AI toolbox currently does not support the integration of fairness metrics. For fairness metrics, please refer to our existing offering [here.](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-machine-learning-fairness-aml)\n', '\n', '## Supported scenarios, models and datasets\n', '\n', ""`azureml-responsibleai` supports computation of Responsible AI insights for `scikit-learn` models that are trained on `pandas.DataFrame`. The `azureml-responsibleai` accept both models and pipelines as input as long as the model or pipeline implements a `predict` or `predict_proba` function that conforms to the `scikit-learn` convention. If not compatible, you can wrap your model's prediction function into a wrapper class that transforms the output into the format that is supported (`predict` or `predict_proba` of `scikit-learn`), and pass that wrapper class to modules in `azureml-responsibleai`.\n"", '\n', 'Currently, we support datasets having numerical and categorical features. The following table provides the scenarios supported for each of the four responsible AI insights:-\n', '\n', '| RAI insight | Binary classification | Multi-class classification | Multilabel classification | Regression | Timeseries forecasting | Categorical features | Text features | Image Features | Recommender Systems | Reinforcement Learning |\n', '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | -- |\n', '| Explainability | Yes | Yes | No | Yes | No | Yes | No | No | No | No |\n', '| Error Analysis | Yes | Yes | No | Yes | No | Yes | No | No | No | No |\n', '| Causal Analysis | Yes | No | No | Yes | No | Yes (max 5 features due to expensiveness) | No | No | No | No |\n', '| Counterfactual | Yes | Yes | No | Yes | No | Yes | No | No | No | No |\n', '\n', '\n', '\n', '## Set Up\n', 'In this section, we will go over the basic setup steps that you need in order to generate Responsible AI insights for your models from SDK and visualize the generated Responsible AI insights in [AML studio](https://ml.azure.com/).\n', '\n', '### Installing `azureml-responsibleai` SDK\n', 'In order to install `azureml-responsibleai` package you will need a python virtual environment. You can create a python virtual environment using `conda`.\n', '```c\n', 'conda create -n azureml_env python=3.7 nb_conda -y\n', '```\n', '\n', 'We support python versions `>= 3.6` and `< 3.9`. Once the `conda` environment `azureml_env` is created, you can install `azureml-responsibleai` using `pip`.\n', '\n', '```c\n', 'activate azureml_env\n', 'pip install azureml-responsibleai\n', 'pip install liac-arff\n', '```\n', '\n', '### Create an Azure subscription\n', 'Create an Azure workspace by using the [configuration notebook](https://github.com/Azure/MachineLearningNotebooks/blob/master/configuration.ipynb)\n', '\n', '### Generating Responsibleai AI Toolbox insights\n', 'Once you have installed `azureml-responsibleai` and created an Azure workspace, you can execute the responsibleai notebooks in the `notebooks` [folder](notebooks/model-analysis) in this repo.\n', '\n', '### Viewing your Responsible AI Toolbox Dashboard in the AzureML studio portal\n', 'After generating the Responsible AI insights via SDK, you can view them in your associated workspace in AzureML studio, under your model registry.\n', '\n', '![01](images/01_model_registry.png)\n', '1. Go to your model registry in your AzureML studio workspace\n', ""2. Click on the model you've uploaded your Responsible AI insights for\n"", '\n', '![02](images/02_model_details.png)\n', '3. Click on the tab for `Responsible AI toolbox (preview)` under your model details page\n', '\n', '![03](images/03_responsibleaitoolbox.png)\n', '4. Under the `Responsible AI toolbox (preview)` tab of your model details, you will see a list of your uploaded Responsible AI insights. You can upload more than one Responsible AI toolbox dashboards for each model. Each row represents one dashboard, with information on which components were uploaded to each dashboard (i.e. explanations, counterfactuals, etc).\n', '\n', '![04](images/04_dashboard.png)\n', '5. At anytime viewing the dashboard, if you wish to return to the model details page, click on `Back to model details`\n', '<ol type=""A"">\n', '  <li>You can view the dashboard insights for each component filtered down on a global cohort you specify. Hovering over the global cohort name will show the number of datapoints and filters in that cohort as a tooltip.</li>\n', '  <li>Switch which global cohort you are applying to the dashboard.</li>\n', '  <li>Create a new global cohort based on filters you can apply in a flyout panel.</li>\n', '  <li>View a list of all global cohorts created and duplicate, edit or delete them.</li>\n', ""  <li>View a list of all Responsible AI components you've uploaded to this dashboard as well as deleting components. The layout of the dashboard will reflect the order of the components in this list.</li>\n"", '</ol>\n', '\n', '❗ **Please note:** Error Analysis, if generated, will always be at the top of the component list in your dashboard. Selecting on the nodes of the error tree or tiles of the error heatmap will automatically generate a temporary cohort that will be populated in the components below so that you can easily experiment with looking at insights for different areas of your error distribution.\n', '\n', '![05](images/05_add_dashboard.png)\n', '6. In between each component you can add components by clicking the blue circular button with a plus sign. This will pop up a tooltip that will give you an option of adding whichever Responsible AI toolbox component you enabled with your SDK.\n', '\n', '#### Known limitations of viewing dashboard in AzureML studio\n', 'Due to current lack of active compute and backend storing and recomputing your Responsible AI toolbox insights in real time, the dashboard in AzureML studio is much less robust than the dashboard generated with the open source package. To generate the full dashboard in a Jupyter python notebook, please download and use our [open source Responsible AI Toolbox SDK](https://github.com/microsoft/responsible-ai-widgets). \n', '\n', 'Some limitations in AzureML studio include:\n', '- Retraining of the Error analysis tree on different features is disabled\n', '- Switching the Error analysis heat map to different features is disabled\n', '- Viewing the Error analysis tree or heatmap on a smaller subset of your full dataset passed into the dashboard (requires retraining of the tree) is disabled\n', '- ICE (Individual Conditional Expectation) plots in the feature importance tab for explanations is disabled\n', '- Manually creating a What-If datapoint is disabled; you can only view the counterfactual examples already pre-generated by the SDK\n', '- Causal analysis individual what-if is disabled; you can only view the individual causal effects of each individual datapoint\n', '\n', '## Responsible AI Toolbox walkthrough and sample notebooks\n', 'Please read through our [sample notebooks for both regression and classification](notebooks/model-analysis) to see if this feature supports your use case. For more details about each individual component, please read through our brief [tour guide of the new Responsible AI toolbox capabilities.](https://github.com/microsoft/responsible-ai-widgets/blob/main/notebooks/responsibleaitoolbox-dashboard/tour.ipynb) \n', '\n', '## What Next?: How to join Private Preview 👀\n', 'We are super excited for you to try this new feature in AzureML! \n', '- Reach out to mithigpe@microsoft.com to enable your Azure subscription for this Private Preview feature.\n', '- Fill out this form - Private Preview sign up for [Responsible AI Dashboard in AzureML](https://forms.office.com/r/R6PmBCkyWb)\n', '\n', '## Contributing\n', '\n', 'This project welcomes contributions and suggestions.  Most contributions require you to agree to a\n', 'Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\n', 'the rights to use your contribution. For details, visit https://cla.opensource.microsoft.com.\n', '\n', 'When you submit a pull request, a CLA bot will automatically determine whether you need to provide\n', 'a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions\n', 'provided by the bot. You will only need to do this once across all repos using our CLA.\n', '\n', 'This project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\n', 'For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\n', 'contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n', '\n', '## Trademarks\n', '\n', 'This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft \n', 'trademarks or logos is subject to and must follow \n', ""[Microsoft's Trademark & Brand Guidelines](https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general).\n"", 'Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship.\n', ""Any use of third-party trademarks or logos are subject to those third-party's policies.\n""]"
Responsible+AI,understandable-machine-intelligence-lab/Quantus,understandable-machine-intelligence-lab,https://api.github.com/repos/understandable-machine-intelligence-lab/Quantus,335,51,14,"['https://api.github.com/users/annahedstroem', 'https://api.github.com/users/dkrako', 'https://api.github.com/users/dilyabareeva', 'https://api.github.com/users/aaarrti', 'https://api.github.com/users/leanderweber', 'https://api.github.com/users/3-nan', 'https://api.github.com/users/FerranPares', 'https://api.github.com/users/annariasdu', 'https://api.github.com/users/Wickstrom', 'https://api.github.com/users/rodrigobdz', 'https://api.github.com/users/sebastian-lapuschkin', 'https://api.github.com/users/vedal', 'https://api.github.com/users/p-wojciechowski', 'https://api.github.com/users/sltzgs']",Python,2023-04-06T20:13:37Z,https://raw.githubusercontent.com/understandable-machine-intelligence-lab/Quantus/main/README.md,"['<p align=""center"">\n', '  <img width=""350"" src=""https://raw.githubusercontent.com/understandable-machine-intelligence-lab/Quantus/main/quantus_logo.png"">\n', '</p>\n', '<!--<h1 align=""center""><b>Quantus</b></h1>-->\n', '<h3 align=""center""><b>A toolkit to evaluate neural network explanations</b></h3>\n', '<p align=""center"">\n', '  PyTorch and TensorFlow\n', '\n', '[![Getting started!](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/understandable-machine-intelligence-lab/Quantus/blob/main/tutorials/Tutorial_ImageNet_Example_All_Metrics.ipynb)\n', '[![Launch Tutorials](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/understandable-machine-intelligence-lab/Quantus/HEAD?labpath=tutorials)\n', '[![Python package](https://github.com/understandable-machine-intelligence-lab/Quantus/actions/workflows/python-package.yml/badge.svg)](https://github.com/understandable-machine-intelligence-lab/Quantus/actions/workflows/python-package.yml)\n', '[![Code coverage](https://github.com/understandable-machine-intelligence-lab/Quantus/actions/workflows/codecov.yml/badge.svg)](https://github.com/understandable-machine-intelligence-lab/Quantus/actions/workflows/codecov.yml)\n', '![Python version](https://img.shields.io/badge/python-3.7%20%7C%203.8%20%7C%203.9-blue.svg)\n', '[![PyPI version](https://badge.fury.io/py/quantus.svg)](https://badge.fury.io/py/quantus)\n', '[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)\n', '[![Documentation Status](https://readthedocs.org/projects/quantus/badge/?version=latest)](https://quantus.readthedocs.io/en/latest/?badge=latest)\n', '[![codecov.io](https://codecov.io/github/understandable-machine-intelligence-lab/Quantus/coverage.svg?branch=master)](https://codecov.io/github/understandable-machine-intelligence-lab/Quantus?branch=master)\n', '[![Downloads](https://static.pepy.tech/badge/quantus)](https://pepy.tech/project/quantus)\n', '\n', '_Quantus is currently under active development so carefully note the Quantus release version to ensure reproducibility of your work._\n', '\n', '[📑 Shortcut to paper!](https://jmlr.org/papers/volume24/22-0142/22-0142.pdf)\n', '        \n', '## News and Highlights! :rocket:\n', '\n', '- Accepted to Journal of Machine Learning Research (MLOSS) ([paper](https://jmlr.org/papers/v24/22-0142.html))!\n', '- Offers more than **30+ metrics in 6 categories** for XAI evaluation\n', '- Supports different data types (image, time-series, tabular, NLP next up!) and models (PyTorch, TensorFlow)\n', '- Extended built-in support for explanation methods ([captum](https://captum.ai/) and [tf-explain](https://tf-explain.readthedocs.io/en/latest/))\n', '- New optimisations to help speed up computation, see API reference [here](https://quantus.readthedocs.io/en/latest/docs_api/quantus.metrics.base_batched.html)!\n', '\n', 'See [here](https://github.com/understandable-machine-intelligence-lab/Quantus/releases) for the latest release(s).\n', '\n', '## Citation\n', '\n', 'If you find this toolkit or its companion paper\n', '[**Quantus: An Explainable AI Toolkit for Responsible Evaluation of Neural Network Explanations and Beyond**](https://jmlr.org/papers/v24/22-0142.html)\n', 'interesting or useful in your research, use the following Bibtex annotation to cite us:\n', '\n', '```bibtex\n', '@article{hedstrom2023quantus,\n', '  author  = {Anna Hedstr{\\""{o}}m and Leander Weber and Daniel Krakowczyk and Dilyara Bareeva and Franz Motzkus and Wojciech Samek and Sebastian Lapuschkin and Marina Marina M.{-}C. H{\\""{o}}hne},\n', '  title   = {Quantus: An Explainable AI Toolkit for Responsible Evaluation of Neural Network Explanations and Beyond},\n', '  journal = {Journal of Machine Learning Research},\n', '  year    = {2023},\n', '  volume  = {24},\n', '  number  = {34},\n', '  pages   = {1--11},\n', '  url     = {http://jmlr.org/papers/v24/22-0142.html}\n', '}\n', '```\n', '\n', 'When applying the individual metrics of Quantus, please make sure to also properly cite the work of the original authors (as linked below).\n', '\n', '## Table of contents\n', '\n', '* [Library overview](#library-overview)\n', '* [Installation](#installation)\n', '* [Getting started](#getting-started)\n', '* [Tutorials](#tutorials)\n', '* [Contributing](#contributing)\n', '<!--* [Citation](#citation)-->\n', '\n', '## Library overview \n', '\n', 'A simple visual comparison of eXplainable Artificial Intelligence (XAI) methods is often not sufficient to decide which explanation method works best as shown exemplarily in Figure a) for four gradient-based methods — Saliency ([Mørch et al., 1995](https://ieeexplore.ieee.org/document/488997); [Baehrens et al., 2010](https://www.jmlr.org/papers/volume11/baehrens10a/baehrens10a.pdf)), Integrated Gradients ([Sundararajan et al., 2017](http://proceedings.mlr.press/v70/sundararajan17a/sundararajan17a.pdf)), GradientShap ([Lundberg and Lee, 2017](https://arxiv.org/abs/1705.07874)) or FusionGrad ([Bykov et al., 2021](https://arxiv.org/abs/2106.10185)), yet it is a common practice for evaluation XAI methods in absence of ground truth data. Therefore, we developed Quantus, an easy-to-use yet comprehensive toolbox for quantitative evaluation of explanations — including 30+ different metrics. \n', '\n', '</p>\n', '<p align=""center"">\n', '  <img width=""800"" src=""https://raw.githubusercontent.com/understandable-machine-intelligence-lab/Quantus/main/viz.png"">\n', '</p>\n', '\n', 'With Quantus, we can obtain richer insights on how the methods compare e.g., b) by holistic quantification on several evaluation criteria and c) by providing sensitivity analysis of how a single parameter e.g. the pixel replacement strategy of a faithfulness test influences the ranking of the XAI methods.\n', ' \n', '### Metrics\n', '\n', 'This project started with the goal of collecting existing evaluation metrics that have been introduced in the context of XAI research — to help automate the task of _XAI quantification_. Along the way of implementation, it became clear that XAI metrics most often belong to one out of six categories i.e., 1) faithfulness, 2) robustness, 3) localisation 4) complexity 5) randomisation or 6) axiomatic metrics. The library contains implementations of the following evaluation metrics:\n', '\n', '<details>\n', '  <summary><b>Faithfulness</b></summary>\n', 'quantifies to what extent explanations follow the predictive behaviour of the model (asserting that more important features play a larger role in model outcomes)\n', ' <br><br>\n', '  <ul>\n', '    <li><b>Faithfulness Correlation </b><a href=""https://www.ijcai.org/Proceedings/2020/0417.pdf"">(Bhatt et al., 2020)</a>: iteratively replaces a random subset of given attributions with a baseline value and then measuring the correlation between the sum of this attribution subset and the difference in function output \n', '    <li><b>Faithfulness Estimate </b><a href=""https://arxiv.org/pdf/1806.07538.pdf"">(Alvarez-Melis et al., 2018)</a>: computes the correlation between probability drops and attribution scores on various points\n', '    <li><b>Monotonicity Metric </b><a href=""https://arxiv.org/abs/1909.03012"">(Arya et al. 2019)</a>: starts from a reference baseline to then incrementally replace each feature in a sorted attribution vector, measuring the effect on model performance\n', '    <li><b>Monotonicity Metric </b><a href=""https://arxiv.org/pdf/2007.07584.pdf""> (Nguyen et al, 2020)</a>: measures the spearman rank correlation between the absolute values of the attribution and the uncertainty in the probability estimation\n', '    <li><b>Pixel Flipping </b><a href=""https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0130140"">(Bach et al., 2015)</a>: captures the impact of perturbing pixels in descending order according to the attributed value on the classification score\n', '    <li><b>Region Perturbation </b><a href=""https://arxiv.org/pdf/1509.06321.pdf"">(Samek et al., 2015)</a>: is an extension of Pixel-Flipping to flip an area rather than a single pixel\n', '    <li><b>Selectivity </b><a href=""https://arxiv.org/pdf/1706.07979.pdf"">(Montavon et al., 2018)</a>: measures how quickly an evaluated prediction function starts to drop when removing features with the highest attributed values\n', '    <li><b>SensitivityN </b><a href=""https://arxiv.org/pdf/1711.06104.pdf"">(Ancona et al., 2019)</a>: computes the correlation between the sum of the attributions and the variation in the target output while varying the fraction of the total number of features, averaged over several test samples\n', '    <li><b>IROF </b><a href=""https://arxiv.org/pdf/2003.08747.pdf"">(Rieger at el., 2020)</a>: computes the area over the curve per class for sorted mean importances of feature segments (superpixels) as they are iteratively removed (and prediction scores are collected), averaged over several test samples\n', '    <li><b>Infidelity </b><a href=""https://arxiv.org/pdf/1901.09392.pdf"">(Chih-Kuan, Yeh, et al., 2019)</a>: represents the expected mean square error between 1) a dot product of an attribution and input perturbation and 2) difference in model output after significant perturbation \n', '    <li><b>ROAD </b><a href=""https://arxiv.org/pdf/2202.00449.pdf"">(Rong, Leemann, et al., 2022)</a>: measures the accuracy of the model on the test set in an iterative process of removing k most important pixels, at each step k most relevant pixels (MoRF order) are replaced with noisy linear imputations\n', '    <li><b>Sufficiency </b><a href=""https://arxiv.org/abs/2202.00734"">(Dasgupta et al., 2022)</a>: measures the extent to which similar explanations have the same prediction label\n', '</ul>\n', '</details>\n', '\n', '<details>\n', '<summary><b>Robustness</b></summary>\n', 'measures to what extent explanations are stable when subject to slight perturbations of the input, assuming that model output approximately stayed the same\n', '     <br><br>\n', '<ul>\n', '    <li><b>Local Lipschitz Estimate </b><a href=""https://arxiv.org/pdf/1806.08049.pdf"">(Alvarez-Melis et al., 2018)</a>: tests the consistency in the explanation between adjacent examples\n', '    <li><b>Max-Sensitivity </b><a href=""https://arxiv.org/pdf/1901.09392.pdf"">(Yeh et al., 2019)</a>: measures the maximum sensitivity of an explanation using a Monte Carlo sampling-based approximation\n', '    <li><b>Avg-Sensitivity </b><a href=""https://arxiv.org/pdf/1901.09392.pdf"">(Yeh et al., 2019)</a>: measures the average sensitivity of an explanation using a Monte Carlo sampling-based approximation\n', '    <li><b>Continuity </b><a href=""https://arxiv.org/pdf/1706.07979.pdf"">(Montavon et al., 2018)</a>: captures the strongest variation in explanation of an input and its perturbed version\n', '    <li><b>Consistency </b><a href=""https://arxiv.org/abs/2202.00734"">(Dasgupta et al., 2022)</a>: measures the probability that the inputs with the same explanation have the same prediction label\n', '    <li><b>Relative Input Stability (RIS)</b><a href=""https://arxiv.org/pdf/2203.06877.pdf""> (Agarwal, et. al., 2022)</a>: measures the relative distance between explanations e_x and e_x\' with respect to the distance between the two inputs x and x\'\n', '    <li><b>Relative Representation Stability (RRS)</b><a href=""https://arxiv.org/pdf/2203.06877.pdf""> (Agarwal, et. al., 2022)</a>: measures the relative distance between explanations e_x and e_x\' with respect to the distance between internal models representations L_x and L_x\' for x and x\' respectively\n', '    <li><b>Relative Output Stability (ROS)</b><a href=""https://arxiv.org/pdf/2203.06877.pdf""> (Agarwal, et. al., 2022)</a>: measures the relative distance between explanations e_x and e_x\' with respect to the distance between output logits h(x) and h(x\') for x and x\' respectively\n', '</ul>\n', '</details>\n', '\n', '<details>\n', '<summary><b>Localisation</b></summary>\n', 'tests if the explainable evidence is centred around a region of interest (RoI) which may be defined around an object by a bounding box, a segmentation mask or, a cell within a grid\n', '     <br><br>\n', '<ul>\n', '    <li><b>Pointing Game </b><a href=""https://arxiv.org/abs/1608.00507"">(Zhang et al., 2018)</a>: checks whether attribution with the highest score is located within the targeted object\n', '    <li><b>Attribution Localization </b><a href=""https://arxiv.org/abs/1910.09840"">(Kohlbrenner et al., 2020)</a>: measures the ratio of positive attributions within the targeted object towards the total positive attributions\n', '    <li><b>Top-K Intersection </b><a href=""https://arxiv.org/abs/2104.14995"">(Theiner et al., 2021)</a>: computes the intersection between a ground truth mask and the binarized explanation at the top k feature locations\n', '    <li><b>Relevance Rank Accuracy </b><a href=""https://arxiv.org/abs/2003.07258"">(Arras et al., 2021)</a>: measures the ratio of highly attributed pixels within a ground-truth mask towards the size of the ground truth mask\n', '    <li><b>Relevance Mass Accuracy </b><a href=""https://arxiv.org/abs/2003.07258"">(Arras et al., 2021)</a>: measures the ratio of positively attributed attributions inside the ground-truth mask towards the overall positive attributions\n', '    <li><b>AUC </b><a href=""https://doi.org/10.1016/j.patrec.2005.10.010"">(Fawcett et al., 2006)</a>: compares the ranking between attributions and a given ground-truth mask\n', '    <li><b>Focus </b><a href=""https://arxiv.org/abs/2109.15035"">(Arias et al., 2022)</a>: quantifies the precision of the explanation by creating mosaics of data instances from different classes\n', '</ul>\n', '</details>\n', '\n', '<details>\n', '<summary><b>Complexity</b></summary>\n', 'captures to what extent explanations are concise i.e., that few features are used to explain a model prediction\n', '     <br><br>\n', '<ul>\n', '    <li><b>Sparseness </b><a href=""https://arxiv.org/abs/1810.06583"">(Chalasani et al., 2020)</a>: uses the Gini Index for measuring, if only highly attributed features are truly predictive of the model output\n', '    <li><b>Complexity </b><a href=""https://arxiv.org/abs/2005.00631"">(Bhatt et al., 2020)</a>: computes the entropy of the fractional contribution of all features to the total magnitude of the attribution individually\n', '    <li><b>Effective Complexity </b><a href=""https://arxiv.org/abs/2007.07584"">(Nguyen at el., 2020)</a>: measures how many attributions in absolute values are exceeding a certain threshold\n', '</ul>\n', '</details>\n', '\n', '<details>\n', '<summary><b>Randomisation</b></summary>\n', 'tests to what extent explanations deteriorate as inputs to the evaluation problem e.g., model parameters are increasingly randomised\n', '     <br><br>\n', '<ul>\n', '    <li><b>Model Parameter Randomisation </b><a href=""https://arxiv.org/abs/1810.03292"">(Adebayo et. al., 2018)</a>: randomises the parameters of single model layers in a cascading or independent way and measures the distance of the respective explanation to the original explanation\n', '    <li><b>Random Logit Test </b><a href=""https://arxiv.org/abs/1912.09818"">(Sixt et al., 2020)</a>: computes for the distance between the original explanation and the explanation for a random other class\n', '</ul>\n', '</details>\n', '\n', '<details>\n', '<summary><b>Axiomatic</b></summary>\n', '  assesses if explanations fulfil certain axiomatic properties\n', '     <br><br>\n', '<ul>\n', '    <li><b>Completeness </b><a href=""https://arxiv.org/abs/1703.01365"">(Sundararajan et al., 2017)</a>: evaluates whether the sum of attributions is equal to the difference between the function values at the input x and baseline x\' (and referred to as Summation to Delta (Shrikumar et al., 2017), Sensitivity-n (slight variation, Ancona et al., 2018) and Conservation (Montavon et al., 2018))\n', '    <li><b>Non-Sensitivity </b><a href=""https://arxiv.org/abs/2007.07584"">(Nguyen at el., 2020)</a>: measures whether the total attribution is proportional to the explainable evidence at the model output\n', '    <li><b>Input Invariance </b><a href=""https://arxiv.org/abs/1711.00867"">(Kindermans et al., 2017)</a>: adds a shift to input, asking that attributions should not change in response (assuming the model does not)\n', '</ul>\n', '</details>\n', '\n', 'Additional metrics will be included in future releases. Please [open an issue](https://github.com/understandable-machine-intelligence-lab/Quantus/issues/new/choose) if you have a metric you believe should be apart of Quantus.\n', '\n', '**Disclaimers.** It is worth noting that the implementations of the metrics in this library have not been verified by the original authors. Thus any metric implementation in this library may differ from the original authors. Further, bear in mind that evaluation metrics for XAI methods are often empirical interpretations (or translations) of qualities that some researcher(s) claimed were important for explanations to fulfil, so it may be a discrepancy between what the author claims to measure by the proposed metric and what is actually measured e.g., using entropy as an operationalisation of explanation complexity. Please read the [user guidelines](https://quantus.readthedocs.io/en/latest/guidelines/guidelines_and_disclaimers.html) for further guidance on how to best use the library. \n', '\n', '## Installation\n', '\n', 'If you already have [PyTorch](https://pytorch.org/) or [TensorFlow](https://www.TensorFlow.org) installed on your machine, \n', 'the most light-weight version of Quantus can be obtained from [PyPI](https://pypi.org/project/quantus/) as follows (no additional explainability functionality or deep learning framework will be included):\n', '\n', '```setup\n', 'pip install quantus\n', '```\n', 'Alternatively, you can simply add the desired deep learning framework (in brackets) to have the package installed together with Quantus.\n', 'To install Quantus with PyTorch, please run:\n', '```setup\n', 'pip install ""quantus[torch]""\n', '```\n', '\n', 'For TensorFlow, please run:\n', '\n', '```setup\n', 'pip install ""quantus[tensorflow]""\n', '```\n', '\n', 'Alternatively, you can simply install Quantus with [requirements.txt](https://github.com/understandable-machine-intelligence-lab/Quantus/blob/main/requirements.txt).\n', 'Note that this installation requires that either [PyTorch](https://pytorch.org/) or [TensorFlow](https://www.TensorFlow.org) are already installed on your machine.\n', '\n', '```setup\n', 'pip install -r requirements.txt\n', '```\n', '\n', 'For a more in-depth guide on how to install Quantus, please read more [here](https://quantus.readthedocs.io/en/latest/getting_started/installation.html). This includes instructions for how to install a desired deep learning framework such as PyTorch or TensorFlow together with Quantus.\n', '\n', '### Package requirements\n', '\n', 'The package requirements are as follows:\n', '```\n', 'python>=3.7.0\n', 'pytorch>=1.10.1\n', 'TensorFlow==2.6.2\n', '```\n', '\n', '## Getting started\n', '\n', 'The following will give a short introduction to how to get started with Quantus. Note that this example is based on the [PyTorch](https://pytorch.org/) framework, but we also support \n', '[TensorFlow](https://www.tensorflow.org), which would differ only in the loading of the model, data and explanations. To get started with Quantus, you need:\n', '* A model (`model`), inputs (`x_batch`) and labels (`y_batch`)\n', '* Some explanations you want to evaluate (`a_batch`)\n', '\n', '\n', '<details>\n', '<summary><b><big>Step 1. Load data and model</big></b></summary>\n', '\n', ""Let's first load the data and model. In this example, a pre-trained LeNet available from Quantus \n"", ""for the purpose of this tutorial is loaded, but generally, you might use any Pytorch (or TensorFlow) model instead. To follow this example, one needs to have quantus and torch installed, by e.g., `pip install 'quantus[torch]'`.\n"", '\n', '```python\n', 'import quantus\n', 'from quantus.helpers.model.models import LeNet\n', 'import torch\n', 'import torchvision\n', 'from torchvision import transforms\n', '  \n', '# Enable GPU.\n', 'device = torch.device(""cuda:0"" if torch.cuda.is_available() else ""cpu"")\n', '\n', '# Load a pre-trained LeNet classification model (architecture at quantus/helpers/models).\n', 'model = LeNet()\n', 'if device.type == ""cpu"":\n', '    model.load_state_dict(torch.load(""tests/assets/mnist"", map_location=torch.device(\'cpu\')))\n', 'else: \n', '    model.load_state_dict(torch.load(""tests/assets/mnist""))\n', '\n', '# Load datasets and make loaders.\n', ""test_set = torchvision.datasets.MNIST(root='./sample_data', download=True, transforms=transforms.Compose([transforms.ToTensor()]))\n"", 'test_loader = torch.utils.data.DataLoader(test_set, batch_size=24)\n', '\n', '# Load a batch of inputs and outputs to use for XAI evaluation.\n', 'x_batch, y_batch = iter(test_loader).next()\n', 'x_batch, y_batch = x_batch.cpu().numpy(), y_batch.cpu().numpy()\n', '```\n', '</details>\n', '\n', '<details>\n', '<summary><b><big>Step 2. Load explanations</big></b></summary>\n', '\n', 'We still need some explanations to evaluate. \n', 'For this, there are two possibilities in Quantus. You can provide either:\n', '1. a set of re-computed attributions (`np.ndarray`)\n', '2. any arbitrary explanation function (`callable`), e.g., the built-in method `quantus.explain` or your own customised function\n', '\n', 'We show the different options below.\n', '\n', '#### Using pre-computed explanations\n', '\n', 'Quantus allows you to evaluate explanations that you have pre-computed, \n', ""assuming that they match the data you provide in `x_batch`. Let's say you have explanations \n"", 'for [Saliency](https://arxiv.org/abs/1312.6034) and [Integrated Gradients](https://arxiv.org/abs/1703.01365)\n', 'already pre-computed.\n', '\n', 'In that case, you can simply load these into corresponding variables `a_batch_saliency` \n', 'and `a_batch_intgrad`:\n', '\n', '```python\n', 'a_batch_saliency = load(""path/to/precomputed/saliency/explanations"")\n', 'a_batch_saliency = load(""path/to/precomputed/intgrad/explanations"")\n', '```\n', '\n', 'Another option is to simply obtain the attributions using one of many XAI frameworks out there, \n', 'such as [Captum](https://captum.ai/), \n', '[Zennit](https://github.com/chr5tphr/zennit), \n', '[tf.explain](https://github.com/sicara/tf-explain),\n', 'or [iNNvestigate](https://github.com/albermax/innvestigate). The following code example shows how to obtain explanations ([Saliency](https://arxiv.org/abs/1312.6034) \n', 'and [Integrated Gradients](https://arxiv.org/abs/1703.01365), to be specific) \n', 'using [Captum](https://captum.ai/):\n', '\n', '```python\n', 'import captum\n', 'from captum.attr import Saliency, IntegratedGradients\n', '\n', '# Generate Integrated Gradients attributions of the first batch of the test set.\n', 'a_batch_saliency = Saliency(model).attribute(inputs=x_batch, target=y_batch, abs=True).sum(axis=1).cpu().numpy()\n', 'a_batch_intgrad = IntegratedGradients(model).attribute(inputs=x_batch, target=y_batch, baselines=torch.zeros_like(x_batch)).sum(axis=1).cpu().numpy()\n', '\n', '# Save x_batch and y_batch as numpy arrays that will be used to call metric instances.\n', 'x_batch, y_batch = x_batch.cpu().numpy(), y_batch.cpu().numpy()\n', '\n', '# Quick assert.\n', 'assert [isinstance(obj, np.ndarray) for obj in [x_batch, y_batch, a_batch_saliency, a_batch_intgrad]]\n', '```\n', '\n', '#### Passing an explanation function\n', '\n', ""If you don't have a pre-computed set of explanations but rather want to pass an arbitrary explanation function \n"", 'that you wish to evaluate with Quantus, this option exists. \n', '\n', 'For this, you can for example rely on the built-in `quantus.explain` function to get started, which includes some popular explanation methods \n', '(please run `quantus.available_methods()` to see which ones).  Examples of how to use `quantus.explain` \n', 'or your own customised explanation function are included in the next section.\n', '\n', '<img class=""center"" width=""500"" alt=""drawing""  src=""tutorials/assets/mnist_example.png""/>\n', '\n', 'As seen in the above image, the qualitative aspects of explanations \n', 'may look fairly uninterpretable --- since we lack ground truth of what the explanations\n', 'should be looking like, it is hard to draw conclusions about the explainable evidence. To gather quantitative evidence for the quality of the different explanation methods, we can apply Quantus.\n', '</details>\n', '\n', '<details>\n', '<summary><b><big>Step 3. Evaluate with Quantus</big></b></summary> \n', '\n', 'Quantus implements XAI evaluation metrics from different categories, \n', 'e.g., Faithfulness, Localisation and Robustness etc which all inherit from the base `quantus.Metric` class. \n', 'To apply a metric to your setting (e.g., [Max-Sensitivity](https://arxiv.org/abs/1901.09392)) \n', 'it first needs to be instantiated:\n', '\n', '```python\n', 'metric = quantus.MaxSensitivity(nr_samples=10,\n', '                                lower_bound=0.2,\n', '                                norm_numerator=quantus.fro_norm,\n', '                                norm_denominator=quantus.fro_norm,\n', '                                perturb_func=quantus.uniform_noise,\n', '                                similarity_func=quantus.difference)\n', '```\n', '\n', 'and then applied to your model, data, and (pre-computed) explanations:\n', '\n', '```python\n', 'scores = metric(\n', '    model=model,\n', '    x_batch=x_batch,\n', '    y_batch=y_batch,\n', '    a_batch=a_batch_saliency,\n', '    device=device\n', ')\n', '```\n', '\n', '#### Use quantus.explain\n', '\n', 'Alternatively, instead of providing pre-computed explanations, you can employ the `quantus.explain` function,\n', 'which can be specified through a dictionary passed to `explain_func_kwargs`.\n', '\n', '```python\n', 'scores = metric(\n', '    model=model,\n', '    x_batch=x_batch,\n', '    y_batch=y_batch,\n', '    device=device,\n', '    explain_func=quantus.explain,\n', '    explain_func_kwargs={""method"": ""Saliency""}\n', ')\n', '```\n', '\n', '#### Employ customised functions\n', '\n', 'You can alternatively use your own customised explanation function\n', '(assuming it returns an `np.ndarray` in a shape that matches the input `x_batch`). This is done as follows:\n', '\n', '```python\n', 'def your_own_callable(model, models, targets, **kwargs) -> np.ndarray\n', '  """"""Logic goes here to compute the attributions and return an \n', '  explanation  in the same shape as x_batch (np.array), \n', '  (flatten channels if necessary).""""""\n', '  return explanation(model, x_batch, y_batch)\n', '\n', 'scores = metric(\n', '    model=model,\n', '    x_batch=x_batch,\n', '    y_batch=y_batch,\n', '    device=device,\n', '    explain_func=your_own_callable\n', ')\n', '```\n', '#### Run large-scale evaluation\n', '\n', 'Quantus also provides high-level functionality to support large-scale evaluations,\n', 'e.g., multiple XAI methods, multifaceted evaluation through several metrics, or a combination thereof. To utilise `quantus.evaluate()`, you simply need to define two things:\n', '\n', '1. The **Metrics** you would like to use for evaluation (each `__init__` parameter configuration counts as its own metric):\n', '    ```python\n', '    metrics = {\n', '        ""max-sensitivity-10"": quantus.MaxSensitivity(nr_samples=10),\n', '        ""max-sensitivity-20"": quantus.MaxSensitivity(nr_samples=20),\n', '        ""region-perturbation"": quantus.RegionPerturbation(),\n', '    }\n', '    ```\n', '   \n', '2. The **XAI methods** you would like to evaluate, e.g., a `dict` with pre-computed attributions:\n', '    ```python\n', '    xai_methods = {\n', '        ""Saliency"": a_batch_saliency,\n', '        ""IntegratedGradients"": a_batch_intgrad\n', '    }\n', '    ```\n', '\n', 'You can then simply run a large-scale evaluation as follows (this aggregates the result by `np.mean` averaging):\n', '\n', '```python\n', 'import numpy as np\n', 'results = quantus.evaluate(\n', '      metrics=metrics,\n', '      xai_methods=xai_methods,\n', '      agg_func=np.mean,\n', '      model=model,\n', '      x_batch=x_batch,\n', '      y_batch=y_batch,\n', '      **{""softmax"": False,}\n', ')\n', '```\n', '</details>\n', '\n', 'Please see [\n', ""Getting started tutorial](https://github.com/understandable-machine-intelligence-lab/quantus/blob/main/tutorials/Tutorial_Getting_Started.ipynb) to run code similar to this example. For more information on how to customise metrics and extend Quantus' functionality, please see [Getting started guide](https://quantus.readthedocs.io/en/latest/getting_started/getting_started_example.html).\n"", '\n', '\n', '## Tutorials\n', '\n', 'Further tutorials are available that showcase the many types of analysis that can be done using Quantus.\n', 'For this purpose, please see notebooks in the [tutorials](https://github.com/understandable-machine-intelligence-lab/Quantus/blob/main/tutorials/) folder which includes examples such as:\n', '* [All Metrics ImageNet Example](https://github.com/understandable-machine-intelligence-lab/Quantus/blob/main/tutorials/Tutorial_ImageNet_Example_All_Metrics.ipynb): shows how to instantiate the different metrics for ImageNet dataset\n', '* [Metric Parameterisation Analysis](https://github.com/understandable-machine-intelligence-lab/Quantus/blob/main/tutorials/Tutorial_Metric_Parameterisation_Analysis.ipynb): explores how sensitive a metric could be to its hyperparameters\n', '* [Robustness Analysis Model Training](https://github.com/understandable-machine-intelligence-lab/Quantus/blob/main/tutorials/Tutorial_XAI_Sensitivity_Model_Training.ipynb): measures robustness of explanations as model accuracy increases \n', '* [Full Quantification with Quantus](https://github.com/understandable-machine-intelligence-lab/Quantus/blob/main/tutorials/Tutorial_ImageNet_Quantification_with_Quantus.ipynb): example of benchmarking explanation methods\n', '* [Tabular Data Example](https://github.com/understandable-machine-intelligence-lab/Quantus/blob/main/tutorials/Tutorial_Getting_Started_with_Tabular_Data.ipynb): example of how to use Quantus with tabular data\n', '* [Quantus and TensorFlow Data Example](https://github.com/understandable-machine-intelligence-lab/Quantus/blob/main/tutorials/Tutorial_Getting_Started_with_Tensorflow.ipynb): showcases how to use Quantus with TensorFlow\n', '\n', '... and more.\n', '\n', '## Contributing\n', '\n', 'We welcome any sort of contribution to Quantus! For a detailed contribution guide, please refer to [Contributing](https://github.com/understandable-machine-intelligence-lab/Quantus/blob/main/CONTRIBUTING.md) documentation first. \n', '\n', 'If you have any developer-related questions, please [open an issue](https://github.com/understandable-machine-intelligence-lab/Quantus/issues/new/choose)\n', 'or write us at [hedstroem.anna@gmail.com](mailto:hedstroem.anna@gmail.com).\n']"
Responsible+AI,mit-ll-responsible-ai/responsible-ai-toolbox,mit-ll-responsible-ai,https://api.github.com/repos/mit-ll-responsible-ai/responsible-ai-toolbox,29,5,6,"['https://api.github.com/users/rsokl', 'https://api.github.com/users/jgbos', 'https://api.github.com/users/dependabot%5Bbot%5D', 'https://api.github.com/users/oliviamb', 'https://api.github.com/users/miscpeeps', 'https://api.github.com/users/Jasha10']",Python,2023-03-27T09:39:13Z,https://raw.githubusercontent.com/mit-ll-responsible-ai/responsible-ai-toolbox/main/README.md,"['# Responsible AI Toolbox\n', '\n', '<p align=""center"">\n', '  <img width=""200"" height=""200"" src=""brand/logo_no_text_small.png"">\n', '</p>\n', '\n', '<p align=""center"">\n', '  <a href=""https://pypi.org/project/rai-toolbox/"">\n', '    <img src=""https://img.shields.io/pypi/v/rai-toolbox.svg"" alt=""PyPI"" />\n', '  </a>\n', '  <a>\n', '    <img src=""https://img.shields.io/badge/python-3.7%20&#8208;%203.10-blue.svg"" alt=""Python version support"" />\n', '  </a>\n', '  <a href=""https://github.com/mit-ll-responsible-ai/responsible-ai-toolbox/actions?query=workflow%3ATests+branch%3Amain"">\n', '    <img src=""https://github.com/mit-ll-responsible-ai/responsible-ai-toolbox/workflows/Tests/badge.svg"" alt=""GitHub Actions"" />\n', '  <a href=""https://hypothesis.readthedocs.io/"">\n', '    <img src=""https://img.shields.io/badge/hypothesis-tested-brightgreen.svg"" alt=""Tested with Hypothesis"" />\n', '  </a>\n', '\n', '  <p align=""center"">\n', '    A library that provides high-quality, PyTorch-centric tools for evaluating and enhancing both the robustness and the explainability of AI models.\n', '  </p>\n', '  <p align=""center"">\n', '    Check out our <a href=""https://mit-ll-responsible-ai.github.io/responsible-ai-toolbox/"">documentation</a> for more information.\n', '  </p>\n', '  <p align=""center"">\n', '    The rAI-toolbox works great with <a href=""https://www.pytorchlightning.ai/"">PyTorch Lightning</a> ⚡ and <a href=""https://hydra.cc/"">Hydra</a> 🐉. Check out <a href=""https://mit-ll-responsible-ai.github.io/responsible-ai-toolbox/ref_mushin.html"">rai_toolbox.mushin</a> to see how we use these frameworks to create efficient, configurable, and reproducible ML workflows with minimal boilerplate code.\n', '  </p>\n', '</p>\n', '\n', '\n', '\n', '## Citation\n', '\n', 'Using `rai_toolbox` for your research? Please cite the following publication:\n', '\n', '```\n', '@article{soklaski2022tools,\n', '  title={Tools and Practices for Responsible AI Engineering},\n', '  author={Soklaski, Ryan and Goodwin, Justin and Brown, Olivia and Yee, Michael and Matterer, Jason},\n', '  journal={arXiv preprint arXiv:2201.05647},\n', '  year={2022}\n', '}\n', '```\n', '\n', '\n', '## Contributing\n', '\n', 'If you would like to contribute to this repo, please refer to our `CONTRIBUTING.md` document.\n', '\n', '\n', '\n', '## Disclaimer\n', '\n', 'DISTRIBUTION STATEMENT A. Approved for public release. Distribution is unlimited.\n', '\n', '© 2023 MASSACHUSETTS INSTITUTE OF TECHNOLOGY\n', '\n', '- Subject to FAR 52.227-11 – Patent Rights – Ownership by the Contractor (May 2014)\n', '- SPDX-License-Identifier: MIT\n', '\n', 'This material is based upon work supported by the Under Secretary of Defense for Research and Engineering under Air Force Contract No. FA8702-15-D-0001. Any opinions, findings, conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the Under Secretary of Defense for Research and Engineering.\n', '\n', 'A portion of this research was sponsored by the United States Air Force Research Laboratory and the United States Air Force Artificial Intelligence Accelerator and was accomplished under Cooperative Agreement Number FA8750-19-2-1000. The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies, either expressed or implied, of the United States Air Force or the U.S. Government. The U.S. Government is authorized to reproduce and distribute reprints for Government purposes notwithstanding any copyright notation herein.\n', '\n', 'The software/firmware is provided to you on an As-Is basis.\n']"
Responsible+AI,microsoft/responsible-ai-workshop,microsoft,https://api.github.com/repos/microsoft/responsible-ai-workshop,13,6,5,"['https://api.github.com/users/philber', 'https://api.github.com/users/microsoftopensource', 'https://api.github.com/users/RiadEtm', 'https://api.github.com/users/alazraq', 'https://api.github.com/users/microsoft-github-operations%5Bbot%5D']",Python,2023-02-16T03:28:31Z,https://raw.githubusercontent.com/microsoft/responsible-ai-workshop/main/README.md,"['\n', '# Responsible AI Workshop\n', '![Workshop logo](https://github.com/microsoft/responsible-ai-workshop/blob/main/rai-ws-banner.png)\n', '\n', 'Responsible innovation is top of mind. As such, the tech industry as well as a growing number of organizations of all kinds in their digital transformation are being called upon to develop and deploy Artificial Intelligence (AI) technologies and Machine Learning (ML)-powered systems (products or services) and/or features (all referred as to AI systems below) more responsibly. And yet many organizations implementing such AI systems report being unprepared to address AI risks and failures, and struggle with new challenges in terms of governance, security and compliance.\n', '\n', 'Advancements in AI are indeed different than other technologies because of the pace of innovation. There has been hundreds of research papers published every year in the past few years -, but also because of its proximity to human intelligence, impacting us at a personal and societal level.\n', '\n', ""There are a number of challenges and questions raised through the use of AI technologies. We refer to these as socio-technical impacts. All of these have given rise to an industry debate about how the world should/shouldn't use these new capabilities. It isn't because you can do something that you should necessarily do it. \n"", '\n', 'This project is an attempt to introduce and illustrate the use of: \n', '* Resources designed to help you responsibly use AI at every stage of innovation - from concept to development, deployment, and beyond. \n', '* Available toolkits & frameworks that help you integrate relevant Responsible AI features into your AI environment by themes and through the lifecycle stages of your AI system.\n', '* Activities to strengthen gradually the confidence that we can have in this technology and therefore facilitate its adoption in contexts where it would have a great responsibility.\n', '\n', 'It is thus designed to help you or your ""customers"", whoever they are, to put Responsible AI into practice for your AI-powered solutions throughout their lifecycle.\n', '\n', '# Workshop Tutorials/Walkthroughs\n', '\n', '## Work in Progress\n', '\n', 'This project is a work in progress (WIP).\n', '\n', 'This project currently contains the following tutorials:\n', '* [Responsible AI Tooling Tutorials](https://github.com/microsoft/responsible-ai-workshop/tree/master/tooling-tutorials)\n', '* [End-to-End Responsible AI Lifecycle Walkthrough](https://github.com/microsoft/responsible-ai-workshop/tree/main/lifecycle-walkthrough)\n', '* [Towards a (more) trustworthy AI lifecycle](https://github.com/microsoft/responsible-ai-workshop/tree/main/trustworthy-ai-lifecycle)\n', '\n', 'Each of the above tutorials consists of a series of modules for data engineers, data scientists, ML developers, ML engineers, and other AI practitioners, as well as potentially anyone interested considering the wide range of socio-technical aspects involved in the subject.\n', '\n', '## Prerequisites\n', '\n', 'The workshop is meant to be hands-on. Therefore, basic knowledge of any version of Python is a prerequisite. It also assumes that you have prior experience training machine learning (ML) models with Python using open-source frameworks like Scikit-Learn, PyTorch, and TensorFlow.\n', '\n', 'One should also note that this workshop might also be introduced by the following [Microsoft Learn](https://docs.microsoft.com/en-us/learn/) learning paths:\n', '* [Discover ways to foster an AI-ready culture in your business](https://docs.microsoft.com/en-us/learn/paths/foster-ai-ready-culture/).\n', '* [Identify principles and practices for responsible AI](https://docs.microsoft.com/en-us/learn/paths/responsible-ai-business-principles/).\n', '* [Identify guiding principles for responsible AI in government](https://docs.microsoft.com/en-us/learn/paths/responsible-ai-government-principles/).\n', '\n', '## Additional resources\n', '\n', 'From holistically transforming industries to addressing critical issues facing humanity, AI is already solving some of our most complex challenges and redefining how humans and technology interact. \n', '\n', 'You can read the publicly shared [Microsoft Responsible AI Standard](https://blogs.microsoft.com/wp-content/uploads/prod/sites/5/2022/06/Microsoft-Responsible-AI-Standard-v2-General-Requirements-3.pdf), i.e., a framework to guide how Microsoft build AI systems. It is an important step in our journey to develop better, more trustworthy AI systems. We are releasing our latest Responsible AI Standard to share what we have learned, invite feedback from others, and contribute to the discussion about building better norms and practices around AI. \n', '\n', 'For those wanting to dig into our approach further, we have also made available some key resources that support the Responsible AI Standard: notably our [Impact Assessment template](https://blogs.microsoft.com/wp-content/uploads/prod/sites/5/2022/06/Microsoft-RAI-Impact-Assessment-Template.pdf) and [guide](https://blogs.microsoft.com/wp-content/uploads/prod/sites/5/2022/06/Microsoft-RAI-Impact-Assessment-Guide.pdf). Impact Assessments have proven valuable at Microsoft to ensure teams explore the impact of their AI system – including its stakeholders, intended benefits, and potential harms – in depth at the earliest design stages. \n', '\n', 'In addition, you can also visit our [Responsible AI resource center](https://www.microsoft.com/en-us/ai/responsible-ai) where you can find access to tools, guidelines, and additional resources that will help you create a (more) Responsible AI solution:\n', '* [Put Responsible AI into Practice webinar](https://info.microsoft.com/ww-put-responsible-ai-into-practice-On-Demand-Registration.html) (On Demand).\n', '* [Ten Guidelines for Product Leaders to implement AI Responsibly](https://aka.ms/RAITenGuidelines).\n', '* [Establish a responsible AI strategy](https://aka.ms/AIBS).\n', '* [Design, build, and manage your AI-powered solution](http://aka.ms/RAIresources).\n', '  \n', '\n', '# Contributing\n', '\n', 'This project welcomes contributions and suggestions.  Most contributions require you to agree to a\n', 'Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\n', 'the rights to use your contribution. For details, visit https://cla.opensource.microsoft.com.\n', '\n', 'When you submit a pull request, a CLA bot will automatically determine whether you need to provide\n', 'a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions\n', 'provided by the bot. You will only need to do this once across all repos using our CLA.\n', '\n', 'This project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\n', 'For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\n', 'contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n', '\n', '# Legal Notices\n', '\n', 'Microsoft and any contributors grant you a license to the Microsoft documentation and other content\n', 'in this repository under the [Creative Commons Attribution 4.0 International Public License](https://creativecommons.org/licenses/by/4.0/legalcode),\n', 'see the [LICENSE](LICENSE) file, and grant you a license to any code in the repository under the [MIT License](https://opensource.org/licenses/MIT), see the\n', '[LICENSE-CODE](LICENSE-CODE) file.\n', '\n', 'Microsoft, Windows, Microsoft Azure and/or other Microsoft products and services referenced in the documentation\n', 'may be either trademarks or registered trademarks of Microsoft in the United States and/or other countries.\n', 'The licenses for this project do not grant you rights to use any Microsoft names, logos, or trademarks.\n', ""Microsoft's general trademark guidelines can be found at http://go.microsoft.com/fwlink/?LinkID=254653.\n"", '\n', 'Privacy information can be found at https://privacy.microsoft.com/en-us/\n', '\n', 'Microsoft and any contributors reserve all other rights, whether under their respective copyrights, patents,\n', 'or trademarks, whether by implication, estoppel or otherwise.\n']"
Responsible+AI,jphall663/responsible_xai,jphall663,https://api.github.com/repos/jphall663/responsible_xai,17,6,1,['https://api.github.com/users/jphall663'],Python,2023-03-04T01:58:48Z,https://raw.githubusercontent.com/jphall663/responsible_xai/master/README.md,"['# responsible_xai\n', 'Guidelines for the responsible use of explainable AI and machine learning. See [responsible_xai.pdf](responsible_xai.pdf).\n', '\n', 'A static version of this document, that may not reflect recent changes, is available on [arXiv](https://arxiv.org/abs/1906.03533).\n', '\n', 'For associated slides see: https://github.com/jphall663/hc_ml.\n']"
Responsible+AI,AthenaCore/AwesomeResponsibleAI,AthenaCore,https://api.github.com/repos/AthenaCore/AwesomeResponsibleAI,11,5,2,"['https://api.github.com/users/josepcurto', 'https://api.github.com/users/mariolopezdeavila']",,2023-04-02T22:18:58Z,https://raw.githubusercontent.com/AthenaCore/AwesomeResponsibleAI/main/README.md,"['[![Awesome](awesome.svg)](https://github.com/AthenaCore/AwesomeResponsibleAI)\n', '[![Maintenance](https://img.shields.io/badge/Maintained%3F-YES-green.svg)](https://github.com/AthenaCore/AwesomeResponsibleAI/graphs/commit-activity)\n', '![GitHub](https://img.shields.io/badge/Release-PROD-yellow.svg)\n', '![GitHub](https://img.shields.io/badge/Languages-MULTI-blue.svg)\n', '![GitHub](https://img.shields.io/badge/License-MIT-lightgrey.svg)\n', '[![GitHub](https://img.shields.io/twitter/follow/athenacoreai.svg?label=Follow)](https://twitter.com/athenacoreai)\n', '\n', '# Awesome Responsible AI\n', 'A curated list of awesome academic research, books, code of ethics, newsletters, principles, podcast, reports, tools and regulations related to Responsible AI and Human-Centered AI.\n', '\n', '## Contents\n', '\n', '- [Academic Research](#academic-research)\n', '- [Books](#books)\n', '- [Code of Ethics](#code-of-ethics)\n', '- [Data Sets](#data-sets)\n', '- [Institutes](#institutes)\n', '- [Newsletters](#newsletters)\n', '- [Principles](#principles)\n', '- [Podcasts](#podcasts)\n', '- [Reports](#reports)\n', '- [Tools](#tools)\n', '- [Regulations](#regulations)\n', '\n', '## Academic Research\n', '\n', '### Bias\n', '\n', '- Towards a Standard for Identifying and Managing Bias in Artificial Intelligence ([Schwartz, Reva et al., 2022]()) `NIST`\n', '\n', '### Challenges\n', '\n', ""- Underspecification presents challenges for credibility in modern machine learning. ([D'AMOUR, Alexander, et al., 2020](https://arxiv.org/abs/2011.03395)) `Google`\n"", '\n', '### Drift\n', '\n', '- FreaAI: Automated extraction of data slices to test machine learning models ([Ackerman, S. et al. 2021](https://arxiv.org/pdf/2108.05620.pdf)) `IBM`\n', '- Machine Learning Model Drift Detection Via Weak Data Slices ([Ackerman, S. et al. 2021](https://arxiv.org/pdf/2108.05319.pdf)) `IBM`\n', '\n', '### Explainability\n', '\n', '- Efficient Data Representation by Selecting Prototypes with Importance Weights ([Gurumoorthy et al., 2019](https://arxiv.org/abs/1707.01212)) `Amazon Development Center` `IBM Research`\n', '- Explanations based on the Missing: Towards Contrastive Explanations with Pertinent Negatives ([Dhurandhar et al., 2018](https://papers.nips.cc/paper/7340-explanations-based-on-the-missing-towards-contrastive-explanations-with-pertinent-negatives)) `University of Michigan` `IBM Research`\n', '- Contrastive Explanations Method with Monotonic Attribute Functions ([Luss et al., 2019](https://arxiv.org/abs/1905.12698))\n', '- ""Why Should I Trust You?"": Explaining the Predictions of Any Classifier (LIME) ([Ribeiro et al. 2016](https://arxiv.org/abs/1602.04938),  [Github](https://github.com/marcotcr/lime)) `University of Washington`\n', '- A Unified Approach to Interpreting Model Predictions (SHAP) ([Lundberg, et al. 2017](http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions),  [Github](https://github.com/slundberg/shap)) `University of Washington`\n', '- Teaching AI to Explain its Decisions ([Hind et al., 2019](https://doi.org/10.1145/3306618.3314273)) `IBM Research`\n', '- Boolean Decision Rules via Column Generation (Light Edition) ([Dash et al., 2018](https://papers.nips.cc/paper/7716-boolean-decision-rules-via-column-generation)) `IBM Research`\n', '- Generalized Linear Rule Models ([Wei et al., 2019](http://proceedings.mlr.press/v97/wei19a.html)) `IBM Research`\n', '- Improving Simple Models with Confidence Profiles ([Dhurandhar et al., 2018](https://papers.nips.cc/paper/8231-improving-simple-models-with-confidence-profiles)) `IBM Research`\n', '- Towards Robust Interpretability with Self-Explaining Neural Networks ([Alvarez-Melis et al., 2018](https://papers.nips.cc/paper/8003-towards-robust-interpretability-with-self-explaining-neural-networks)) `MIT`\n', '- Leveraging Latent Features for Local Explanations ([Luss et al., 2019](https://arxiv.org/abs/1905.12698)) `IBM Research` `University of Michigan`\n', '\n', '### Fairness\n', '\n', '- [LiFT: A Scalable Framework for Measuring Fairness in ML Applications](https://engineering.linkedin.com/blog/2020/lift-addressing-bias-in-large-scale-ai-applications) ([Vasuvedan et al., 2020](https://arxiv.org/abs/2008.07433)) `LinkedIn`\n', '\n', '### Ethical Data Products\n', '\n', '- [Building Inclusive Products Through A/B Testing](https://engineering.linkedin.com/blog/2020/building-inclusive-products-through-a-b-testing) ([Saint-Jacques et al, 2020](https://arxiv.org/pdf/2002.05819)) `LinkedIn`\n', '\n', '### Sustainability\n', '\n', '- Energy and policy considerations for deep learning in NLP ([Strubell, E. et al. 2019](https://arxiv.org/abs/1906.02243))\n', '- Quantifying the carbon emissions of machine learning. ([Lacoste, A. et al. 2019](https://arxiv.org/abs/1910.09700))\n', '- Carbon emissions and large neural network training. ([Patterson, D. et al. 2021](https://arxiv.org/abs/2104.10350)) \n', '- The Energy and Carbon Footprint of Training End-to-End Speech Recognizers. ([Parcollet, T., & Ravanelli, M. 2021](https://hal.archives-ouvertes.fr/hal-03190119/document))\n', '- Sustainable AI: AI for sustainability and the sustainability of AI ([van Wynsberghe, A. 2021](https://link.springer.com/article/10.1007/s43681-021-00043-6)). AI and Ethics, 1-6\n', '- Green Algorithms: Quantifying the carbon emissions of computation ([Lannelongue, L. et al. 2020](https://arxiv.org/abs/2007.07610))\n', '- Machine Learning: The High Interest Credit Card of Technical Debt ([Sculley, D. et al. 2014](https://research.google/pubs/pub43146/)) `Google`\n', '\n', '### Collections\n', '\n', '- Google Research on Responsible AI: https://research.google/pubs/?collection=responsible-ai `Google`\n', '\n', '## Books\n', '\n', '### Open Access\n', '\n', '- Interpretable Machine Learning ([Molnar, C., 2021](https://christophm.github.io/interpretable-ml-book/)) `Explainability` `Interpretability` `Transparency` `R`\n', '- Explanatory Model Analysis ([Biecek et al., 2020](https://ema.drwhy.ai)) `Explainability` `Interpretability` `Transparency` `R`\n', '\n', '### Commercial / Propietary / Closed Access\n', '\n', '- Trust in Machine Learning ([Varshney, K., 2022](https://www.manning.com/books/trust-in-machine-learning)) `Safety` `Privacy` `Drift` `Fairness` `Interpretability` `Explainability`\n', '- Interpretable AI ([Thampi, A., 2022](https://www.manning.com/books/interpretable-ai)) `Explainability` `Fairness` `Interpretability` \n', '- AI Fairness ([Mahoney, T., Varshney, K.R., Hind, M., 2020](https://learning.oreilly.com/library/view/ai-fairness/9781492077664/) `Report` `Fairness`\n', '- Practical Fairness ([Nielsen, A., 2021](https://learning.oreilly.com/library/view/practical-fairness/9781492075721/)) `Fairness`\n', '- Hands-On Explainable AI (XAI) with Python ([Rothman, D., 2020](https://www.packtpub.com/product/hands-on-explainable-ai-xai-with-python/9781800208131)) `Explainability`\n', '- AI and the Law ([Kilroy, K., 2021](https://learning.oreilly.com/library/view/ai-and-the/9781492091837/)) `Report` `Trust` `Law`\n', '- Responsible Machine Learning ([Hall, P., Gill, N., Cox, B., 2020](https://learning.oreilly.com/library/view/responsible-machine-learning/9781492090878/)) `Report` `Law`  `Compliance` `Safety` `Privacy` \n', '- [Privacy-Preserving Machine Learning](https://www.manning.com/books/privacy-preserving-machine-learning)\n', '- [Human-In-The-Loop Machine Learning: Active Learning and Annotation for Human-Centered AI](https://www.manning.com/books/human-in-the-loop-machine-learning)\n', '- [Interpretable Machine Learning With Python: Learn to Build Interpretable High-Performance Models With Hands-On Real-World Examples](https://www.packtpub.com/product/interpretable-machine-learning-with-python/9781800203907)\n', '- Responsible AI ([Hall, P., Chowdhury, R., 2023](https://learning.oreilly.com/library/view/responsible-ai/9781098102425/)) `Governance` `Safety` `Drift`\n', '\n', '## Code of Ethics\n', '\n', '- [ACS Code of Professional Conduct](https://www.acs.org.au/content/dam/acs/rules-and-regulations/Code-of-Professional-Conduct_v2.1.pdf) by Australian ICT (Information and Communication Technology)\n', '- [AI Standards Hub](https://aistandardshub.org)\n', ""- [Association for Computer Machinery's Code of Ethics and Professional Conduct](https://www.acm.org/code-of-ethics)\n"", '- [IEEE Global Initiative for Ethical Considerations in Artificial Intelligence (AI) and Autonomous Systems (AS)](https://ethicsinaction.ieee.org/)\n', ""- [ISO/IEC's Standards for Artificial Intelligence](https://www.iso.org/committee/6794475/x/catalogue/)\n"", '- [Ethics guidelines for trustworthy AI](https://op.europa.eu/en/publication-detail/-/publication/d3988569-0434-11ea-8c1f-01aa75ed71a1/language-en/format-PDF/source-229277158) - European Commission document prepared by the High-Level Expert Group on Artificial Intelligence (AI HLEG).\n', '- [Google AI Principles](https://ai.google/principles/)\n', '- [Microsoft AI Principles](https://www.microsoft.com/en-us/ai/responsible-ai)\n', '\n', '## Data Sets\n', '\n', '- [An ImageNet replacement for self-supervised pretraining without humans](https://www.robots.ox.ac.uk/~vgg/research/pass/)\n', '- [Huggingface Data Sets](https://huggingface.co/datasets)\n', '\n', '## Institutes\n', '\n', '- [Ada Lovelace Institute](https://www.adalovelaceinstitute.org/)\n', '- [European Centre for Algorithmic Transparency](https://algorithmic-transparency.ec.europa.eu/index_en)\n', '- [Center for Responsible AI](https://airesponsibly.com/)\n', '- [Montreal AI Ethics Institute](https://montrealethics.ai/)\n', '- [Munich Center for Technology in Society (IEAI)](https://ieai.mcts.tum.de/)\n', '- [Open Data Institute](https://theodi.org/)\n', '- [Stanford University Human-Centered Artificial Intelligence (HAI)](https://hai.stanford.edu)\n', '- [The Institute for Ethical AI & Machine Learning](https://ethical.institute/)\n', '- [University of Oxford Institute for Ethics in AI](https://www.oxford-aiethics.ox.ac.uk/)\n', '\n', '## Newsletters\n', '\n', '- [Import AI](https://jack-clark.net)\n', '- [The AI Ethics Brief](https://brief.montrealethics.ai)\n', '- [The Machine Learning Engineer](https://ethical.institute/mle.html) \n', '\n', '## Principles\n', '\n', ""- [European Commission's Guidelines for Trustworthy AI](https://ec.europa.eu/futurium/en/ai-alliance-consultation)\n"", ""- [IEEE's Ethically Aligned Design](https://ethicsinaction.ieee.org/)\n"", '- [The Institute for Ethical AI & Machine Learning: The Responsible Machine Learning Principles](https://ethical.institute/principles.html)\n', '\n', 'Additional:\n', '\n', '- [FAIR Principles](https://www.go-fair.org/fair-principles/) `Findability` `Accessibility` `Interoperability` `Reuse`\n', '\n', '## Podcasts\n', '\n', '- [The Human-Centered AI Podcast](https://podcasts.apple.com/us/podcast/the-human-centered-ai-podcast/id1499839858)\n', '- [Responsible AI Podcast](https://open.spotify.com/show/63Fx70r96P3ghWavisvPEQ)\n', '- [Trustworthy AI](https://marketing.truera.com/trustworthy-ai-podcast)\n', '\n', '## Reports\n', '\n', '- [Inferring Concept Drift Without Labeled Data, 2021](https://concept-drift.fastforwardlabs.com) `Drift`\n', '- [Interpretability, Fast Forward Labs, 2020](https://ff06-2020.fastforwardlabs.com) `Interpretability`\n', '- [State of AI](https://www.stateof.ai) - from 2018 up to now -\n', '\n', '## Tools\n', '\n', '### Bias\n', '\n', '- [balance](https://import-balance.org) `Python` `Facebook`\n', '\n', '### Causal Inference\n', '\n', '- [CausalAI](https://github.com/salesforce/causalai) `Python` `Salesforce`\n', '- [CausalNex](https://causalnex.readthedocs.io) `Python`\n', '- [CausalImpact](https://cran.r-project.org/web/packages/CausalImpact) `R`\n', '- [Causalinference](https://causalinferenceinpython.org) `Python`\n', '- [CIMTx: Causal Inference for Multiple Treatments with a Binary Outcome](https://cran.r-project.org/web/packages/CIMTx) `R`\n', '- [dagitty](https://cran.r-project.org/web/packages/dagitty) `R`\n', '- [DoWhy](https://github.com/Microsoft/dowhy) `Python` `Microsoft`\n', '- [mediation: Causal Mediation Analysis](https://cran.r-project.org/web/packages/mediation) `R`\n', '- [MRPC](https://cran.r-project.org/web/packages/MRPC) `R`\n', '\n', '### Differential Privacy\n', '\n', '- [BackPACK](https://toiaydcdyywlhzvlob.github.io/backpack) `Python`\n', '- [DataSynthesizer: Privacy-Preserving Synthetic Datasets](https://github.com/DataResponsibly/DataSynthesizer) `Python` `Drexel University` `University of Washington`\n', '- [diffpriv](https://github.com/brubinstein/diffpriv) `R`\n', '- [Diffprivlib](https://github.com/IBM/differential-privacy-library) `Python` `IBM`\n', '- [Discrete Gaussian for Differential Privacy](https://github.com/IBM/discrete-gaussian-differential-privacy) `Python` `IBM`\n', '- [Opacus](https://opacus.ai) `Python` `Facebook`\n', '- [PyVacy: Privacy Algorithms for PyTorch](https://github.com/ChrisWaites/pyvacy) `Python`\n', '- [SEAL](https://github.com/Microsoft/SEAL) `Python` `Microsoft`\n', '- [SmartNoise](https://github.com/opendp/smartnoise-core) `Python` `OpenDP`\n', '- [Tensorflow Privacy](https://github.com/tensorflow/privacy) `Python` `Google`\n', '\n', '### Drift\n', '\n', '- [Alibi Detect](https://github.com/SeldonIO/alibi-detect) `Python`\n', '- [Deepchecks](https://github.com/deepchecks/deepchecks) `Python`\n', '- [drifter](https://cran.r-project.org/web/packages/drifter/) `R`\n', '- [Evidently](https://github.com/evidentlyai/evidently) `Python`\n', '- [nannyML](https://github.com/NannyML/nannyml) `Python`\n', '\n', '### Fairness\n', '\n', ""- [Aequitas' Bias & Fairness Audit Toolkit](http://aequitas.dssg.io/) `Python`\n"", '- [AI360 Toolkit](https://github.com/Trusted-AI/AIF360) `Python` `R` `IBM`\n', '- [Fairlearn](https://fairlearn.org) `Python` `Microsoft`\n', '- [Fairmodels](https://fairmodels.drwhy.ai) `R`\n', '- [fairness](https://cran.r-project.org/web/packages/fairness/) `R`\n', '- [FairPAN - Fair Predictive Adversarial Network](https://modeloriented.github.io/FairPAN/) `R`\n', '- [Themis ML](https://github.com/cosmicBboy/themis-ml) `Python`\n', '- [What-If Tool](https://github.com/PAIR-code/what-if-tool) `Python` `Google`\n', '\n', '### Interpretability/Explicability\n', '\n', '- [AI360 Toolkit](https://github.com/Trusted-AI/AIF360) `Python` `R` `IBM`\n', '- [aorsf: Accelerated Oblique Random Survival Forests](https://cran.r-project.org/web/packages/aorsf/index.html) `R`\n', '- [breakDown: Model Agnostic Explainers for Individual Predictions](https://cran.r-project.org/web/packages/breakDown/index.html) `R`\n', '- [ceterisParibus: Ceteris Paribus Profiles](https://cran.r-project.org/web/packages/ceterisParibus/index.html) `R`\n', '- [DALEX: moDel Agnostic Language for Exploration and eXplanation](https://dalex.drwhy.ai) `Python` `R`\n', '- [DALEXtra: extension for DALEX](https://modeloriented.github.io/DALEXtra) `Python` `R`\n', '- [ecco](https://pypi.org/project/ecco/) [article](https://jalammar.github.io/explaining-transformers/) `Python`\n', '- [eli5](https://github.com/TeamHG-Memex/eli5) `Python`\n', '- [eXplainability Toolbox](https://ethical.institute/xai.html) `Python`\n', '- [ExplainerHub](https://explainerdashboard.readthedocs.io/en/latest/index.html) [in github](https://github.com/oegedijk/explainerdashboard) `Python` \n', '- [fasttreeshap](https://github.com/linkedin/fasttreeshap) `Python` `LinkedIn`\n', '- [FAT Forensics](https://fat-forensics.org/) `Python`\n', '- [intepretML](https://interpret.ml) `Python`\n', '- [interactions: Comprehensive, User-Friendly Toolkit for Probing Interactions](https://cran.r-project.org/web/packages/interactions/index.html) `R`\n', '- [kernelshap: Kernel SHAP](https://cran.r-project.org/web/packages/kernelshap/index.html) `R`\n', '- [lime: Local Interpretable Model-Agnostic Explanations](https://cran.r-project.org/web/packages/lime/index.html) `R`\n', '- [Shap](https://github.com/slundberg/shap) `Python`\n', '- [Shapash](https://github.com/maif/shapash) `Python`\n', '- [shapviz](https://cran.r-project.org/web/packages/shapviz/index.html) `R`\n', '- [Skater](https://github.com/oracle/Skater) `Python` `Oracle`\n', '- [survex](https://github.com/ModelOriented/survex) `R`\n', '- [pre: Prediction Rule Ensembles](https://cran.r-project.org/web/packages/pre/index.html) `R`\n', '- [XAI - An eXplainability toolbox for machine learning](https://github.com/EthicalML/xai) `Python` `The Institute for Ethical Machine Learning`\n', '- [Zennit](https://github.com/chr5tphr/zennit) `Python`\n', '\n', '### Performance (& Automated ML)\n', '\n', '- [automl: Deep Learning with Metaheuristic](https://cran.r-project.org/web/packages/automl/index.html) `R`\n', '- [AutoKeras](https://github.com/keras-team/autokeras) `Python`\n', '- [Auto-Sklearn](https://github.com/automl/auto-sklearn) `Python`\n', '- [DataPerf](https://sites.google.com/mlcommons.org/dataperf/) `Python` `Google`\n', '- [deepchecks](https://deepchecks.com) `Python`\n', '- [Featuretools](https://www.featuretools.com) `Python`\n', '- [forester](https://modeloriented.github.io/forester/) `R`\n', '- [metrica: Prediction performance metrics](https://adriancorrendo.github.io/metrica/) `R`\n', '- [NNI: Neural Network Intelligence](https://github.com/microsoft/nni) `Python` `Microsoft`\n', '- [TPOT](http://epistasislab.github.io/tpot/) `Python`\n', '- [Unleash](https://www.getunleash.io)\n', '\n', '### Responsible AI toolkit\n', '\n', '- [Dr. Why](https://github.com/ModelOriented/DrWhy) `R` `Warsaw University of Technology`\n', '- [Responsible AI Widgets](https://github.com/microsoft/responsible-ai-widgets) `R` `Microsoft`\n', '- [The Data Cards Playbook](https://pair-code.github.io/datacardsplaybook/)\n', '\n', '### Sustainability\n', '\n', '- [Code Carbon](https://github.com/mlco2/codecarbon) `Python`\n', '- [Azure Sustainability Calculator](https://appsource.microsoft.com/en-us/product/power-bi/coi-sustainability.sustainability_dashboard) `Microsoft`\n', '- [Computer Progress](https://www.computerprogress.com)\n', '\n', '## Reproducible Research\n', '\n', '- [Papers with Code](https://paperswithcode.com)\n', '- [Papers without Code](https://www.paperswithoutcode.com)\n', '\n', '## Regulations\n', '\n', '- [Data Protection Laws of the Word](https://www.dlapiperdataprotection.com)\n', '\n', '### European Union\n', '\n', '- [General Data Protection Regulation GDPR](https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=celex%3A32016R0679) - Legal text for the EU GDPR regulation 2016/679 of the European Parliament and of the Council of 27 April 2016 on the protection of natural persons with regard to the processing of personal data and on the free movement of such data, and repealing Directive 95/46/EC\n', '- [GDPR.EU Guide](https://gdpr.eu/) - A project co-funded by the Horizon 2020 Framework programme of the EU which provides a resource for organisations and individuals researching GDPR, including a library of straightforward and up-to-date information to help organisations achieve GDPR compliance ([Legal Text](https://www.govinfo.gov/content/pkg/USCODE-2012-title5/pdf/USCODE-2012-title5-partI-chap5-subchapII-sec552a.pdf)).\n', '\n', '### United States\n', '\n', '- State consumer privacy laws: California ([CCPA](https://www.oag.ca.gov/privacy/ccpa) and its amendment, [CPRA](https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=202120220AB1490)), Virginia ([VCDPA](https://lis.virginia.gov/cgi-bin/legp604.exe?212+sum+HB2307)), and Colorado ([ColoPA](https://leg.colorado.gov/sites/default/files/documents/2021A/bills/2021a_190_rer.pdf)).\n', '- Specific and limited privacy data laws: [HIPAA](https://www.cdc.gov/phlp/publications/topic/hipaa.html), [FCRA](https://www.ftc.gov/enforcement/statutes/fair-credit-reporting-act), [FERPA](https://www.cdc.gov/phlp/publications/topic/ferpa.html), [GLBA](https://www.ftc.gov/tips-advice/business-center/privacy-and-security/gramm-leach-bliley-act), [ECPA](https://bja.ojp.gov/program/it/privacy-civil-liberties/authorities/statutes/1285), [COPPA](https://www.ftc.gov/enforcement/rules/rulemaking-regulatory-reform-proceedings/childrens-online-privacy-protection-rule), [VPPA](https://www.law.cornell.edu/uscode/text/18/2710) and [FTC](https://www.ftc.gov/enforcement/statutes/federal-trade-commission-act).\n', '- [EU-U.S. and Swiss-U.S. Privacy Shield Frameworks](https://www.privacyshield.gov/welcome) - The EU-U.S. and Swiss-U.S. Privacy Shield Frameworks were designed by the U.S. Department of Commerce and the European Commission and Swiss Administration to provide companies on both sides of the Atlantic with a mechanism to comply with data protection requirements when transferring personal data from the European Union and Switzerland to the United States in support of transatlantic commerce.\n', '- [Executive Order on Maintaining American Leadership in AI](https://www.whitehouse.gov/presidential-actions/executive-order-maintaining-american-leadership-artificial-intelligence/) - Official mandate by the President of the US to \n', '[Privacy Act of 1974](https://www.justice.gov/opcl/privacy-act-1974) - The privacy act of 1974 which establishes a code of fair information practices that governs the collection, maintenance, use and dissemination of information about individuals that is maintained in systems of records by federal agencies.\n', '- [Privacy Protection Act of 1980](https://epic.org/privacy/ppa/) - The Privacy Protection Act of 1980 protects journalists from being required to turn over to law enforcement any work product and documentary materials, including sources, before it is disseminated to the public.\n', '- [AI Bill of Rights](https://www.whitehouse.gov/ostp/ai-bill-of-rights/) - The Blueprint for an AI Bill of Rights is a guide for a society that protects all people from IA threats based on five principles: Safe and Effective Systems, Algorithmic Discrimination Protections, Data Privacy, Notice and Explanation, and  Human Alternatives, Consideration, and Fallback.\n']"
Responsible+AI,aws-samples/aws-machine-learning-university-responsible-ai,aws-samples,https://api.github.com/repos/aws-samples/aws-machine-learning-university-responsible-ai,30,7,2,"['https://api.github.com/users/mimicarina', 'https://api.github.com/users/amazon-auto']",Python,2023-03-27T06:06:43Z,https://raw.githubusercontent.com/aws-samples/aws-machine-learning-university-responsible-ai/main/README.md,"['![logo](data/MLU_Logo.png)\n', '## Machine Learning University: Responsible AI\n', '\n', 'This repository contains __slides__, __notebooks__, and __data__ for the __Machine Learning University (MLU) Responsible AI__ class. Our mission is to make Machine Learning accessible to everyone. We have courses available across many topics of machine learning and believe knowledge of ML can be a key enabler for success. This class is designed to help you get started with Responsible AI, learn about widely used Machine Learning techniques, and apply them to real-world problems.\n', '\n', '## YouTube\n', 'Watch all Responsible AI video recordings in this [YouTube playlist](https://www.youtube.com/playlist?list=PL8P_Z6C4GcuVMxhwT9JO_nKuW0QMSJ-cZ) from our [YouTube channel](https://www.youtube.com/channel/UC12LqyqTQYbXatYS9AA7Nuw/playlists).\n', '\n', '## Course Overview\n', 'There are three lectures and one final project for this class.\n', '\n', '__Final Project:__ Practice working with a ""real-world"" dataset for the final project. Final project dataset is in the [data/final_project folder](https://github.com/aws-samples/aws-machine-learning-university-responsible-ai/tree/master/data/final_project). For more details on the final project, check out [this notebook](https://github.com/aws-samples/aws-machine-learning-university-responsible-ai/blob/main/notebooks/day_1/MLA-RESML-DAY1-FINAL-STUDENT-NB.ipynb).\n', '\n', '## Interactives/Visuals\n', 'Interested in visual, interactive explanations of core machine learning concepts? Check out our [MLU-Explain articles](https://mlu-explain.github.io/) to learn at your own pace! \n', '\n', '## Contribute\n', 'If you would like to contribute to the project, see [CONTRIBUTING](CONTRIBUTING.md) for more information.\n', '\n', '## License\n', ""The license for this repository depends on the section.  Data set for the course is being provided to you by permission of Amazon and is subject to the terms of the [Amazon License and Access](https://www.amazon.com/gp/help/customer/display.html?nodeId=201909000). You are expressly prohibited from copying, modifying, selling, exporting or using this data set in any way other than for the purpose of completing this course. The lecture slides are released under the CC-BY-SA-4.0 License.  This project is licensed under the Apache-2.0 License. See each section's LICENSE file for details.\n""]"
Responsible+AI,microsoft/responsible-ai-toolbox-tracker,microsoft,https://api.github.com/repos/microsoft/responsible-ai-toolbox-tracker,28,3,6,"['https://api.github.com/users/danyrouh', 'https://api.github.com/users/thuvanm', 'https://api.github.com/users/microsoftopensource', 'https://api.github.com/users/raghoshMSFT', 'https://api.github.com/users/mrfmendonca', 'https://api.github.com/users/microsoft-github-operations%5Bbot%5D']",TypeScript,2023-03-30T08:56:50Z,https://raw.githubusercontent.com/microsoft/responsible-ai-toolbox-tracker/main/README.md,"['![MIT license](https://img.shields.io/badge/License-MIT-blue.svg)\n', '\n', '# Responsible AI Tracker\n', '\n', 'Responsible AI Tracker is a JupyterLab Extension for managing, tracking, and comparing results of machine learning experiments for model improvement. Using this extension, users can view models, code, and visualization artifacts within the same framework enabling fast model iteration and evaluation processes. The extension is a work-in-progress research prototype to test and understand tooling functionalities and visualizations that can be helpful to data scientists. If you would like to propose new ideas for improvement feel free to contact the development team at [rai-toolbox@microsoft.com](mailto:rai-toolbox@microsoft.com) or create new issues in this repository.\n', '\n', 'This repo is a part of the [Responsible AI Toolbox](https://github.com/microsoft/responsible-ai-toolbox#responsible-ai-toolbox), a suite of tools providing a collection of model and data exploration and assessment user interfaces and libraries that enable a better understanding of AI systems. These interfaces and libraries empower developers and stakeholders of AI systems to develop and monitor AI more responsibly, and take better data-driven actions.\n', '\n', '### Main functionalities of the tracker include:\n', '\n', '- **Managing and linking model improvement artifacts**: the extension encourages clean and systematic data science practices by allowing users to associate the notebook used to create a model with the resulting model. These practices support careful model tracking and systematic experimentation.\n', '\n', '- **Disaggregated model evaluation and comparisons**: the model comparison table in the extension provides an in-depth comparison between the different models registered in the extension. This comparison contrasts performance results across different data cohorts and metrics, following a disaggregated approach, which goes beyond single-score performance numbers and highlights cohorts of data for which a model may perform worse than its older versions. Read more about disaggregated analysis [here](https://responsible-ai-toolbox-tracker.readthedocs.io/en/latest/basics_disaggregated.html).\n', '\n', '- **Integration with the Responsible AI Mitigations library**: as data scientists experiment and ideate different steps for model improvement, the [Responsible AI Mitigations Library](https://github.com/microsoft/responsible-ai-toolbox-mitigations) helps them implement different mitigation techniques in python that may improve model performance and can be targeted towards specified cohorts of interests.\n', '\n', '## Tour\n', '\n', 'Watch a [video tour](https://www.youtube.com/watch?v=jN6LWFzSLaU) of the Responsible AI Tracker and follow along using the notebooks and dataset [here](./tour).\n', '<p align=""center"">\n', '<img src=""./docs/imgs/RAI%20Tracker%20full%20view.png"" alt=""ResponsibleAITrackerOverview"" width=""750""/>\n', '\n', '\n', '\n', '## Installation\n', '\n', 'The Responsible AI Tracker can be deployed on Windows or Ubuntu, using anaconda or python.\n', '\n', '### The Responsible AI Tracker prerequisites:\n', '\n', '- [Nodejs](https://nodejs.org/)\n', '- [Python](https://www.python.org/downloads/) (versions supported 3.9 **to** 3.10.6)\n', '\n', '- JupyterLab\n', '  - If you use pip:\n', '  ```shell\n', '  pip install jupyterlab==3.6.1\n', '  ```\n', '  - If you use conda:\n', '  ```shell\n', '  conda install -c conda-forge jupyterlab==3.6.1\n', '  ```\n', '\n', '### The Responsible AI Tracker has two installation options:\n', '\n', '- The default installation only installs the essential packages.\n', '\n', '  ```shell\n', '  pip install raitracker\n', '  ```\n', '\n', '- The installation With the [all] flag installs the essential packages plus PyTorch, and Tensorflow.\n', '  ```shell\n', '  pip install raitracker[all]\n', '  ```\n', '\n', 'Installation through the JupyterLab Extension Manager coming soon. \n', '\n', '### Running\n', '\n', 'Start up JupyterLab using:\n', '\n', '```bash\n', 'jupyter lab\n', '```\n', '\n', 'The extension should be available in the left vertical bar. For ideas on getting started, watch the [video tour](https://www.youtube.com/watch?v=jN6LWFzSLaU) and follow along using the notebooks and dataset [here](./tour).\n', ' \n', '<details><summary>Dependencies</summary>\n', '<ul>\n', '\n', '<li>jupyterlab</li>\n', '<li>fluentui</li>\n', '<li>nodejs</li>\n', '<li>react</li>\n', '<li>redux</li>\n', '<li>lumino</li>\n', '<li>lodash</li>\n', '<li>babel</li>\n', '<li>codeMirror</li>\n', '<li>webpack</li>\n', '<li>mlflow</li>\n', '<li>numpy</li>\n', '<li>pandas</li>\n', '<li>scikit-learn</li>\n', '<li>pytorch</li>\n', '</ul>\n', '</details>\n', '\n', '---\n', '\n', '## Getting help\n', '\n', 'We encourage you to check the Responsible AI Tracker [documentation](https://responsible-ai-toolbox-tracker.readthedocs.io/en/latest/). \n', '\n', 'For Responsible AI Mitigations Library help see [Responsible AI Mitigations documentation](https://responsible-ai-toolbox-mitigations.readthedocs.io/en/latest/).  \n', '\n', 'See [here](https://github.com/microsoft/responsible-ai-toolbox-tracker/blob/main/SUPPORT.md) for further support information.\n', '\n', '\n', '### Bug reports\n', '\n', 'To report a bug please read the [guidelines](https://responsible-ai-toolbox-tracker.readthedocs.io/en/latest/) and then open a [Github issue](https://github.com/microsoft/responsible-ai-toolbox-tracker/issues/new). \n', '\n', '\n', '### Feature requests\n', '\n', 'We welcome suggestions for new features as they help make the project more useful for everyone. To request a feature please use the [feature request template](https://github.com/microsoft/responsible-ai-toolbox-tracker/labels/enhancement).\n', '\n', '### Contributing\n', '\n', 'To contribute code or documentation to the Responsible AI Tracker, please read the [contribution guidelines](https://github.com/microsoft/responsible-ai-toolbox-tracker/blob/main/CONTRIBUTING.md).\n', '\n', '---\n', '\n', '## Microsoft Open Source Code of conduct\n', '\n', 'The [Microsoft  Code of conduct](https://github.com/microsoft/responsible-ai-toolbox-tracker/blob/main/CODE_OF_CONDUCT.md) outlines expectations for participation in Microsoft-managed open source communities.\n', '\n', '\n', '## Trademarks\n', '\n', 'This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft \n', 'trademarks or logos is subject to and must follow \n', ""[Microsoft's Trademark & Brand Guidelines](https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general).\n"", 'Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship.\n', ""Any use of third-party trademarks or logos are subject to those third-party's policies.\n"", '\n', '## Research and Acknowledgements\n', '\n', '**Current Maintainers:** [ThuVan Pham](https://www.microsoft.com/en-us/research/people/thuvanp/), [Matheus Mendonça](https://github.com/mrfmendonca), [Besmira Nushi](https://github.com/nushib), [Rahee Ghosh Peshawaria](https://github.com/raghoshMSFT), [Marah Abdin](https://github.com/marah-abdin), [Mark Encarnación](https://github.com/markenc), [Dany Rouhana](https://github.com/danyrouh)\n', '\n', '**Past Maintainers:** [Irina Spiridonova](https://github.com/irinasp)\n', '\n', '**Research Contributors:** [Besmira Nushi](https://github.com/nushib), [Jingya Chen](https://www.jingyachen.net/), [Rahee Ghosh Peshawaria](https://github.com/raghoshMSFT), [ThuVan Pham](https://www.microsoft.com/en-us/research/people/thuvanp/), [Matheus Mendonça](https://github.com/mrfmendonca), [Ece Kamar](https://www.ecekamar.com/), [Dany Rouhana](https://github.com/danyrouh)']"
Responsible+AI,microsoft/responsible-ai-toolbox-genbit,microsoft,https://api.github.com/repos/microsoft/responsible-ai-toolbox-genbit,20,3,7,"['https://api.github.com/users/declangroves', 'https://api.github.com/users/mesameki', 'https://api.github.com/users/microsoftopensource', 'https://api.github.com/users/hal3', 'https://api.github.com/users/KinshukSengupta', 'https://api.github.com/users/dependabot%5Bbot%5D', 'https://api.github.com/users/microsoft-github-operations%5Bbot%5D']",Python,2023-04-05T06:50:33Z,https://raw.githubusercontent.com/microsoft/responsible-ai-toolbox-genbit/main/README.md,"['# GenBit: A Tool for Measuring Gender Bias in Text Corpora\n', '\n', 'This Responsible-AI-Toolbox-GenBit repo consists of a python library that aims to empower data scientists and ML developers to measure gender bias in their Natural Language Processing (NLP) datasets. \n', '\n', 'This repo is a part of the [Responsible AI Toolbox](https://github.com/microsoft/responsible-ai-toolbox#responsible-ai-toolbox), a suite of tools providing a collection of model and data exploration and assessment user interfaces and libraries that enable a better understanding of AI systems. These interfaces and libraries empower developers and stakeholders of AI systems to develop and monitor AI more responsibly, and take better data-driven actions.\n', '\n', ""With the increasing adoption of Natural Language Processing (NLP) models in real-world applications and products, it has become more critical than ever to understand these models' biases and potential harms they could cause to their end users. Many NLP systems suffer from various biases often inherited from the data on which these systems are trained. The prejudice is exhibited at multiple levels spilling from how individuals generate, collect, and label the information leveraged into datasets. Datasets, features, and rules in machine learning algorithms absorb and often magnify such biases present in datasets. Therefore, it becomes essential to measure preferences at the data level to prevent unfair model outcomes.\n"", '\n', 'This repository introduces the Gender Bias Tool (**G**en**B**i**t**), a tool to measure gender bias in NLP datasets. The main goal of GenBit is to analyze your corpora and compute metrics that give insights into the gender bias present in a corpus. The computations in this tool are based primarily on ideas from Shikha Bordia and Samuel R. Bowman, ""[Identifying and reducing gender bias in word-level language models](https://arxiv.org/abs/1904.03035)"" in the NAACL 2019 Student Research Workshop. \n', '\n', 'GenBit helps determine if gender is uniformly distributed across data by measuring the strength of association between a pre-defined list of gender definition words and other words in the corpus via co-occurrence statistics. The key metric it produces (the genbit_score) gives an estimate of the strength of association, on average, of any word in the corpus with a male, female, non-binary, transgender (trans), and cisgender (cis) gender definition words. The metrics that it provides can be used to identify gender bias in a data set to enable the production and use of more balanced datasets for training, tuning and evaluating machine learning models. It can also be used as a standalone corpus analysis tool.\n', '\n', '\n', 'GenBit supports 5 languages: English, German, Spanish, French, Italian and Russian. For English it provides metrics for both binary, non-binary, transgender, and cisgender bias; for the remaining four languages we currently only support binary gender bias. To deal with the challenges of grammatical gender in non-English languages, it leverages [stanza lemmatizers](https://stanfordnlp.github.io/stanza/lemma.html). It also uses the NLTK tokenization libraries. The full list of requirements are listed in [requirements.txt](requirements.txt)\n', '\n', '## Contents\n', '- [Install GenBit](#installation)\n', '- [Use GenBit](#use)\n', '- [Gendered Terms](#terms)\n', '- [Supported Metrics](#metrics)\n', '- [Metric Scores, Benchmarking and Interpretation](#interpret)\n', '- [Citation](#citation)\n', '- [Useful Links](#links)\n', '- [Contributing](#contributing)\n', '- [Trademarks](#trademarks)\n', '- [Authors and acknowledgment](#authors)\n', '\n', '# <a name=""installation""></a>\n', '## Install GenBit\n', '\n', 'The package can be installed from [pypi](https://pypi.org/project/genbit/) with:\n', '\n', '```\n', 'pip install genbit\n', '```\n', '\n', 'Tested and supported environments for the GenBit python package are:\n', '- Local usage on Windows\n', '- Local usage on Linux (Tested on Ubuntu 18.04 and Debian Buster 10)\n', '- As part of Azure functions installed using a [remote build](https://docs.microsoft.com/en-us/azure/azure-functions/functions-reference-python#remote-build-with-extra-index-url).\n', '\n', '\n', '\n', '# <a name=""use""></a>\n', '## Use GenBit\n', '\n', 'To use GenBit metrics, run the following code:\n', '\n', '```python\n', 'from genbit.genbit_metrics import GenBitMetrics\n', '\n', '# Create a GenBit object with the desired settings:\n', '\n', 'genbit_metrics_object = GenBitMetrics(language_code, context_window=5, distance_weight=0.95, percentile_cutoff=80)\n', '\n', '\n', ""# Let's say you want to use GenBit with a test sentence, you can add the sentence to GenBit:\n"", 'test_text = [""I think she does not like cats. I think he does not like cats."", ""He is a dog person.""]\n', '\n', 'genbit_metrics_object.add_data(test_text, tokenized=False)\n', '\n', '\n', '# To generate the gender bias metrics, we run `get_metrics` by setting `output_statistics` and `output_word_lists` to false, we can reduce the number of metrics created.\n', '\n', '\n', 'metrics = genbit_metrics_object.get_metrics(output_statistics=True, output_word_list=True)\n', '\n', '```\n', '\n', 'This process can be repeated as needed. Every separate string will be treated as an individual document, i.e. the context window will not reach beyond the limits of a single string. Therefore if a document is coherent, the content should be appended and added as a single string in the input list.\n', '\n', 'The metric works best on bigger corpora; therefore, we suggest analyzing at least 400 documents and 600 unique words (excluding stop words).\n', '\n', '\n', '# <a name=""terms""></a>\n', '## Gendered Terms\n', 'We have collected a [list of ""gendered"" terms for female, male, non-binary, binary, transgender, and cisgender groups](https://github.com/microsoft/responsible-ai-toolbox-genbit/tree/main/genbit/gendered-word-lists).\n', '\n', '- [Female words](https://github.com/microsoft/responsible-ai-toolbox-genbit/blob/main/genbit/gendered-word-lists/en/female.txt) contain terms such as ""her"" and ""waitress"".\n', '- [Male words](https://github.com/microsoft/responsible-ai-toolbox-genbit/blob/main/genbit/gendered-word-lists/en/male.txt) contain terms such as ""he"" and ""fireman"".\n', '- [Non-binary words](https://github.com/microsoft/responsible-ai-toolbox-genbit/blob/main/genbit/gendered-word-lists/en/non-binary.txt) contain terms such as ""sibling"" and ""parent"".\n', '- [Cisgender words](https://github.com/microsoft/responsible-ai-toolbox-genbit/blob/main/genbit/gendered-word-lists/en/cis.txt) contain terms such as ""cisgender"" and ""cissexual"".\n', '- [Transgender words](https://github.com/microsoft/responsible-ai-toolbox-genbit/blob/main/genbit/gendered-word-lists/en/trans.txt) contain terms such as ""trans woman"" and ""trans man"".\n', '\n', 'Please note that there is no explicit file for binary terms because the terms from male.txt and female.txt will be combined to form the binary word list.\n', '\n', 'The inclusion criterion for terms that are not inherently gendered (e.g., ""womb"" or ""homemaker"" in female.txt) should be: If the association of the term with a particular gender is only due to a social phenomenon that we want to approximate with our measurement (e.g., stereotyping, discrimination), then the term should be excluded. The categories are defined in terms of similar societal stereotypes/discrimination/bias/stigma because that is what GenBit would like to measure. \n', '\n', '### Creation of New Word Lists for Male/Female\n', 'The gender definition terms consist of pairs of corresponding entries – one for male gendered forms and one for female gendered forms. In general, for every male gendered form, there should be one or more female gendered forms, and for every female gendered form there should be one or more male gendered form. It should be noted, however, that there may be some rare cases, where there are entries that do not have a opposite gender equivalent form in some languages.\n', '\n', 'A gender definition entry is a concept that can only ever be attributed to a person of a specific gender; they represent words that are associated with gender by definition. They are unambiguous – they only ever have one possible semantic interpretation. They are primarily nouns or pronouns that refer to a person of a specific gender (e.g. he/she/zie, father/mother) but may occasionally include adjectives/adverbs/verbs (e.g. masculine / feminine, manly/womanly).\n', '\n', '\n', '### Creation of New Word Lists for Non-binary/Binary \n', 'The binary/non-binary dimension has 3 categories: \n', '- Binary: terms that typically refer to men or women, but not to non-binary people \n', '- Non-binary: terms that specifically refer to non-binary people and that are not typically used to refer to men or women - these terms require abandoning the idea of there being only two genders \n', '- All-gender: terms that can refer to people of any gender, including men, women, and non-binary people \n', '\n', '<b>Motivation for this split</b>: If we just put both non-binary and all-gender terms in the same txt file, we will not get any meaningful numbers out of GenBiT because the all-gender terms are so much more frequent and they\'re often used to refer to binary people, so we wouldn\'t really be measuring the anti-non-binary bias that we would like to measure.  On the other hand, if we only use the explicitly non-binary terms, we\'ll miss a lot of textual references to non-binary people that we would catch for binary people (e.g., we\'d catch ""brother"" and ""sister"", but not ""sibling""). \n', '\n', 'We combined the categories “non-binary” and “all-gender” into one word list. \n', '\n', '\n', '### Creation of New Word Lists for Transgender/Cisgender\n', '\n', 'The transgender category includes all terms that relate to transgressing gender boundaries or that are perceived as transgressing gender boundaries (for example, as evidenced by the type of stigma they receive). This is why the trans category includes terms for people that may not self-identify as trans, but that also transgress gender boundaries. \n', '\n', ""All terms in the non-binary category are also included in the trans category. Terms that are in the trans category, but not in the non-binary category, are terms that refer to transgressing gender boundaries, but that doesn't necessarily require abandoning the idea of there only being two genders. \n"", '\n', '\n', 'The collected terms could be found [here](https://github.com/microsoft/responsible-ai-toolbox-genbit/tree/main/genbit/gendered-word-lists), and you can explore [Lexicon Guidelines](https://github.com/microsoft/responsible-ai-toolbox-genbit/blob/main/genbit/gendered-word-lists/LEXICON_GUIDELINES.md) for creating lexicons to support new languages.\n', '\n', '\n', '\n', '# <a name=""metrics""></a>\n', '## Metrics\n', '\n', 'With the predefined ""gendered"" terms collected and available for you, GenBit computes a number of metrics which are functions of word co-occurrences with these predefined ""gendered"" words. As a reminder, the gendered words are divided into ""female"" words, ""male"" words, ""trans"" words (English only), ""cis"" words (English only), and ""non-binary"" words (English only). \n', '\n', '### Female vs Male Calculations\n', ""The main calculation is computing co-occurrences between words `w` in your provided text, and words `f` from the female list and words `m` from the male list. In all that follows, `c[w,F]` (respectively, `c[w,M]`) denotes the frequency that word `w` co-occurs with a word on the female (respectively, male) lists. These are naturally interpretable as probabilities by normalizing: `p(w|F) = c[w,F] / c[.,F]` where `c[.,F]` is the sum over all `w'` of `c[w',F]`.\n"", '\n', '### Non-binary vs Binary Calculations (English only)\n', ""The main calculation is computing co-occurrences between words `w` in your provided text, and words `nb` from the non-binary list and words `b` from the binary list. In all that follows, `c[w,nb]` (respectively, `c[w,b]`) denotes the frequency that word `w` co-occurs with a word on the binary (respectively, non-binary) lists. These are naturally interpretable as probabilities by normalizing: `p(w|nb) = c[w,nb] / c[.,nb]` where `c[.,nb]` is the sum over all `w'` of `c[w',nb]`.\n"", '\n', '### Transgender vs Cisgender Calculations (English only)\n', ""The main calculation is computing co-occurrences between words `w` in your provided text, and words `t` from the transgender list and words `c` from the cisgender list. In all that follows, `c[w,t]` (respectively, `c[w,t]`) denotes the frequency that word `w` co-occurs with a word on the transgender (respectively, cisgender) lists. These are naturally interpretable as probabilities by normalizing: `p(w|t) = c[w,t] / c[.,t]` where `c[.,t]` is the sum over all `w'` of `c[w',t]`.\n"", '\n', '### Supported Metrics\n', '\n', 'GenBit supports the following dataset metrics:\n', '- **avg_bias_ratio**: The average of the bias ratio scores per token. Formally, this is the average over all words `w` of `log( c[w,M] / c[w,F] )`.\n', '- **avg_bias_conditional**: The average of the bias conditional ratios per token. Similarly, this is the average over all words `w` of `log( p(w|M) / p(w|F) )`.\n', '- **avg_bias_ratio_absolute**. The average of the absolute bias ratio scores per token. Similar to `avg_bias_ratio`, this is the average over all `w` of `| log( c[w,M] / c[w,F] ) |`.\n', '- **avg_bias_conditional_absolute (genbit_score)**: The average of the absolute bias conditional ratios per token [note: this score is most commonly used as the key bias score in the literature]. Formally, this is the average over all `w` of `| log( p(w|M) / p(w|F) ) |`.\n', '- **avg_non_binary_bias_ratio**: the average of the token-level non-binary bias token ratios. Formally, this is the average over all words `w` of `log( (c[w,M] + c[w,F]) / c[w,NB] )`\n', '- **avg_non_binary_bias_conditional**: the average of the token-level non-binary bias conditional ratios. This is the average over all words `w` of `log( p(w|M) + p(w|F) / p(w|NB) )`\n', '- **avg_non_binary_bias_ratio_absolute**: the average of the token-level absolute non-binary bias ratio scores. Similar to `avg_non_binary_bias_ratio`, this is the average over all `w` of `| log( (c[w,M] + c[w,F]) / c[w,NB] ) |`\n', '- **avg_non_binary_bias_conditional_absolute**: the average of the token-level absolute non-binary bias conditional ratios.\n', '- **std_dev_bias_ratio**: Standard deviation of the bias ratio scores. This is the standard deviation that corresponds to `avg_bias_ratio`.\n', '- **std_dev_bias_conditional**: Standard deviation of the bias conditional scores. This is the standard deviation that corresponds to `avg_bias_conditional`.\n', '- **std_dev_non_binary_bias_ratio**: Standard deviation of non binary bias ratio scores. This is the standard deviation that corresponds to `avg_non_binary_bias_ratio`.\n', '- **std_dev_non_binary_bias_conditional**: Standard deviation of non binary bias conditional scores. This is the standard deviation that corresponds to `avg_non_binary_bias_conditional`.\n', '- **percentage_of_female_gender_definition_words**: The percentage of gendered (male, female and non-binary) words in the corpus that belong to the list of female gendered words\n', '- **percentage_of_male_gender_definition_words**: The percentage of gendered (male, female and non-binary) words in the corpus that belong to the list of male gendered words\n', '- **percentage_of_non_binary_gender_definition_words**: The percentage of gendered (male, female and non-binary words in the corpus that belong to the list of non-binary gendered words)\n', '\n', '### Metric Statistics\n', '\n', 'An optional set of `dict` containing statistics that can be included as part of the metrics dict object by the key `statistics`. These statistics will be returned if `output_statistics=True`.\n', '\n', '- **frequency_cutoff**: the percentile frequency cutoff value. Any co-occurrence counts that are above this frequency will be used in calculating the metrics\n', '- **num_words_considered**: the count of words that were included in calculating the metrics\n', '- **freq_of_female_gender_definition_words**: The number of times any of the female gendered words occur in the corpus\n', '- **freq_of_male_gender_definition_words**: The number of times any of the male gendered words occur in the corpus\n', '- **freq_of_non_binary_gender_definition_words**: The number of times any of the non-binary gendered words occur in the corpus\n', '- **jsd**: The Jensen-Shannon divergence between the word probabilities conditioned on male and female gendered words. This is `JSD( p(w|M) || p(w|F) )`, where `JSD(q||p)` is the average KL divergence between `q` and `m`, and between `p` and `m`, where m is the average distribution `(p+q)/2`.\n', '\n', '### Token Based Metrcs\n', '\n', 'A `dict` containing object containing per word bias statistics that can be included as part of the metrics dict object by the key `token_based_metrics`. These statistics will be returned if `output_word_list=True`.\n', 'By Token:\n', '\n', '- **frequency**: The frequency of the token (the number of times it appears in the document): `c[w,.]`\n', '- **male_count**: the number of times the word occurs within context of a male gendered word: `c[w,M]`\n', '- **female_count**: the number of times the word occurs within context of a female gendered word: `c[w,F]`\n', '- **non_binary_count**: the number of times the word occurs within context of a male gendered word: `c[w,NB]`\n', '- **female_conditional_prob**: the conditional probability of the token occurring in context with a female gendered word: `p(w|F)`\n', '- **male_conditional_prob**: the conditional probability of the token occurring in context with a male gendered word: `p(w|M)`\n', '- **bias_ratio**: log(male_count / female_count) the more positive the value, the more biased the word is towards being associated with male gendered word, the more negative the value the more biased the word is towards being associated with female gendered. Each value is `log( c[w,M] / c[w,F] )`. A value of zero means that this word is equally likely to appear co-occurring with words in the female list as the male list (positive indicates more co-occurrence with male words; negative indicates more co-occurrence with female words).\n', '- **non_binary_bias_ratio**: log((male_count + female_count) / non_binary_count) the more positive the value, the more biased the word is towards being associated with a binary gendered word. A value of zero means the word has non-binary gender bias associated with it\n', '- **bias_conditional_ratio**: log( male_cond_prob/female_cond_prob ) the more positive the value, the more biased the word is towards being associated with male gendered word, the more negative the value the more biased the word is towards being associated with female gendered. Each value is `log( p(w|M) / p(w|F) )`. A value of zero means that the probability of this word co-occurring with words in the female list is equal to the probability of co-occurring with words in the male list (positive indicates more likely co-occurrence with male words; negative indicates more likely co-occurrence with female words).\n', '- **non_binary_bias_conditional_ratio**: log( (male_cond_prob+female_cond_prob) / non_binary_cond_prob ) the more positive the value, the more biased the word is towards being associated with binary gendered words; the more negative the value the more biased the word is towards being associated with a non-binary gendered word. A value of zero means the word has no gender bias associated with it.\n', '\n', '# <a name=""interpret""></a>\n', '## Metric Scores, Benchmarking and Interpretation\n', '\n', ""A detailed benchmarking was conducted to evaluate Genbit's performance across different samples and quantities of gender bias in the corpora/datasets.\n"", '\n', 'The score interpretation depends on two key factors,\n', '\n', 'a) The percentage of male or female gendered definition words\n', '\n', 'b) Average bias condition absolute score (genbit_score)\n', '\n', 'It is observed that With the increase in the gendered definition word percentage the Genbit Score tends to surge, demonstrating the presence of gender bias.\n', '\n', 'A detailed benchmarking is conducted to study the correlation of score ranges across different datasets and to examine how genderbias could influence the overall machine learning task using multilingual parallel datasets[Winogender-schema, WinoMT, Curated-WinoMT, IMDB, TedTalks and few others].\n', '\n', '**Table1: GenBit V2 Reference Score Range for biased datasets.**\n', '| Language | Score Range | Data Size | Bias % Indicator<br>(moderate-high) |\n', '|:--------: |------------- |:------------: |:-----------------------------------: |\n', '| EN | 0.30-1.0+ | >400 Samples | > 0.30 |\n', '| IT | 0.50-1.5+ | >400 Samples | > 1.00 |\n', '| DE | 0.60-2.4+ | >200 Samples | > 0.60 |\n', '| ES | 0.60-2.5+ | >400 Samples | > 0.60 |\n', '| FR | 0.50-1.3+ | >200 Samples | > 0.60 |\n', '| RU | 0.80-2.3+ | >400 Samples | > 1.10+ |\n', '\n', ""The score ranges are derived from certain type of datasets and may vary with datasets. The bias indicator percentage can aid in understanding the degree of biased a dataset can be. A genbit score of greater than the value provided in the last column indicates observable gender bias in the data set that may impact any resulting model trained on the dataset negatively (we would dub this 'moderate' gender bias). The higher this value the great the gender bias in the dataset. \n"", '\n', ""It is recommended as a best practice to use both the **genbit_score** as well as observe the values given for **percentage_of_male/female/non-binary_gender_definition_words** to provide some indication of the reliability of the **genbit_score**. In a 'naturally' distributed dataset you would expect that the percentage values for the male/female/non-binary gender definition words not to be overly skewed e.g. if the value observed was 10% male_gender_definition_words, 90% female_gender_definition_words, 0% non-binary_gender_definition_words this would potentially indicate quality concerns with the dataset as such a extreme skew is unlikely (and definitely undesirable) in a dataset. \n"", '\n', '# <a name=""citation""></a>\n', '## Citation\n', '<a>\n', '<pre>\n', '@article{sengupta2021genbit,\n', '  title={GenBiT: measure and mitigate gender bias in language datasets},\n', '  author={Sengupta, Kinshuk and Maher, Rana and Groves, Declan and Olieman, Chantal},\n', '  journal={Microsoft Journal of Applied Research},\n', '  year={2021},\n', '  volume={16},\n', '  pages={63--71}}\n', '}\n', '</pre>\n', '</a>\n', '<a href=""https://www.microsoft.com/en-us/research/uploads/prod/2021/10/MSJAR_Genbit_Final_Version-616fd3a073758.pdf"">Paper link</a>\n', '  \n', '  \n', '# <a name=""links""></a>\n', '## Useful Links\n', '\n', '+ [Get started](notebooks/quickstart_sample_notebook.ipynb) using a sample Jupyter notebook.\n', '+ [Identifying and Reducing Gender Bias in Word-Level Language Models](https://arxiv.org/pdf/1904.03035.pdf): Bordia and Bowman paper that describes the approach that GenBit is based on.\n', '+ [Winogender](https://github.com/rudinger/winogender-schemas) Winogender data set; we use samples from these dataset as part of the GenBit tests and in our sample Jupyter notebook.\n', '\n', '# <a name=""contributing""></a>\n', '## Contributing\n', '\n', 'This project welcomes contributions and suggestions.  Most contributions require you to agree to a\n', 'Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\n', 'the rights to use your contribution. For details, visit https://cla.opensource.microsoft.com.\n', '\n', 'When you submit a pull request, a CLA bot will automatically determine whether you need to provide\n', 'a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions\n', 'provided by the bot. You will only need to do this once across all repos using our CLA.\n', '\n', 'This project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\n', 'For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\n', 'contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n', '\n', '\n', '# <a name=""trademarks""></a>\n', '## Trademarks\n', '\n', 'This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft \n', 'trademarks or logos is subject to and must follow \n', ""[Microsoft's Trademark & Brand Guidelines](https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general).\n"", 'Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship.\n', ""Any use of third-party trademarks or logos are subject to those third-party's policies.\n"", '\n', '# <a name=""authors""></a>\n', '## Authors and acknowledgment\n', '\n', 'The original GenBit tool was co-authored by (listed in alphabetical order) Declan Groves, Chantal Olieman, Kinshuk Sengupta, David Riff, Eshwar Stalin, Marion Zepf.\n', '\n', 'The team members behind the open source release of the tool are (listed in alphabetical order) Chad Atalla, Hal Daumé III, Declan Groves, Mehrnoosh Sameki, Kinshuk Sengupta, and Marion Zepf.\n']"
Responsible+AI,microsoft/responsible-ai-toolbox-mitigations,microsoft,https://api.github.com/repos/microsoft/responsible-ai-toolbox-mitigations,33,3,11,"['https://api.github.com/users/mrfmendonca', 'https://api.github.com/users/akshara-msft', 'https://api.github.com/users/marah-abdin', 'https://api.github.com/users/irinasp', 'https://api.github.com/users/morrissharp', 'https://api.github.com/users/mesameki', 'https://api.github.com/users/microsoftopensource', 'https://api.github.com/users/danyrouh', 'https://api.github.com/users/ms-kashyap', 'https://api.github.com/users/dependabot%5Bbot%5D', 'https://api.github.com/users/akshararama']",Python,2023-03-21T13:09:07Z,https://raw.githubusercontent.com/microsoft/responsible-ai-toolbox-mitigations/main/README.md,"['# Responsible AI Mitigations\n', '\n', '\n', 'This Responsible-AI-Toolbox-Mitigations repo consists of a python library that aims to empower data scientists and ML developers to measure their dataset balance and representation of different dataset cohorts, while having access to mitigation techniques they could incorporate to mitigate errors and fairness issues in their datasets. Together with the measurement and mitigation steps, ML professionals are empowered to build more accurate and fairer models.\n', '\n', 'This repo is a part of the [Responsible AI Toolbox](https://github.com/microsoft/responsible-ai-toolbox#responsible-ai-toolbox), a suite of tools providing a collection of model and data exploration and assessment user interfaces and libraries that enable a better understanding of AI systems. These interfaces and libraries empower developers and stakeholders of AI systems to develop and monitor AI more responsibly, and take better data-driven actions.\n', '\n', '\n', '<p align=""center"">\n', '<img src=""./docs/imgs/responsible-ai-toolbox-mitigations.png"" alt=""ResponsibleAIToolboxMitigationsOverview"" width=""750""/>\n', '\n', 'The Responsible AI Mitigations Library helps AI practitioners explore different measurements and mitigation steps that may be most appropriate when the model underperforms for a given data cohort. The library currently has three modules:\n', '\n', '- **DataProcessing** offers mitigation techniques for improving model performance for specific cohorts.\n', '- **DataBalanceAnalysis** provides metrics for diagnosing errors that originate from data imbalance either on class labels or feature values.\n', '- **Cohort** provides classes for handling and managing cohorts, which allows the creation of custom pipelines for each cohort in an easy and intuitive interface. The module also provides techniques for learning different decoupled estimators (models) for different cohorts and combining them in a way that optimizes different definitions of group fairness.\n', '\n', '\n', 'In this library, we take a **targeted approach to mitigating errors** in Machine Learning models. This is complementary and different from the traditional blanket approaches which aim at maximizing a single-score performance number, such as overall accuracy, by merely increasing the size of traning data or model architecture. Since blanket approaches are often costly but also ineffective for improving the model in areas of poorest performance, with targeted approaches to model improvement we focus the improvement efforts in areas previously identified to have more errors and their underlying diagnoses of error. For example, if a practitioner has identified that the model is underperforming for a cohort of interest by using Error Analysis in the Responsible AI Dashboard, they may also continue the debugging process by finding out through Data Balance Analysis and find out that there is class imbalance for this particular cohort. To mitigate the issue, they then focus on improving class imbalance for the cohort of interest by using the Responsible AI Mitigations library. This and several other examples in the documentation of each mitigation function illustrate how targeted approaches may help practitioner best at mitigation giving them more control in the model improvement process.\n', '\n', '\n', '## Installation\n', '\n', 'Use the following pip command to install the Responsible AI Toolbox. Make sure you are using Python 3.7, 3.8, 3.9 or 3.10. If running in jupyter, please make sure to restart the jupyter kernel after installing. There are three installation options for the ``raimitigations`` package:\n', '\n', '* To install the minimum dependencies, use:\n', '\n', '```\n', 'pip install raimitigations\n', '```\n', '\n', '* To install the minimum dependencies + the packages required to run all of the notebooks in the ``notebooks/`` folder:\n', '\n', '```\n', 'pip install raimitigations[all]\n', '```\n', '\n', '* To install all the dependencies used for development (such as ``pytest``, for example), use:\n', '\n', '```\n', 'pip install raimitigations[dev]\n', '```\n', '\n', '## Documentation\n', '\n', 'To learn more about the supported dataset measurements and mitigation techniques covered in the **raimitigations** package, [please check out this documentation.](https://responsible-ai-toolbox-mitigations.readthedocs.io/en/latest/)\n', '\n', '\n', '\n', '## Data Balance Analysis: Examples\n', '\n', '- [Data Balance Analysis Walk Through](notebooks/databalanceanalysis/data_balance_overall.ipynb)\n', '- [Data Balance Analysis Adult Census Example](notebooks/databalanceanalysis/data_balance_census.ipynb)\n', '- [End to End Notebook](notebooks/data_balance_e2e.ipynb)\n', '\n', '## Data Processing/Mitigations: Examples\n', '\n', 'Here is a set of tutorial notebooks that aim to explain how to use each one of the mitigation\n', 'methods offered in the **dataprocessing** module.\n', '\n', '- [Encoders](notebooks/dataprocessing/module_tests/encoding.ipynb)\n', '- [Scalers](notebooks/dataprocessing/module_tests/scaler.ipynb)\n', '- [Basic Imputer](notebooks/dataprocessing/module_tests/basic_imputation.ipynb)\n', '- [Iterative Imputer](notebooks/dataprocessing/module_tests/iterative_imputation.ipynb)\n', '- [KNN Imputer](notebooks/dataprocessing/module_tests/knn_imputation.ipynb)\n', '- [Sequential Feature Selection](notebooks/dataprocessing/module_tests/feat_sel_sequential.ipynb)\n', '- [Feature Selection using Catboost](notebooks/dataprocessing/module_tests/feat_sel_catboost.ipynb)\n', '- [Identifying correlated features: tutorial](notebooks/dataprocessing/module_tests/feat_sel_corr_tutorial.ipynb)\n', '- [Data Rebalance using imblearn](notebooks/dataprocessing/module_tests/rebalance_imbl.ipynb)\n', '- [Data Rebalance using SDV](notebooks/dataprocessing/module_tests/rebalance_sdv.ipynb)\n', ""- [Using scikit-learn's Pipeline](notebooks/dataprocessing/module_tests/pipeline_test.ipynb)\n"", '\n', 'Here is a set of case study scenarios where we use the transformations available in the **dataprocessing**\n', 'module in order to train a model for a real-world dataset.\n', '\n', '- [Simple Example](notebooks/dataprocessing/module_tests/model_test.ipynb)\n', '- [Case Study 1](notebooks/dataprocessing/case_study/case1.ipynb)\n', '- [Case Study 2](notebooks/dataprocessing/case_study/case2.ipynb)\n', '- [Case Study 3](notebooks/dataprocessing/case_study/case3.ipynb)\n', '\n', '## Handling Cohorts\n', '\n', 'Here is a set of tutorial notebooks that aim to explain how to manage cohorts.\n', '\n', '- [Creating Single Cohorts](notebooks/cohort/cohort_definition.ipynb)\n', '- [Creating Different Pipelines for each Cohort](notebooks/cohort/cohort_manager.ipynb)\n', '- [Different Pre-processing Scenarios using cohorts](notebooks/cohort/cohort_manager_scenarios.ipynb)\n', '- [Using Decoupled Classifiers](notebooks/cohort/decoupled.ipynb)\n', '\n', 'Here is a set of case study notebooks showing how creating customized dataprocessing pipelines for each\n', 'cohort can help in some scenarios.\n', '\n', '- [Cohort Case Study 1](notebooks/cohort/case_study/case_1.ipynb)\n', '- [Cohort Case Study 1 - Rebalancing only specific cohorts](notebooks/cohort/case_study/case_1_rebalance.ipynb)\n', '- [Cohort Case Study 1 - Using RAI Toolbox](notebooks/cohort/case_study/case_1_dashboard.ipynb)\n', '- [Cohort Case Study 2](notebooks/cohort/case_study/case_2.ipynb)\n', '- [Cohort Case Study 3](notebooks/cohort/case_study/case_3.ipynb)\n', '- [Decoupled Classifier Case 1](notebooks/cohort/case_study/decoupled_class/case_1.ipynb)\n', '- [Decoupled Classifier Case 2](notebooks/cohort/case_study/decoupled_class/case_2.ipynb)\n', '- [Decoupled Classifier Case 3](notebooks/cohort/case_study/decoupled_class/case_3.ipynb)\n', '\n', '\n', '\n', '## Dependencies\n', '\n', '**RAI Toolbox Mitigations** uses several libraries internally. The direct dependencies are the following:\n', '\n', '- [Numpy](https://numpy.org/)\n', '- [Pandas](https://pandas.pydata.org/)\n', '- [SciPy](https://scipy.org/)\n', '- [Scikit Learn](https://scikit-learn.org/stable/index.html)\n', '- [ResearchPY](https://pypi.org/project/researchpy/)\n', '- [Statsmodels](https://www.statsmodels.org/stable/index.html)\n', '- [Imbalanced Learn](https://imbalanced-learn.org/stable/)\n', '- [SDV](https://pypi.org/project/sdv/)\n', '- [CatBoost](https://catboost.ai/en/docs/)\n', '- [XGBoost](https://xgboost.readthedocs.io/en/stable/python/python_intro.html)\n', '- [MLxtend](https://pypi.org/project/mlxtend/)\n', '- [UCI Dataset](https://pypi.org/project/uci-dataset/)\n', '\n', '## Contributing\n', '\n', 'This project welcomes contributions and suggestions. Most contributions require you to agree to a\n', 'Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\n', 'the rights to use your contribution. For details, visit https://cla.opensource.microsoft.com.\n', '\n', 'When you submit a pull request, a CLA bot will automatically determine whether you need to provide\n', 'a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions\n', 'provided by the bot. You will only need to do this once across all repos using our CLA.\n', '\n', 'This project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\n', 'For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\n', 'contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n', '\n', '### Installing Using ``dev`` Mode\n', '\n', 'After cloning this repo and moving to its root folder, install the package in editable mode with the development dependencies using:\n', '\n', '```console\n', '> pip install -e .[dev]\n', '```\n', '\n', '### Pre-Commit\n', '\n', 'This repository uses pre-commit hooks to guarantee that the code format is kept consistent. For development, make sure to\n', 'activate pre-commit before creating a pull request. Any code pushed to this repository is checked for code consistency using\n', 'Github Actions, so if pre-commit is not used when doing a commit, there is a chance that it fails in the format check workflow.\n', 'Using pre-commit will avoid this.\n', '\n', 'To use pre-commit with this repository, first install pre-commit (**NOTE:** when installing the package with the ``[dev]`` tag, the\n', '``pre-commit`` package will already be installed):\n', '\n', '```console\n', '> pip install pre-commit\n', '```\n', '\n', 'After installed, navigate to the root directory of this repository and activate pre-commit through the following command:\n', '\n', '```console\n', '> pre-commit install\n', '```\n', '\n', 'With pre-commit installed and activated, whenever you do a new commit, pre-commit will check all new code using the pre-commit hooks configured in the *.pre-commit-config.yaml* file, located in the root of the repository. Some of the hooks might make formatting changes to some of the files commited. If any file is changed or if any other hook fails, the commit will fail. If that happens, make the necessary modifications, add the files to the commit and try commiting one more time. Do this until all hooks are successful. Note that these same checks will be done after pushing anything, so if your commit was successful while using pre-commit, it will pass in the format check workflow as well.\n', '\n', '### Updating the Docs\n', '\n', 'The documentation is built using [Sphinx](https://www.sphinx-doc.org/en/master/), [Pandoc](https://pandoc.org/installing.html), and [Graphviz](https://graphviz.org/) (to build the class diagrams). Graphviz and Pandoc must be installed separately ([detailed instructions here for Graphviz](https://graphviz.org/download/) and [here for Pandoc](https://pandoc.org/installing.html)). On Linux, this can be done with `apt` or `yum` (depending on your distribution):\n', '\n', '```console\n', '> sudo apt install graphviz pandoc\n', '```\n', '\n', '```console\n', '> sudo yum install graphviz pandoc\n', '```\n', '\n', 'Make sure Graphviz and Pandoc are installed before recompiling the docs. After that, update the documentation files, which are all located inside the ```docs/``` folder. Finally, use:\n', '\n', '```console\n', '> cd docs/\n', '> make html\n', '```\n', '\n', 'To view the documentation, open the file ```docs/_build/html/index.html``` in your browser.\n', '\n', '**Note for Windows users:** if you are trying to update the docs in a Windows environment, you might get an error regarding the *_sqlite3* module:\n', '\n', '```\n', 'ImportError: DLL load failed while importing _sqlite3: The specified module could not be found.\n', '```\n', '\n', 'To fix this, following the instructions found [in this link](https://www.dev2qa.com/how-to-fix-importerror-dll-load-failed-while-importing-_sqlite3-the-specified-module-could-not-be-found/).\n', '\n', '\n', '## Support\n', '### How to file issues and get help\n', '\n', 'This project uses GitHub Issues to track bugs and feature requests. Please search the existing\n', 'issues before filing new issues to avoid duplicates.  For new issues, file your bug or\n', 'feature request as a new Issue.\n', '\n', 'For help and questions about using this project, please post your question in Stack Overflow using the ``raimitigations`` tag.\n', '\n', '### Microsoft Support Policy\n', '\n', 'Support for this package is limited to the resources listed above.\n', '\n', '## Trademarks\n', '\n', 'This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft\n', 'trademarks or logos is subject to and must follow\n', ""[Microsoft's Trademark & Brand Guidelines](https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general).\n"", 'Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship.\n', ""Any use of third-party trademarks or logos are subject to those third-party's policies.\n"", '\n', '## Research and Acknowledgements\n', '\n', '**Current Maintainers:** [Marah Abdin](https://github.com/marah-abdin), [Matheus Mendonça](https://github.com/mrfmendonca), [Dany Rouhana](https://github.com/danyrouh), [Mark Encarnación](https://github.com/markenc)\n', '\n', '**Past Maintainers:** [Akshara Ramakrishnan](https://github.com/akshara-msft), [Irina Spiridonova](https://github.com/irinasp)\n', '\n', '**Research Contributors:** [Besmira Nushi](https://github.com/nushib), [Rahee Ghosh Peshawaria](https://github.com/raghoshMSFT), [Ece Kamar](https://www.ecekamar.com/)\n']"
Responsible+AI,leestott/ResponsibleAI,leestott,https://api.github.com/repos/leestott/ResponsibleAI,2,3,1,['https://api.github.com/users/leestott'],Python,2021-02-18T15:58:41Z,https://raw.githubusercontent.com/leestott/ResponsibleAI/master/README.md,"['---\n', 'languages:\n', '  - python\n', 'products:\n', '  - Azure Machine Learning Service\n', 'description: ""Responsible AI 2020""\n', '---\n', '\n', '![App Overview](/docs/rai.jpeg)\n', '\n', '# Responsible AI 2020 - Detect if a patient needs treatment based on heart-disease data\n', '\n', '# Introduction\n', '\n', 'This repository wishes to show how using the latest machine learning features in Azure Machine Learning and Microsoft open-source toolkits we can put the responsible AI principles into practice.\n', 'These tools empower data scientists and developers to understand ML models, protect people and their data, and control the end-to-end ML process. \n', '\n', 'For this, we will develop a solution that wishes to detect if a person is suitable for receiving treatment for heart disease or not. We will use a dataset that will help us classify patients that have heart disease from those that doesn’t. Using this example, we will show how to ensure ethical, transparent and accountable use of AI in a medical scenario.\n', '\n', 'This example ilustrates how to put the responsible AI principles into practice throughout the different stages of Machine Learning pipeline (Preprocessing, Training/Evaluation, Register Model).\n', '\n', 'Within this repository, you will find all the resources needed to create and simulate a medical scenario using Azure Machine Learning Service with Responsible AI techniques such as:\n', '\n', '1. [Differential Privacy](https://github.com/opendifferentialprivacy)\n', '2. [FairLearn](https://github.com/fairlearn/fairlearn)\n', '3. [InterpretML](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-machine-learning-interpretability)\n', '4. [DataDrift](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-monitor-data-drift)\n', '\n', '> **The goal of this project is to detect if a person is suitable for receiving a treatment for heart disease.**\n', '\n', '# Objectives\n', '\n', '- Understand how Responsible AI techniques work.\n', '- Use Azure Machine learning Service to create a Machine Learning Pipeline with these Responsible AI techniques.\n', '- Prevent data exposure with differential privacy.\n', '- Mitigate model unfairness.\n', '- Interpret and explain models.\n', '\n', '# Why use Azure Machine Learning Service?\n', '\n', 'Azure Machine Learning Service give to use the capability to use MLOps techniques, it empowers data scientists and app developers to help bring ML models to production.\n', '\n', 'This MLOps functionalities that Azure Machine Learning have, enables you to track / version / audit / certify / re-use every asset in your ML lifecycle and provides orchestration services to streamline managing this lifecycle.\n', '\n', '![mlops](docs/ml-lifecycle.png)\n', '\n', '## What are the key challenges we wish to solve with MLOps?\n', '\n', '![mlops_flow](docs/mlops.png)\n', '\n', '**Model reproducibility & versioning**\n', '\n', '- Track, snapshot & manage assets used to create the model\n', '- Enable collaboration and sharing of ML pipelines\n', '\n', '**Model packaging & validation**\n', '\n', '- Support model portability across a variety of platforms\n', '- Certify model performance meets functional and latency requirements\n', '\n', '**Model auditability & explainability**\n', '\n', '- Maintain asset integrity & persist access control logs\n', '- Certify model behavior meets regulatory & adversarial standards\n', '\n', '**Model deployment & monitoring**\n', '\n', '- Release models with confidence\n', '- Monitor & know when to retrain by analyzing signals such as data drift\n', '\n', 'if you want to know more about how we have implemented the machine learning workflow using Azure Machine Learning Studio, please, see the following [file](docs/ResponsibleAI_Presentation.pdf)\n', '\n', '# Understanding (InterpretML)\n', '\n', '![InterpretML](docs/interpretML.png)\n', '\n', 'As ML integrates deeply into our day-to-day business processes, transparency is critical. Azure Machine Learning helps not only to understand model behavior, but also to assess and mitigate bias.\n', '\n', 'Interpretation and model’s explanation in Azure Machine Learning is based on the InterpretMLtoolset. It helps developers and data scientists to understand the models’ behavior and provide explanations about the decisions made during the model’s inference. Thus, it provides transparency to customers and business stakeholders.\n', '\n', 'Use model interpretation capability to:\n', '\n', '1. **Create accurate ML models.**\n', '\n', '2. **Understand the behavior of a wide variety of models, including deep neural networks, during the learning and inference phases.**\n', '\n', '![InterpretML](docs/interpretML_2.png)\n', '\n', '3. **Perform conditional analysis to determine the impact on model predictions when characteristic values are changed.**\n', '\n', '![InterpretML](docs/interpretML_3.png)\n', '\n', '## Evaluation and mitigation of model bias (FairLearn)\n', '\n', '![FairLearn](docs/fairlearn.png)\n', '\n', 'Today, a challenge with the creation of artificial intelligence systems is the inability to prioritize impartiality. By using Fairlearn with Azure Machine Learning,developers and data scientists can leverage specialized algorithms to ensure more unbiased results for everyone.\n', '\n', 'Use impartiality capabilities to:\n', '\n', '1. **Evaluate the bias of models during learning and implementation.**\n', '\n', '2. **Mitigate bias while optimizing model performance.**\n', '\n', '3. **Use interactive visualizations to compare a set of recommended models that mitigate bias.**\n', '\n', '![FairLearn](docs/fairlearn_2.png)\n', '\n', '![FairLearn](docs/fairlearn_3.png)\n', '\n', '# Protection (Differential Privacy)\n', '\n', '|                                                     |                                                     |     |\n', '| :-------------------------------------------------: | :-------------------------------------------------: | :-: |\n', '| ![Grid_1](docs/differential-privacy.png)   | ![Grid_2](docs/differential-privacy_2.png)  |\n', '| ![Grid_3](docs/differential-privacy_3.png) | ![Grid_4](docs/differential-privacy_4.png) |\n', '| ![Grid_5](docs/differential-privacy_5.png) | ![Grid_6](docs/differential-privacy_6.png) |\n', '\n', 'ML is increasingly used in scenarios that encompass sensitive information, such as census and patient medical data. Current practices, such as writing or masking data, may be limiting ML. To address this issue, confidential machine learning and differential privacy techniques can be used to help organizations create solutions while maintaining data privacy and confidentiality.\n', '\n', '## Avoid data exposure with differential privacy\n', '\n', ""By using the new Differential Privacy Toolkit with Azure Machine Learning, data science teams can create ML solutions that preserve privacy and help prevent the re-identification of a person's data. These differential privacy techniques have been developed in collaboration with researchers from the Institute of Quantitative Social Sciences (IQSS) and the Harvard School of Engineering.\n"", '\n', 'Differential privacy protects sensitive information with:\n', '\n', '1. **Statistical noise injection into the data to help prevent the disclosure of private information, without a significant loss of accuracy.**\n', '\n', '2. **Exposure risk management with budget monitoring for information used in individual consultations and with greater limitation of consultations, as appropriate.**\n', '\n', '## Data protection with sensitive machine learning\n', '\n', 'In addition to data privacy, organizations seek to ensure the security and confidentiality of all ML resources.\n', '\n', 'To enable deployment and learning of secure models, Azure Machine Learning provides a robust set of network and data protection capabilities. This includes support for Azure virtual networks, private links to connect to machine learning workspaces, dedicated compute hosts, and client managed keys for encryption in transit and at rest.\n', '\n', 'On this secure basis, Azure Machine Learning also enables Microsoft data science teams to build models with sensitive data in a secure environment, without the ability to view data. The confidentiality of all machine learning resources is preserved during this process. This approach is fully compatible with open source machine learning frameworks and a wide range of hardware options. We are pleased to offer these confidential machine learning capabilities to all developers and data scientists later this year.\n', '\n', '# Control (Data Drift)\n', '\n', '![Differential Privacy](docs/drift-ui.png)\n', '\n', 'To build responsibly, the ML development process must be repeatable, reliable, and responsible to stakeholders. Azure Machine Learning enables decision makers, auditors, and all ML lifecycle members to support a responsible process.\n', '\n', '## Tracking ML resources through audit logs\n', '\n', 'Azure Machine Learning provides capabilities to automatically track lineage and maintain an audit trail of ML resources. Details such as execution history, learning environment, and explanations of data and models are captured in a central log, allowing organizations to meet various auditing requirements.\n', '\n', '![Differential Privacy](docs/data_drift.png)\n', '\n', '## Brief explanation of used Azure Machine Learning Services\n', '\n', '| Technology                     | Description                                                                                                                          |\n', '| ------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------ |\n', '| Azure Machine Learning Service | Cloud services to train, deploy and manage machine learning models                                                                   |\n', '| AutoML                         | Process of automating the time consuming, iterative tasks of machine learning model development                                      |\n', '| Differential Privacy           | Process of protecting personal information and users identity                                      |\n', '| Interpret ML                   | Interpret a model by using an explainer that quantifies the amount of influence each feature contribues to the predicted label       |\n', ""| FairLearn                      | Python package that empowers developers of AI systems to assess their system's fairness and mitigate any observed unfairness issues. |\n"", '| DataDrift                      | Data drift is the change in model input data that leads to model performance degradation                                             |\n', '\n', '## Final Result Azure Machine Learning Pipeline\n', '\n', '### Initial Azure Machine Learning Pipeline\n', '\n', '![pipeline](./docs/pipeline.png)\n', '\n', '### Re-train Azure Machine Learning Pipeline with new model metrics validation\n', '\n', '![pipeline_retrain](./docs/pipeline_retrain_check_model_metrics.png)\n', '\n', '## Understanding the Heart-Disease dataset\n', '\n', 'This database contains 76 attributes, but all published experiments refer to using a subset of 14 of them. In particular, the Cleveland database is the only one that has been used by ML researchers to this date. The ""goal"" field refers to the presence of heart disease in the patient. It is integer valued from 0 (no presence) to 1.\n', '\n', 'Download scratch dataset from: http://archive.ics.uci.edu/ml/datasets/Heart+Disease or https://www.kaggle.com/ronitf/heart-disease-uci\n', '\n', '#### Original Columns Dataset:\n', '\n', '  - **age:** age in years\n', '  - **sex:**\n', '    - 0: female\n', '    - 1: male\n', '  - **chest_pain_type:** chest pain type\n', '    - 1: typical angina\n', '    - 2: atypical angina\n', '    - 3: non-anginal pain\n', '    - 4: asymptomatic\n', '  - **resting_blood_pressure:** resting blood pressure (in mm Hg on admission to the hospital)\n', '  - **cholesterol:** serum cholestoral in mg/dl\n', '  - **fasting_blood_sugar:** (fasting blood sugar > 120 mg/dl) (1 = true; 0 = false)\n', '  - **rest_ecg:** resting electrocardiographic results\n', '    - 0: normal\n', '    - 1: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV)\n', ""    - 2: showing probable or definite left ventricular hypertrophy by Estes' criteria\n"", '  - **max_heart_rate_achieved:** maximum heart rate achieved\n', '  - **exercise_induced_angina:** exercise induced angina (1 = yes; 0 = no)\n', '  - **st_depression:** ST depression induced by exercise relative to rest\n', '  - **st_slope:** the slope of the peak exercise ST segment\n', '    - 1: upsloping\n', '    - 2: flat\n', '    - 3: downsloping\n', '  - **num_major_vessels:** number of major vessels (0-3) colored by flourosopy\n', '  - **thalassemia:**\n', '    - 3 = normal;\n', '    - 6 = fixed defect;\n', '    - 7 = reversable defect\n', '  - **target:** diagnosis of heart disease (angiographic disease status)\n', '    - 0: < 50% diameter narrowing\n', '    - 1: > 50% diameter narrowing\n', '\n', '### Attribution:\n', '\n', 'The authors of the databases have requested that any publications resulting from the use of the data include the names of the principal investigator responsible for the data collection at each institution. They would be:\n', '\n', '1. Hungarian Institute of Cardiology. Budapest: Andras Janosi, M.D.\n', '2. University Hospital, Zurich, Switzerland: William Steinbrunn, M.D.\n', '3. University Hospital, Basel, Switzerland: Matthias Pfisterer, M.D.\n', '4. V.A. Medical Center, Long Beach and Cleveland Clinic Foundation:Robert Detrano, M.D., Ph.D.\n', '\n', '### Responsible AI Dataset\n', '\n', ""The dataset we use in this repository is a customized one. In the Getting Started section, we explain how it is generated and which transformations were applied to create our new dataset. The dataset is based on UCI Heart Disease data. The original UCI dataset has by default 76 columns, but Kaggle provides a version containing 14 columns. We used Kaggle one. In this notebook, we'll explore the heart disease dataset.\n"", '\n', 'As part of the exploratory analysis and preprocessing of our data, we have applied several techniques that help us understand the data. The insights discovered (visualizations) were uploaded into an Azure ML Experiment. As part of the study, we took our target variable, and we analyzed it and checked its interaction with other variables.\n', '\n', ""The original dataset doesn't have any personal or sensible data that we can use it to identify a person or mitigate fairness, just Sex and Age. Therefore, for the purpose of this project and to show the capabilities of Differential Privacy and Detect Fairness techniques, we have created a notebook to generate a custom dataset with the following new columns and schema:\n"", '\n', '#### Custom columns base on original dataset:\n', '\n', '#### Original Columns Dataset:\n', '\n', '  - **age (Original)**\n', '  - **sex (Original)**\n', '  - **chest_pain_type: chest pain type (Original)**\n', '  - **resting_blood_pressure (Original)**\n', '  - **cholesterol (Original)**\n', '  - **fasting_blood_sugar (Original)**\n', '  - **rest_ecg (Original)**\n', '  - **max_heart_rate_achieved (Original)**\n', '  - **exercise_induced_angina (Original)**\n', '  - **st_depression (Original)**\n', '  - **st_slope (Original)**\n', '  - **num_major_vessels (Original)**\n', '  - **thalassemia (Original)**\n', '  - **target (Original)**\n', '\n', '#### Custom Columns Dataset:\n', '\n', '  - **state (custom)**\n', '  - **city (custom)**\n', '  - **address (custom)**\n', '  - **postal code (custom)**\n', '  - **ssn (social security card) (custom)**\n', '  - **diabetic (custom)**\n', '    - 0: not diabetic\n', '    - 1: diabetic\n', '  - **pregnant (custom)**\n', '    - 0: not pregnant\n', '    - 1: pregnant\n', '  - **ashtmatic (custom)**\n', '    - 0: not ashtmatic\n', '    - 1: ashtmatic\n', '  - **smoker (custom)**\n', '    - 0: not smoker\n', '    - 1: smoker\n', '  - **observations (custom)**\n', '\n', ""To generate the information related to state, address, city, postal code we have downloaded it from **https://github.com/EthanRBrown/rrad**. From this repository we are able to get a list of real, random addresses that geocode successfully (tested on Google's Geocoding API service). The address data comes from the OpenAddresses project, and all the addresses are in the public domain. The addresses are deliberately not linked to people or businesses; the only guarantee is that they are real addresses that geocode successfully.\n"", '\n', 'This *custom dataset* will be the dataset that the Azure ML steps will use. The name that we set to it was ""complete_patients_dataset.csv"". You can find it on *./dataset*\n', '\n', '# Getting started\n', '\n', 'The solution has this structure:\n', '\n', '```\n', '.\n', '├── dataset\n', '│   ├── complete_patients_dataset.csv\n', '│   ├── heart_disease_preprocessed_inference.csv\n', '│   ├── heart_disease_preprocessed_train.csv\n', '│   ├── uci_dataset.csv\n', '│   └── uci_dataset.yml\n', '├── docs (documentation images)\n', '├── infrastructure\n', '│   ├── Scripts\n', '│   │    └── Deploy-ARM.ps1\n', '│   ├── deployment.json\n', '│   ├── DeployUnified.ps1\n', '│   └── README.md\n', '├── src\n', '│   ├── automated-ml (notebook to run AutoML)\n', '│   ├── dataset-generator (notebook to generate dataset)\n', '│   ├── deployment\n', '│   ├── detect-fairness\n', '│   ├── differential-privacy\n', '│   ├── installation-libraries (notebook to install dependecies)\n', '│   ├── mlops-pipeline\n', '│   ├── monitoring\n', '│   ├── notebooks-settings\n', '│   ├── preprocessing\n', '│   ├── retrain\n', '│   └── utils\n', '├── .gitignore\n', '└── README.md\n', '```\n', '\n', 'To run this sample you have to do this steps:\n', '\n', '1. **Create infrastructure**\n', '2. **Run notebook to install dependencies**\n', '3. **Run Dataset Generator Notebook**\n', '4. **Publish the pipeline**\n', '5. **Submit pipeline using API**\n', '6. **Activate Data Drift Detector**\n', '7. **Activate re-train Step**\n', '\n', '## 1. Create infrastructure\n', '\n', 'We need a infrastructure in Azure to run the experiment. You can read more about the necessary infrastructure [here](./infrastructure/README.md).\n', '\n', 'To facilitate the task of creating the infrastructure, you can run the `infrastructure/DeployUnified.ps1` script. You have to indicate the **Resource Group**, the **Location** and the **Suscription Id**.\n', '\n', 'The final view of the Azure resource group will be like the following image:\n', '\n', '![resource-group](./docs/rg-view.png)\n', '\n', ""**Note:** The services you see marked with a red line will be created in the next steps. Don't worry about it!\n"", '\n', '## 2. Install Project dependencies\n', '\n', '## Install Responsible AI Requirements \n', '\n', 'Each notebook contains an environment.yml file listing all the necessary python libraries which are associated and required for the notebook execution.We recommend you use a conda environment.\n', '\n', '**Here is the basic recipe for using Conda to manage a project specific software stack.**\n', '\n', '`(base) $ cd project-dir`\n', '\n', '`(base) $ conda env create --prefix ./env --file environment.yml`\n', '\n', '`(base) $ conda activate ./env # activate the environment`\n', '\n', '`(/path/to/env) $ conda deactivate # done working on project (for now!)`\n', '\n', 'There are more details below on creating your conda environment\n', '\n', '### Libraries Required\n', '\n', 'The following libraries are required\n', '\n', '- pylint\n', '- numpy\n', '- pandas\n', '- ipykernel\n', '- joblib\n', '- sklearn\n', '- azureml-sdk\n', '- azureml-sdk[automl]\n', '- azureml-widgets\n', '- azureml-interpret\n', '- azureml-contrib-interpret\n', '- interpret-community\n', '- azureml-monitoring\n', '- opendp-whitenoise\n', '- opendp-whitenoise-core\n', '- matplotlib\n', '- seaborn\n', '- pandas-profiling\n', '- fairlearn\n', '- azureml-contrib-fairness\n', '- azureml-datadrift\n', '\n', '## Using Conda for Environments\n', '\n', 'The Notebook will automatically find all Jupyter kernels installed on the connected compute instance. To add a kernel to the compute instance:\n', '\n', 'Select Open terminal in the Notebook toolbar.\n', '\n', 'Use the Visual Studio Code terminal window to create a new environment. For example:\n', '\n', '- **Conda commands to create local env by environment.yml:** `conda env create -f environment.yml`\n', '- **Set conda env into jupyter notebook:** `python -m ipykernel install --user --name <environment_name> --display-name ""Python (<environment_name>)""`\n', '- **Activate the environment after creating newenv:** `conda activate <environment_name>`\n', '\n', '### Adding New Kernels (Optional)\n', '\n', '- **Install pip and ipykernel package to the new environment and create a kernel for that conda env**\n', '`conda install pip`\n', '`conda install ipykernel`\n', '`python -m ipykernel install --user --name newenv --display-name ""Python (newenv)""`\n', '\n', 'Any of the available Jupyter Kernels can be installed. https://github.com/jupyter/jupyter/wiki/Jupyter-kernels\n', '\n', '### Installation of Python Libraries (Optional)\n', '\n', '**Use the following to install the libraries:** `pip --disable-pip-version-check --no-cache-dir install pylint`\n', '\n', '**Or inline within a Juputer Notebook use:** `!pip install numpy`\n', '\n', 'You can now execute the notebooks successfully.\n', '\n', '### Virtual environments to execute Azure Machine Learning notebooks using Visual Studio Codespaces.(Optional)\n', '\n', 'This repository contains a labs to help you get started with Creating and deploying Azure machine learning module.\n', '\n', '[![Open in Visual Studio Online](https://img.shields.io/endpoint?style=social&url=https%3A%2F%2Faka.ms%2Fvso-badge)](https://online.visualstudio.com/environments/new?name=ResponsibleAI&repo=leestott/ResponsibleAI)\n', '\n', '## Manually creating a VS Online Container (Optional)\n', '\n', ""To complete the labs, you'll need the following:\n"", '\n', ""- A Microsoft Azure subscription. If you don't already have one, you can sign up for a free trial at <a href ='https://azure.microsoft.com' target='_blank'>https://azure.microsoft.com</a> or a Student Subscription at <a href ='https://aks.ms/azureforstudents' target='_blank'>https://aka.ms/azureforstudents</a>.\n"", '\n', ""- A Visual Studio Codespaces environment. This provides a hosted instance of Visual Studio Code, in which you'll be able to run the notebooks for the lab exercises. To set up this environment:\n"", '\n', ""    1. Browse to <a href ='https://online.visualstudio.com' target='_blank'>https://online.visualstudio.com</a>\n"", '    2. Click **Get Started**.\n', '    3. Sign in using the Microsoft account associated with your Azure subscription.\n', ""    4. Click **Create environment**. If you don't already have a Visual Studio Online plan, create one. This is used to track resource utlization by your Visual Studio Online environments. Then create an environment with the following settings:\n"", '        - **Environment Name**: *A name for your environment - for example, **MSLearn-create-deploy-azure-ml-module**.*\n', '        - **Git Repository**: leestott/create-deploy-azure-ml-module\n', '        - **Instance Type**: Standard (Linux) 4 cores, 8GB RAM\n', '        - **Suspend idle environment after**: 120 minutes\n', '    5. Wait for the environment to be created, and then click **Connect** to connect to it. This will open a browser-based instance of Visual Studio Code.\n', '\n', 'The current Visual Studio Codespaces Environment is based on Debian 10 there are some limitation to the Azure ML SDK with linux at present. Error on some notebooks may occur ensure the correct libraries and versions are installed using !pip install and please check library dependencies.\n', '\n', '### Using Azure Machine learning Notebooks (Optional)\n', '\n', '- Simply download the folder structure and upload the entire content to Azure Machine Learning Notebook \n', '\n', '![aml notebook](docs/aml_notebook_upload.PNG)\n', '\n', '- You now need to create a new compute instance for your notebook environment \n', '\n', '![aml compute](docs/aml_compute.PNG)\n', '\n', '- You now need to install the AML Prequestites to the Notebook Compute Host, to do this simply open a notebook and then select the open terminal. \n', '\n', '![aml compute terminal](docs/notebook_terminal.PNG)\n', '\n', '- select the terminal and install all the requirements using pip install \n', '\n', '## Jupyter Notebooks\n', '\n', 'In this project we have inside src folder many directories with jupyter notebook that you have to execute to obtain and complete the objective of this repository.\n', 'The folder src have:\n', '\n', '1. **automated-ml:** automated-ml.ipynb and environment.yml\n', '2. **dataset-generator:** dataset-generator.ipynb and environment.yml\n', '3. **detect-fairness:** fairlearn.ipynb and environment.yml\n', '4. **differential-privacy:** differential-privacy.ipynb and environment.yml\n', '5. **mlops pipelines:**\n', '   1. explain_automl_model_local.ipynb\n', '   2. mlops-publish-pipeline.ipynb\n', '   3. mlops-submit-pipeline.ipynb\n', '   4. environment.yml\n', '6. **monitoring:** datadrift-pipeline.ipynb and environment.yml\n', '7. **preprocessing:** exploratory_data_analysis.ipynb and environment.yml\n', '\n', 'Our recommendation is to use dedicated Conda environments for each of the Notebooks due to library and version dependencies if you are running this on a local machine non devcontainer you will need to create the conda enviroments via using conda navigator or execute the Conda installation before do anything inside these notebooks.\n', '\n', '## 3. Run Dataset Generator\n', '\n', 'Run `src/dataset-generator/dataset-generator.ipynb` to create the project dataset made from UCI Heart-Disease dataset specifically to Responsible AI steps.\n', 'See the dataset generated in the **./dataset** folder\n', '\n', '## 4. Publish the pipeline\n', '\n', 'Run `src/mlops-pipeline/mlops-publish-pipeline.ipynb` to create a machine learning service pipeline with Responsible AI steps and MLOps techniques that runs jobs unattended in different compute clusters.\n', '\n', 'You can see the run in the Azure Machine Learning Services Portal in the pipelines section of the portal.\n', '\n', '![Pipelines in portal](docs/pipelines.jpg)\n', '\n', '## 5. Submit pipeline using API Rest\n', '\n', 'Run `src/mlops-pipeline/mlops-submit-pipeline.ipynb` to execute/invoke this publishes the pipeline via REST endpoint.\n', '\n', 'You can see the run in the Azure Machine Learning Services Portal in the pipelines section of the portal.\n', '\n', '![Pipelines in portal](docs/pipelines_runs.jpg)\n', '\n', '## 6. Activate Data Drift Detector\n', '\n', 'Run `src/monitoring/datadrift-pipeline.ipynb` to create and execute data drift detector. At the end of this notebook, you will be able to make a request with new data in order to detect drift\n', '\n', 'Go to Azure Machine Learning portal models section. In the details tab now you can see a new section about Data Drift Detector status and configuration.\n', '\n', '![Data Drift in portal](./src/monitoring/images/drift_service.png)\n', '\n', '## 7. Execute pipeline with retrain configuration\n', '\n', 'If Data Drift coefficient is greater than the configured threshold a new alert will be sent to the final user. In that moment, the user will can execute the re-train pipeline in order to improve the performance of the model taking into account the new collected data.\n', '\n', 'Go to Azure ML Portal Pipelines section. Click on the last pipeline version. Then, you will have to click on submit button. Now, you should see something like the following image:\n', '\n', '![Retrain pipeline in portal](docs/retrain_pipeline.png)\n', '\n', 'First, select an existing experiment or create a new one for this new pipeline execution.\n', 'Finally, in the same view, to do the retrain process correctly some parameters have to change:\n', '\n', '1. **use_datadrift** = False\n', '2. **retrain_status_differential_privacy_step** = True\n', '3. **retrain_status_preprocessing_step** = True\n', '3. **update_deployment_deploy_step** = True\n', '\n', 'Once the parameters are set, we have everything ready to execute the retraining process!\n', '\n', '![Retrain parameters in portal](/docs/retrain_pipeline_parameters.png)\n', '\n', '# References\n', '\n', '- [Azure Machine Learning(Azure ML) Service Workspace](https://docs.microsoft.com/en-us/azure/machine-learning/service/overview-what-is-azure-ml)\n', '- [Azure ML CLI](https://docs.microsoft.com/en-us/azure/machine-learning/service/reference-azure-machine-learning-cli)\n', '- [Azure Responsible AI](https://azure.microsoft.com/es-es/blog/build-ai-you-can-trust-with-responsible-ml/)\n', '- [Azure ML Samples](https://docs.microsoft.com/en-us/azure/machine-learning/service/samples-notebooks)\n', '- [Azure ML Python SDK Quickstart](https://docs.microsoft.com/en-us/azure/machine-learning/service/quickstart-create-workspace-with-python)\n', '- [Azure ML MLOps Quickstart](https://github.com/Microsoft/MLOps)\n', '- [Azure Machine learning](https://azure.microsoft.com/services/machine-learning)\n', '- [Create development environment for Machine learning](https://docs.microsoft.com/azure/machine-learning/service/how-to-configure-environment)\n', '- [AML Python SDK](https://docs.microsoft.com/azure/machine-learning/service/how-to-configure-environment)\n', '- [AML Pipelines](https://docs.microsoft.com/azure/machine-learning/service/how-to-create-your-first-pipeline)\n', '- [Getting started with Auto ML](https://docs.microsoft.com/azure/machine-learning/service/concept-automated-ml)\n', '- [Intro to AML – MS Learn](https://docs.microsoft.com/en-us/learn/modules/intro-to-azure-machine-learning-service)\n', '- [Automate model select with AML - MS Learn](https://docs.microsoft.com/en-us/learn/modules/automate-model-selection-with-azure-automl)\n', '- [Train local model with AML - MS Learn](https://docs.microsoft.com/en-us/learn/modules/train-local-model-with-azure-mls)\n', '\n', '**Tags: Azure Machine Learning Service, Machine Learning, Differential-Privacy, Fairlearn, MLOPs, Data-Drift, InterpretML**\n']"
Responsible+AI,visenger/Awesome-ML-Model-Governance,visenger,https://api.github.com/repos/visenger/Awesome-ML-Model-Governance,67,18,5,"['https://api.github.com/users/visenger', 'https://api.github.com/users/ionicsolutions', 'https://api.github.com/users/floer32', 'https://api.github.com/users/mikeldking', 'https://api.github.com/users/aenyne']",,2023-04-07T06:38:49Z,https://raw.githubusercontent.com/visenger/Awesome-ML-Model-Governance/main/README.md,"['# Awesome ML Model Governance\n', '\n', '## Model Governance, Ethics, Responsible AI\n', '\n', '1. [Book: ""Responsible AI"". 2022. by Patrick Hall, Rumman Chowdhury. O\'Reilly Media, Inc.](https://learning.oreilly.com/library/view/responsible-ai/9781098102425/)\n', '1. [Book: ""Practical Fairness"". 2020. By Aileen Nielsen. O\'Reilly Media, Inc.](https://learning.oreilly.com/library/view/practical-fairness/9781492075721/)\n', '1. [Book: ""Fairness and machine learning: Limitations and Opportunities."" Barocas, S., Hardt, M. and Narayanan, A., 2018.](https://fairmlbook.org/)\n', '1. [Book: ""The Framework for ML Governance"" by Kyle Gallatin. 2021.  O\'Reilly Media](https://learning.oreilly.com/library/view/the-framework-for/9781098100483/)\n', '1. [What are model governance and model operations? A look at the landscape of tools for building and deploying robust, production-ready machine learning models](https://www.oreilly.com/radar/what-are-model-governance-and-model-operations/)\n', '2. [Specialized tools for machine learning development and model governance are becoming essential. Why companies are turning to specialized machine learning tools like MLflow.](https://www.oreilly.com/ideas/specialized-tools-for-machine-learning-development-and-model-governance-are-becoming-essential)\n', '1. [What are model governance and model operations? – O’Reilly](https://www.oreilly.com/radar/what-are-model-governance-and-model-operations/)\n', '1. [AI Fairness 360, A Step Towards Trusted AI - IBM Research](https://www.ibm.com/blogs/research/2018/09/ai-fairness-360/)\n', '1. [Responsible AI](https://www.microsoft.com/en-us/ai/responsible-ai-resources)\n', '1. [Learn how to integrate Responsible AI practices into your ML workflow using TensorFlow](https://www.tensorflow.org/resources/responsible-ai)\n', '1. [ACM Conference on Fairness, Accountability, and Transparency (ACM FAccT)](https://facctconference.org/index.html)\n', '1. [Programming Fairness in Algorithms. Understanding and combating issues of fairness in supervised learning.](https://towardsdatascience.com/programming-fairness-in-algorithms-4943a13dd9f8)\n', '1. [Secure, privacy-preserving and federated machine learning in medical imaging](https://www.nature.com/articles/s42256-020-0186-1)\n', '1. [Explainable AI (Gartner Prediction for 2023)](https://www.gartner.com/en/conferences/apac/data-analytics-india/gartner-insights/rn-top-10-data-analytics-trends/explainable-ai)\n', ""1. [What We've Learned to Control. By Ben Recht](https://www.argmin.net/2020/06/29/tour-revisited/)\n"", '1. [Practical Data Ethics](https://ethics.fast.ai/)\n', '1. Vasudevan, Sriram and Kenthapadi, Krishnaram. [""LiFT: A Scalable Framework for Measuring Fairness in ML Applications""](https://arxiv.org/abs/2008.07433) (2020) - Code: [The LinkedIn Fairness Toolkit (LiFT)](https://github.com/linkedin/LiFT)\n', '1. [Four Principles of Explainable Artificial Intelligence (NIST Draft). Phillips, P.J., Hahn, A.C., Fontana, P.C., Broniatowski, D.A. and Przybocki, M.A., 2020.](https://nvlpubs.nist.gov/nistpubs/ir/2020/NIST.IR.8312-draft.pdf)\n', '1. [Data Ethics Canvas](https://theodi.org/article/data-ethics-canvas/). Helps identify and manage ethical issues – at the start of a project that uses data, and throughout. Also see [Ethics Canvas](https://web.archive.org/web/20210528013717/https://www.ethicscanvas.org/) for broader scope.\n', '1. [The Open Ethics Canvas by the Open Ethics](https://github.com/OpenEthicsAI/Canvas)\n', '1. [ABOUT ML](https://www.partnershiponai.org/about-ml/) - Annotation and Benchmarking on Understanding and Transparency of Machine learning Lifecycles.\n', '1. [Mitchell, Margaret and Wu, Simone and Zaldivar, Andrew and Barnes, Parker and Vasserman, Lucy and Hutchinson, Ben and Spitzer, Elena and Raji, Inioluwa Deborah and Gebru, Timnit. ""Model Cards for Model Reporting"" (2019)](https://arxiv.org/abs/1908.06165)  - Code: [Model Card Toolkit](https://github.com/tensorflow/model-card-toolkit)\n', '1. [Navigate the road to Responsible AI – Gradient Flow Blog](https://gradientflow.com/navigate-the-road-to-responsible-ai/)\n', '1. [😈 Awful AI is a curated list to track current scary usages of AI - hoping to raise awareness](https://github.com/daviddao/awful-ai)\n', '1. [Seven legal questions for data scientists](https://www.oreilly.com/radar/seven-legal-questions-for-data-scientists/)\n', '1. [2020 in Review: 8 New AI Regulatory Proposals from Governments](https://syncedreview.com/2020/12/31/2020-in-review-8-new-ai-regulatory-proposals-from-governments/)\n', '1. [Model Governance resources](https://github.com/bnh-ai/resources)\n', '1. [ML Cards for D/MLOps Governance (The combination of code, data, model, and service cards for D/MLOps, as an integrated solution.)](https://databaseline.tech/ml-cards/)\n', '1. [To regulate AI, try playing in a sandbox](https://www.morningbrew.com/emerging-tech/stories/2021/05/26/regulate-ai-just-play-sandbox)\n', '1. [Biases in AI Systems. A survey for practitioners](https://queue.acm.org/detail.cfm?id=3466134)\n', '1. [Artificial Intelligence Incident Database](https://incidentdatabase.ai/)\n', '1. [Data Ethics Considerations for more Responsible AI](https://arize.com/data-ethics-in-africa/)\n', '1. [Book: Interpretable Machine Learning with Python (by Serg Masis)](https://datatalks.club/books/20210719-interpretable-machine-learning-with-python.html)\n', '1. [Fairness in Machine Learning](https://fairlearn.org/main/user_guide/fairness_in_machine_learning.html)\n', '1. [Paper: Hendrycks, Dan, Nicholas Carlini, John Schulman, and Jacob Steinhardt. ""Unsolved problems in ml safety.""(2021)](https://arxiv.org/pdf/2109.13916.pdf)\n', '\n', '\n', '# Security for ML\n', '\n', '1. [Cybersecurity for Data Science](https://www.coursera.org/learn/cybersecurity-for-data-science)\n', '1. [Artifical intelligence and machine learning security (by Microsoft)](https://docs.microsoft.com/en-us/security/engineering/failure-modes-in-machine-learning) The references therein are useful.\n', '1. [Evtimov, Ivan, Weidong Cui, Ece Kamar, Emre Kiciman, Tadayoshi Kohno, and Jerry Li. ""Security and Machine Learning in the Real World."" arXiv (2020).](https://arxiv.org/pdf/2007.07205.pdf)\n', '1. [Machine Learning Systems: Security](https://sahbichaieb.com/mlsystems-security/)\n', '1. [Enterprise Security and Governance MLOps (by Diego Oppenheimer)](https://youtu.be/JNZk8diyIuE)\n', '1. [Adversarial Machine Learning 101](https://github.com/mitre/advmlthreatmatrix/blob/master/pages/adversarial-ml-101.md#adversarial-machine-learning-101)\n', '1. [ATLAS - Adversarial Threat Landscape for Artificial-Intelligence Systems](https://github.com/mitre/advmlthreatmatrix)\n', '\n', '\n', '# Reports\n', '\n', '1. [State of AI Ethics June 2020 Report by the Montreal AI Ethics Institute](https://montrealethics.ai/wp-content/uploads/2020/06/State-of-AI-Ethics-June-2020-report.pdf)\n', '2. [State of AI Ethics October 2020 Report by the Montreal AI Ethics Institute](https://montrealethics.ai/wp-content/uploads/2020/10/State-of-AI-Ethics-Oct-2020.pdf)\n', '3. [State of AI Ethics January 2021 Report by the Montreal AI Ethics Institute](https://montrealethics.ai/wp-content/uploads/2021/01/State-of-AI-Ethics-Report-January-2021.pdf)\n', '\n', '# Organizations\n', '\n', '1. [AI Ethics Impact Group: From Principles to Practice](https://www.ai-ethics-impact.org/en)\n', '1. [Responsible AI Institute](https://www.responsible.ai/)\n']"
Responsible+AI,PacktPublishing/Designing-Models-for-Responsible-AI,PacktPublishing,https://api.github.com/repos/PacktPublishing/Designing-Models-for-Responsible-AI,3,4,4,"['https://api.github.com/users/sharmi1206', 'https://api.github.com/users/amita-kapoor', 'https://api.github.com/users/Packt-ITService', 'https://api.github.com/users/davids-packt']",Python,2023-03-09T00:04:00Z,https://raw.githubusercontent.com/PacktPublishing/Designing-Models-for-Responsible-AI/main/README.md,"['# Designing-Models-for-Responsible-AI\n', 'Designing Models for Responsible AI\n', '\n', 'Chapter 1\n', '•\tkeras-2.7.0, Tensorflow-2.7.0\n', '•\tpip install adversarial-robustness-toolbox\n', '•\tpip install git+https://github.com/Koukyosyumei/AIJack\n', '\n', 'Reference :https://github.com/Koukyosyumei/AIJack/tree/main/src/aijack,\n', 'https://github.com/Trusted-AI/adversarial-robustness-toolbox\n', '\n', 'Chapter 2\n', '\n', '•\tpip install adversarial-robustness-toolbox\n', '•\tpip install presidio_analyzer\n', '•\tpip install presidio_anonymizer\n', '•\tpip install syft==0.2.9\n', '•\tpip install Pyfhel\n', '•\tpip install secml\n', '•\tpip install crypten\n', '•\tgit clone https://github.com/privacytrustlab/ml_privacy_meter.git , pip install -r requirements.txt, pip install -e\n', '•\tpip install diffprivlib\n', '•\tpip install tensorflow-privacy\n', '•\tpip install mia\n', '•\tpip install foolbox\n', '\n', 'References :\n', 'https://github.com/OpenMined/PySyft\n', 'https://github.com/ibarrond/Pyfhel\n', 'https://github.com/pralab/secml\n', 'https://github.com/facebookresearch/CrypTen\n', 'https://github.com/IBM/differential-privacy-library\n', 'https://github.com/tensorflow/privacy\n', 'https://github.com/bethgelab/foolbox\n', 'https://github.com/privacytrustlab/ml_privacy_meter.git \n', '\n', '\n', '\n']"
Responsible+AI,microsoft/responsible-ai-toolbox-privacy,microsoft,https://api.github.com/repos/microsoft/responsible-ai-toolbox-privacy,12,2,3,"['https://api.github.com/users/shrutitople', 'https://api.github.com/users/microsoftopensource', 'https://api.github.com/users/microsoft-github-operations%5Bbot%5D']",Python,2023-03-19T16:06:17Z,https://raw.githubusercontent.com/microsoft/responsible-ai-toolbox-privacy/main/README.md,"['# Empirical Estimation of Differential Privacy\r\n', '\r\n', 'This repository provides utilities for estimating DP-$\\varepsilon$ from the confusion matrix of a membership inference attack based on the paper <a href=""https://arxiv.org/abs/2206.05199"">Bayesian Estimation of Differential Privacy</a>.\r\n', '\r\n', '## Installation\r\n', '\r\n', 'Simply run the following command to install the privacy-estimates python package. It should install all the relevant dependencies as well.\r\n', '\r\n', '``` bash\r\n', 'pip install privacy-estimates\r\n', '```\r\n', '\r\n', '\r\n', '## Example\r\n', '\r\n', 'The following command takes the output of a membership inference attack on a target model or multiples models in the form of true positives (TP), true negatives (TN), false positives (FP) and false negatives (FN). It also requires the value for  $\\alpha$ which states the significance level of the estimate for two sided intervals of the estimated $\\varepsilon$ value.\r\n', '\r\n', 'For example, we can post-proces the attack outputs of a CNN trained on CIFAR10 with $(\\varepsilon = 10, \\delta = 10^{-5})$ by running\r\n', '\r\n', '``` bash\r\n', 'python scripts/estimate-epsilon.py --alpha 0.1 --delta 1e-5 --TP 487 --TN 1 --FP 512 --FN 0 \r\n', '```\r\n', '\r\n', 'This should take approximately 5 minutes and produce the following output\r\n', '\r\n', '``` bash\r\n', 'Method             Interval                Significance level  eps_lo  eps_hi\r\n', 'Joint beta (ours)  two-sided equal-tailed  0.100               0.145   6.399\r\n', 'Joint beta (ours)  one-sided               0.050               0.145   inf\r\n', 'Clopper Pearson    two-sided equal-tailed  0.100               0.000   inf\r\n', 'Clopper Pearson    one-sided               0.050               0.000   inf\r\n', 'Jeffreys           two-sided equal-tailed  0.100               0.000   inf\r\n', 'Jeffreys           one-sided               0.050               0.000   inf\r\n', '```\r\n', '\r\n', '\r\n', '## Tests\r\n', '\r\n', 'We provide a few test cases which can be run by\r\n', '\r\n', '``` bash\r\n', 'pytest .\r\n', '```\r\n', '\r\n', '# Contributing\r\n', '\r\n', 'This project welcomes contributions and suggestions. Most contributions require you to\r\n', 'agree to a Contributor License Agreement (CLA) declaring that you have the right to,\r\n', 'and actually do, grant us the rights to use your contribution. For details, visit\r\n', 'https://cla.microsoft.com.\r\n', '\r\n', 'When you submit a pull request, a CLA-bot will automatically determine whether you need\r\n', 'to provide a CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the\r\n', 'instructions provided by the bot. You will only need to do this once across all repositories using our CLA.\r\n', '\r\n', 'This project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\r\n', 'For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/)\r\n', 'or contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\r\n']"
Responsible+AI,salilkanitkar/responsible_ai_hackathon,salilkanitkar,https://api.github.com/repos/salilkanitkar/responsible_ai_hackathon,2,3,2,"['https://api.github.com/users/Nithanaroy', 'https://api.github.com/users/salilkanitkar']",Python,2022-05-02T13:43:24Z,https://raw.githubusercontent.com/salilkanitkar/responsible_ai_hackathon/master/README.md,"['# responsible_ai_hackathon\n', 'Repository for Responsible AI Hackathon related code (May 2020)\n', '\n', 'Run the Neural Network model on [![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/salilkanitkar/responsible_ai_hackathon/master?filepath=models%2Fbasic-model%2Fnn-model.ipynb)\n', '\n', '## Dataset Credits\n', '```\n', '@inproceedings{roffo2016personality,\n', '  title={Personality in computational advertising: A benchmark},\n', '  author={Roffo, Giorgio and Vinciarelli, Alessandro},\n', '  booktitle={4 th Workshop on Emotions and Personality in Personalized Systems (EMPIRE) 2016},\n', '  pages={18},\n', '  year={2016}\n', '}\n', '```\n', '\n', '## Live Dashboard\n', '\n', 'Please visit https://bit.ly/ads-rec-fairness-dashboard to see the dashboard live. It may take a few seconds to load as it is running on a free hosting service with basic hardware.\n', '\n', '<a href=""https://bit.ly/ads-rec-fairness-dashboard"" target=""_blank"" rel=""noopener noreferrer""><img src=""https://i.imgur.com/ZQ26GxH.png"" alt=""Ads fairness dashboard screenshot"" target=""_blank"" /></a>\n']"
Responsible+AI,PacktPublishing/Building-Responsible-AI-with-Python,PacktPublishing,https://api.github.com/repos/PacktPublishing/Building-Responsible-AI-with-Python,6,2,2,"['https://api.github.com/users/davids-packt', 'https://api.github.com/users/Packt-ITService']",Python,2023-02-23T02:23:03Z,https://raw.githubusercontent.com/PacktPublishing/Building-Responsible-AI-with-Python/main/README.md,"['# Building-Responsible-AI-with-Python\n', 'Building Responsible AI with Python\n']"
Responsible+AI,SEPIA-Framework/sepia-assist-server,SEPIA-Framework,https://api.github.com/repos/SEPIA-Framework/sepia-assist-server,87,14,1,['https://api.github.com/users/fquirin'],Java,2023-03-21T09:26:15Z,https://raw.githubusercontent.com/SEPIA-Framework/sepia-assist-server/master/README.md,"['# SEPIA Assist-Server\n', 'Part of the [SEPIA Framework](https://sepia-framework.github.io/)  \n', '\n', '<p align=""center"">\n', '  <img src=""https://sepia-framework.github.io/img/SEPIA_connected.png"" alt=""S.E.P.I.A. Framework"" width=350/>\n', '</p>\n', '\n', 'This is the core server of the SEPIA Framework and basically the ""brain"" of the assistant. It includes multiple modules and microservices exposed via the Assist-API, e.g.:\n', '* User-account management\n', '* Database integration (e.g. Elasticsearch)\n', '* Natural-Language-Understanding (NLU) and Named-Entity-Recognition (NER) (works out-of-the-box for German and English, but the modular NLU chain can use APIs and Python scripts as well)\n', '* Conversation flow (aka interview-module)\n', '* Answer-module\n', '* Smart-services (integration of local-services like a to-do lists or cloud-services like a weather API with the NLU, conversation and answer modules)\n', '* Remote-actions (e.g. receive data from IoT devices or wake-word tools)\n', '* Embedded open-source Text-to-Speech integration (eSpeak, MaryTTS, picoTTS - Note: TTS can be handled via this server or inside the SEPIA client)\n', '* ... and more\n', '\n', 'The [SEPIA cross-platform-clients](https://github.com/SEPIA-Framework/sepia-html-client-app) can access the [RESTful Assist-API](https://github.com/SEPIA-Framework/sepia-docs/blob/master/API/assist-server.md) directly and exchange data in JSON format (e.g. for user authentication) or connect to the SEPIA chat-server to send and receive messages.\n', 'SEPIAs running on this server can log-in to the WebSocket chat-server the same way a user does and communicated via channels with multiple users (or devices) at the same time.\n', '\n', 'The SEPIA Assist-Server operates as your own, self-hosted cloud-service and is designed to work the same way no matter if you run it on a Raspberry Pi for a small group of users in a private network \n', 'or when you host it on multiple servers for a larger company network.\n']"
Responsible+AI,malikamalik/RAI-vNext-Preview,malikamalik,https://api.github.com/repos/malikamalik/RAI-vNext-Preview,0,13,3,"['https://api.github.com/users/RachelKellam', 'https://api.github.com/users/riedgar-ms', 'https://api.github.com/users/microsoftopensource']",,2022-01-25T11:08:29Z,https://raw.githubusercontent.com/malikamalik/RAI-vNext-Preview/main/README.md,"['# Azure Machine Learning Responsible AI Dashboard - Private Preview\n', '\n', 'Welcome to the private preview for the new Responsible AI dashboard in Azure Machine Learning (AzureML) SDK and studio. The following is a guide for you to onboard to the new capabilities. For questions, please contact mithigpe@microsoft.com.\n', '\n', '## What is this new feature?\n', '\n', 'AzureML currently supports both [model explanations](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-machine-learning-interpretability-aml) and [model fairness](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-machine-learning-fairness-aml) in public preview. As we expand our offerings under Responsible AI tools for AzureML users, this new feature brings pre-existing features and brand new offerings under one-stop-shop SDK package and studio UI dashboard:\n', '- Error Analysis (new): view and understand the error distributions of your model over your dataset via a decision tree map or heat map visualization.\n', '- Data Explorer: explore your dataset by feature sets and other metrics such as predicted Y or true Y\n', '- Model Statistics: explore the distribution of your model outcomes and performance metrics\n', '- Interpretability: view the aggregate and individual feature importances across your model and dataset\n', ""- Counterfactual What-If's (new): create automatically generated diverse sets of counterfactual examples for each datapoint that is minimally perturbed in order to switch its predicted class or output. Also create your own counterfactual datapoint by perturbing feature values manually to observe the new outcome of your model prediction.\n"", '- Causal Analysis (new): view the aggregate and individual causal effects of *treatment features* (features which you are interested in controlling) on the outcome in order to make informed real-life business decisions. See recommended treatment policies for segmentations of your population for features in your dataset to see the effect on your real-life outcomes. \n', '\n', 'This new feature offers users a new powerful and robust toolkit for understanding your model and data in order to develop your machine learning models responsibly, now all in one place and integrated with your AzureML workspace.\n', '\n', '❗ **Please note:** This initial version of the Responsible AI dashboard currently does not support the integration of fairness metrics. For fairness metrics, please refer to our existing offering [here.](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-machine-learning-fairness-aml)\n', '\n', '## Supported scenarios, models and datasets\n', '\n', ""`azureml-responsibleai` supports computation of Responsible AI insights for `scikit-learn` models that are trained on `pandas.DataFrame`. The `azureml-responsibleai` package accepts both models and SciKit-Learn pipelines as input as long as the model or pipeline implements a `predict` or `predict_proba` function that conforms to the `scikit-learn` convention. If not compatible, you can wrap your model's prediction function into a wrapper class that transforms the output into the format that is supported (`predict` or `predict_proba` of `scikit-learn`), and pass that wrapper class to modules in `azureml-responsibleai`.\n"", '\n', 'Currently, we support datasets having numerical and categorical features. The following table provides the scenarios supported for each of the four responsible AI insights:-\n', '\n', '| RAI insight | Binary classification | Multi-class classification | Multilabel classification | Regression | Timeseries forecasting | Categorical features | Text features | Image Features | Recommender Systems | Reinforcement Learning |\n', '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | -- |\n', '| Explainability | Yes | Yes | No | Yes | No | Yes | No | No | No | No |\n', '| Error Analysis | Yes | Yes | No | Yes | No | Yes | No | No | No | No |\n', '| Causal Analysis | Yes | No | No | Yes | No | Yes (max 5 features due to computational cost) | No | No | No | No |\n', '| Counterfactual | Yes | Yes | No | Yes | No | Yes | No | No | No | No |\n', '\n', 'This is all available via Python SDK or CLI.\n', '\n', '## Set Up\n', 'In this section, we will go over the basic setup steps that you need in order to generate Responsible AI insights for your models from SDK v2, CLI v2 and visualize the generated Responsible AI insights in [AML studio](https://ml.azure.com/).\n', '\n', '### Create an AzureML workspace\n', 'Create an AzureML workspace by using the [configuration notebook](https://github.com/Azure/MachineLearningNotebooks/blob/master/configuration.ipynb)\n', '\n', '### Install the required packages\n', 'In order to install `azureml-responsibleai` package you will need a python virtual environment. You can create a python virtual environment using `conda`.\n', '```c\n', 'conda create -n azureml_env python=3.8\n', 'activate azureml_env\n', '```\n', '\n', 'After activating your environment, if this is your first time running the RAI Dashboard in private preview then continue to the [setup instructions](https://github.com/Azure/RAI-vNext-Preview/blob/main/docs/Setup.md) to do a one-time setup for your workspace.\n', '\n', '\n', '\n', '### Generating Responsibleai AI Dashboard insights\n', 'Once you have created an Azure workspace and registered your components in the one-time setup above, you can create a Responsible AI dashboard via the CLI or SDK. Start here for `examples` [folder](examples) to get started.\n', '\n', '### Viewing your Responsible AI Dashboard in the AzureML studio portal\n', 'After generating the Responsible AI insights, you can view them in your associated workspace in AzureML studio, under your model registry.\n', '\n', '![01](images/01_model_registry.png)\n', '1. Go to your model registry in your AzureML studio workspace\n', ""2. Click on the model for which you've uploaded your Responsible AI insights\n"", '\n', '![02](images/02_model_details.png)\n', '3. Click on the tab for `Responsible AI dashboard (preview)` under your model details page\n', '\n', '![03](images/03_responsibleaitoolbox.png)\n', '4. Under the `Responsible AI dashboard (preview)` tab of your model details, you will see a list of your uploaded Responsible AI insights. You can upload more than one Responsible AI dashboard for each model. Each row represents one dashboard, with information on which components were uploaded to each dashboard (i.e. explanations, counterfactuals, etc).\n', '\n', '![04](images/04_dashboard.png)\n', '5. At anytime while viewing the dashboard, if you wish to return to the model details page, click on `Back to model details`\n', '<ol type=""A"">\n', '  <li>You can view the dashboard insights for each component filtered down on a cohort you specify (or view all the data with the global cohort). Hovering over the cohort name will show the number of datapoints and filters in that cohort as a tooltip.</li>\n', '  <li>Switch which cohort you are applying to the dashboard.</li>\n', '  <li>Create a new cohort based on filters you can apply in a flyout panel.</li>\n', '  <li>View a list of all cohorts created and duplicate, edit or delete them.</li>\n', ""  <li>View a list of all Responsible AI components you've uploaded to this dashboard as well as hiding components. The layout of the dashboard will reflect the order of the components in this list.</li>\n"", '</ol>\n', '\n', '❗ **Please note:** Error Analysis, if generated, will always be at the top of the component list in your dashboard. Selecting on the nodes of the error tree or tiles of the error heatmap will automatically generate a temporary cohort that will be populated in the components below so that you can easily experiment with looking at insights for different areas of your error distribution.\n', '\n', '![05](images/05_add_dashboard.png)\n', '6. In between each component you can add components by clicking the blue circular button with a plus sign. This will pop up a tooltip that will give you an option of adding whichever Responsible AI component you enabled with your SDK.\n', '\n', '#### Known limitations of viewing dashboard in AzureML studio\n', 'Due to the (current) lack of active compute, the dashboard in AzureML studio has fewer features than the dashboard generated with the open source package. To generate the full dashboard in a Jupyter python notebook, please download and use our [open source Responsible AI Dashboard SDK](https://github.com/microsoft/responsible-ai-widgets). \n', '\n', 'Some limitations in AzureML studio include:\n', '- Retraining of the Error analysis tree on different features is disabled\n', '- Switching the Error analysis heat map to different features is disabled\n', '- Viewing the Error analysis tree or heatmap on a smaller subset of your full dataset passed into the dashboard (requires retraining of the tree) is disabled\n', '- ICE (Individual Conditional Expectation) plots in the feature importance tab for explanations are disabled\n', '- Manually creating a What-If datapoint is disabled; you can only view the counterfactual examples already pre-generated by the SDK\n', '- Causal analysis individual what-if is disabled; you can only view the individual causal effects of each individual datapoint\n', '\n', 'However, if you create a dashboard in AzureML, and then download it to a Jupyter notebook, it will be fully featured when running in that notebook.\n', '\n', '## Responsible AI Dashboard walkthrough and sample notebooks\n', 'Please read through our [examples folder](examples) to see if this feature supports your use case. For more details about each individual component, please read through our brief [tour guide of the new Responsible AI dashboard capabilities.](https://github.com/microsoft/responsible-ai-widgets/blob/main/notebooks/responsibleaitoolbox-dashboard/tour.ipynb) \n', '\n', '## What Next?: How to join Private Preview 👀\n', 'We are super excited for you to try this new feature in AzureML! \n', '- Reach out to mithigpe@microsoft.com to enable your Azure subscription for this Private Preview feature.\n', '- Fill out this form - Private Preview sign up for [Responsible AI Dashboard in AzureML](https://forms.office.com/r/R6PmBCkyWb)\n', '\n', '## Contributing\n', '\n', 'This project welcomes contributions and suggestions.  Most contributions require you to agree to a\n', 'Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\n', 'the rights to use your contribution. For details, visit https://cla.opensource.microsoft.com.\n', '\n', 'When you submit a pull request, a CLA bot will automatically determine whether you need to provide\n', 'a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions\n', 'provided by the bot. You will only need to do this once across all repos using our CLA.\n', '\n', 'This project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\n', 'For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\n', 'contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n', '\n', '## Trademarks\n', '\n', 'This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft \n', 'trademarks or logos is subject to and must follow \n', ""[Microsoft's Trademark & Brand Guidelines](https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general).\n"", 'Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship.\n', ""Any use of third-party trademarks or logos are subject to those third-party's policies.\n"", '\n']"
Responsible+AI,cylynx/verifyml,cylynx,https://api.github.com/repos/cylynx/verifyml,17,2,4,"['https://api.github.com/users/jasonho-lynx', 'https://api.github.com/users/timlrx', 'https://api.github.com/users/CodesAreHonest', 'https://api.github.com/users/swanhl']",Python,2023-03-15T16:10:39Z,https://raw.githubusercontent.com/cylynx/verifyml/main/README.md,"['# VerifyML\n', '\n', 'VerifyML is an opinionated, open-source toolkit and workflow to help companies implement human-centric AI practices. It is built on 3 principles:\n', '\n', '- A git and code first approach to model development and maintenance.\n', ""- Automatic generation of model cards - machine learning documents that provide context and transparency into a model's development and performance.\n"", '- Model tests for validating performance of models across protected groups of interest, during development and in production.\n', '\n', '## Components\n', '\n', '![VerifyML Dataflow](https://github.com/cylynx/verifyml/raw/main/verifyml-dataflow.png)\n', '\n', 'At the core of the VerifyML workflow is a model card that captures 6 aspects of a model:\n', '\n', '- Model details\n', '- Considerations\n', '- Model / data parameters\n', '- Quantitative analysis\n', '- Explainability analysis\n', '- Fairness analysis\n', '\n', ""It is adapted from Google's Model Card Toolkit and expanded to include broader considerations such as fairness and explainability.\n"", '\n', 'A [model card editor](https://report.verifyml.com), provides a web-based interface to gather input and align stakeholders across product, data science, compliance.\n', '\n', 'Our Python toolkit supports data science workflows, and allows a custom model to be built and logged within the model card framework. The package also contains perfomance and fairness tests for model diagnostics, fairness and reliability checks.\n', '\n', 'Being a standard protobuf format, the model card can be translated to various outputs including a model report, trade-off comparison and even tests results summary.\n', '\n', '## Installation\n', '\n', 'The Model Card Toolkit is hosted on [PyPI](https://pypi.org/project/verifyml/), and can be installed with `pip install verifyml`.\n', '\n', '## Getting Started\n', '\n', '### Generate a model card\n', '\n', '![VerifyML Model Card Editor](https://github.com/cylynx/verifyml/raw/main/model-card-editor.png)\n', '\n', 'The [VerifyML card creator](https://report.verifyml.com/create) provides an easy way for teams to create and edit model cards in a WYSIWYG editor. Use it to bootstrap your model card or edit text records through a web browser. It is a client side application and no data gets stored on a server.\n', '\n', 'Alternatively, generate a model card with the python toolkit:\n', '\n', '```py\n', 'import verifyml.model_card_toolkit as mctlib\n', '\n', '# Initialize the Model Card Toolkit with a path to store generate assets\n', 'mct = mctlib.ModelCardToolkit(output_dir=""model_card_output"", file_name=""breast_cancer_diagnostic_model_card"")\n', 'model_card = mct.scaffold_assets()\n', '```\n', '\n', '### Populate the model card with details\n', '\n', '```py\n', '# You can add free text fields\n', ""model_card.model_details.name = 'Breast Cancer Wisconsin (Diagnostic) Dataset'\n"", '\n', '# Or use helper classes\n', 'model_card.model_parameters.data.append(mctlib.Dataset())\n', 'model_card.model_parameters.data[0].graphics.description = (\n', ""  f'{len(X_train)} rows with {len(X_train.columns)} features')\n"", 'model_card.model_parameters.data[0].graphics.collection = [\n', '    mctlib.Graphic(image=mean_radius_train),\n', '    mctlib.Graphic(image=mean_texture_train)\n', ']\n', '```\n', '\n', '### Save and export to html\n', '\n', '```py\n', 'html = mct.export_format(output_file=""example.html"")\n', 'display.display(display.HTML(html))\n', '```\n', '\n', '## Model Tests\n', '\n', 'Model tests provides an out of the box way to conduct checks and analysis on performance, explainability and fairness. The tests included in VerifyML are atomic functions that can be imported and run without a model card. However, by using it with a model card, it provides a way to standardize objectives and check for intended or unintended model biases. It also automates documentation and renders the insights to a business friendly report.\n', '\n', 'Currently, VerifyML provides 5 classes of tests:\n', '\n', '1. **Subgroup Disparity Test** - For a given metric, assert that the difference between the best and worst performing group is less than a specified threshold\n', '2. **Min/Max Metric Threshold Test** - For a given metric, assert that all groups should be below / above a specified threshold\n', '3. **Perturbation Test** - Assert that a given metric does not change significantly after perturbing on a specified input variable\n', '4. **Feature Importance Test** - Assert that certain specified variables are not included as the top n most important features\n', '5. **Data Shift Test** - Assert that the distributions of specified attributes are similar across two given datasets of interest\n', '\n', 'The detailed [model tests readme](https://github.com/cylynx/verifyml/blob/main/verifyml/model_tests/README.md) contains more information on the tests.\n', '\n', 'You can also easily create your own model tests by inheriting from the base model test class. See [DEVELOPMENT](https://github.com/cylynx/verifyml/blob/main/DEVELOPMENT.md) for more details.\n', '\n', '### Example usage\n', '\n', '```py\n', 'from verifyml.model_tests.FEAT import SubgroupDisparity\n', '\n', '# Ratio of false positive rates between age subgroups should not be more than 1.5\n', ""sgd_test = SubgroupDisparity(metric='fpr', method='ratio', threshold=1.5)\n"", 'sgd_test.run(output) # test data with prediction results\n', 'sgd_test.plot(alpha=0.05)\n', '```\n', '\n', '### Adding the test to the model card\n', '\n', '```py\n', 'import verifyml.model_card_toolkit as mctlib\n', '\n', 'mc_sgd_test = mctlib.Test()\n', 'mc_sgd_test.read_model_test(sgd_test)\n', 'model_card.fairness_analysis.fairness_reports[0].tests = [mc_smt_test]\n', '```\n', '\n', '## Schema\n', '\n', 'Model cards are stored as a protobuf format. The reference model card protobuf schema can be found in the [proto directory](https://github.com/cylynx/verifyml/tree/main/verifyml/model_card_toolkit/proto). A translated copy in json schema format is also made available for convenience in the [schema folder](https://github.com/cylynx/verifyml/tree/main/verifyml/model_card_toolkit/schema)\n', '\n', '## Templates\n', '\n', 'Model cards can be rendered into various reports through the use of templates. The template folder contains two html templates - a default model report and a compare template, and a default markdown model report.\n', '\n', '## Contributions and Development\n', '\n', 'Contributions are always welcome - check out [CONTRIBUTING](https://github.com/cylynx/verifyml/blob/main/CONTRIBUTING.md)\n', '\n', ""The package and it's functionalities can be easily extended to meet the needs of a team. Check out [DEVELOPMENT](https://github.com/cylynx/verifyml/blob/main/DEVELOPMENT.md) for more info.\n"", '\n', '## Prior Art\n', '\n', ""The model card in VerifyML is adapted from Google's [Model Card Toolkit](https://github.com/tensorflow/model-card-toolkit). It is backward compatible with v0.0.2 and expands on it by adding sections on explainability and fairness. You can specify the desired rendering template by specifying the `template_path` argument when calling the `mct.export_format` function. For example:\n"", '\n', '```py\n', 'mct.export_format(output_file=""example.md"", template_path=""path_to_my_template"")\n', '```\n', '\n', ""View the [templates' README](https://github.com/cylynx/verifyml/blob/main/verifyml/model_card_toolkit/template/README.md) for more information on creating your own jinja templates.\n"", '\n', '## References\n', '\n', '[1] https://arxiv.org/abs/1810.03993\n', '\n', '## License\n', '\n', 'VerifyML is licensed under the Apache License, Version 2.0. See [LICENSE](https://github.com/cylynx/verifyml/blob/main/LICENSE) for the full license text.\n', '\n', '## Generating Docs\n', '\n', 'Docs are generated using [pydoc-markdown](https://github.com/NiklasRosenstein/pydoc-markdown), and our configuration is specified in `pydoc-markdown.yml`. The package reads the yml file, then converts the referenced READMEs and code files into corresponding [mkdocs](https://www.mkdocs.org/) markdown files, together with a `mkdocs.yml` config file. These converted files can be found in a `build/docs` directory, which will appear after the commands below are run.\n', '\n', '### Preview\n', '\n', 'To preview the docs locally, run\n', '\n', '```bash\n', './docs.sh serve\n', '```\n', '\n', 'This creates doc files in `build/docs/`, then serves them at `localhost:8000`.\n', '\n', '### Build\n', '\n', 'To build the HTML files, run\n', '\n', '```bash\n', './docs.sh build\n', '```\n', '\n', 'This creates doc files in `build/docs/`, then creates their HTML equivalents in `build/html/`.\n', '\n', '### Details\n', '\n', 'To render Jupyter Notebooks in the docs, we use the [`mkdocs-jupyter`](https://github.com/danielfrg/mkdocs-jupyter) plugin, and reference the notebooks in `pydoc-markdown.yml` (e.g. `source: example.ipynb` in one of the entries).\n', '\n', 'However, because `pydoc-markdown` converts everything to Markdown files by default, only the notebook text would show up by default. Thus, some intermediate steps (/ hacks) are required for the notebook to render correctly:\n', '\n', '1. Build the docs, converting the notebook text into a Markdown file (e.g. `build/docs/example.md`)\n', ""2. Rename the built file's extension from Markdown back into a notebook format (e.g. `mv example.md example.ipynb` in bash)\n"", ""3. Edit the built `mkdocs.yml` file such that the notebook's entry points to the renamed file in step 2 (this is done by `convert_md_to_ipynb.py`)\n"", '\n', '`./docs.sh` handles these steps.\n']"
Responsible+AI,h2oai/xai_guidelines,h2oai,https://api.github.com/repos/h2oai/xai_guidelines,5,6,2,"['https://api.github.com/users/jphall663', 'https://api.github.com/users/navdeep-G']",Python,2022-09-21T12:49:32Z,https://raw.githubusercontent.com/h2oai/xai_guidelines/master/README.md,"['# Responsible Use Guidelines for Explainable Machine Learning\n', 'A proposal for a 180-minute hands-on tutorial at ACM FAT* 2020, Barcelona, Spain.  \n', '\n', 'All tutorial code and materials are available here: https://github.com/h2oai/xai_guidelines. All materials may be re-used and re-purposed, even for commerical applications, with proper attribution of the authors.\n', '\n', '#### For the tutorial outline, please see: [responsible_xai.pdf](responsible_xai.pdf).\n', '\n', '#### To use the code examples for this tutorial: \n', '\n', '1. Navigate to [https://aquarium.h2o.ai](https://aquarium.h2o.ai). \n', '2. Click `Create a new account` below the login. Follow the Aquarium instructions to create a new account.\n', '3. Check the registered email inbox and use the temporary password sent there to login to Aquarium. \n', '4. Click `Browse Labs` in the upper left.\n', '5. Find `Open Source MLI Workshop` and click `View Details`.\n', '6. Click `Start Lab` and wait for several minutes as a cloud server is provisioned for you.  \n', '7. Once your server is ready, click on the `Jupyter URL` at the bottom of your screen. \n', '8. Enter the token `h2o` at the top Jupyter security `Password or Token` text box.\n', '9. Click the `xai_guidelines` folder. (For those interested, the `patrick_hall_mli` folder contains resources from a 2018 FAT* tutorial.)\n', '10. You now have access to the tutorial materials. You may browse them at your own pace or wait for instructions. You may also come back to them at anytime using your Aquarium login. \n', '\n', '#### To view preliminary example code:\n', '* Guideline 2.1: [An explainable, but untrustworthy, model](https://nbviewer.jupyter.org/github/h2oai/xai_guidelines/blob/master/global_shap_resid.ipynb)\n', '* Guideline 2.3: [Augmenting surrogate models with direct explanations](https://nbviewer.jupyter.org/github/h2oai/xai_guidelines/blob/master/dt_surrogate_pd_ice.ipynb)\n', '* Corollary 2.3.1: [Augmenting LIME with direct explanations](https://nbviewer.jupyter.org/github/h2oai/xai_guidelines/blob/master/dt_shap_lime.ipynb)\n', '* Corollary 2.4.1: [Combining interpretable models and explanations](https://nbviewer.jupyter.org/github/h2oai/xai_guidelines/blob/master/dt_shap_lime.ipynb)\n', '* Corollaries 2.4.2 - 2.4.2: [Combining constrained models, explanations, and bias testing](https://nbviewer.jupyter.org/github/h2oai/xai_guidelines/blob/master/dia.ipynb)\n', '\n', '#### Preliminary tutorial slides: [Guidelines for Responsible Explainable ML](https://github.com/jphall663/kdd_2019/blob/master/main.pdf)\n', '\n', '#### Tutorial Instructors:\n', '\n', '**Patrick Hall**: Patrick Hall is senior director for data science products at H2O.ai where he focuses on increasing trust and understanding in machine learning through interpretable models, post-hoc explanations, model debugging, and bias testing and remediation. Patrick is also currently an adjunct professor in the Department of Decision Sciences at George Washington University, where he teaches graduate classes in data mining and machine learning. Prior to joining H2O.ai, Patrick held global customer facing roles and research and development roles at SAS Institute. Find out more about Patrick on [GitHub](https://github.com/jphall663), [Linkedin](https://www.linkedin.com/in/jpatrickhall/), or [Twitter](https://twitter.com/jpatrickhall).\n', '\n', '**Navdeep Gill**: Navdeep Gill is a senior data scientist and engineer at H2O.ai. Navdeep is a founding member of the interpretability team at H2O.ai and has worked on various other projects at H2O.ai including the open source h2o, automl, and h2o4gpu machine learning libraries. Before joining H2O.ai, Navdeep worked at Cisco, focusing on data science and software development and previous to that he researched neuroscience. Find out more about Navdeep on [GitHub](https://github.com/navdeep-G), \n', '[Linkedin](https://www.linkedin.com/in/navdeep-gill-b1729456/), or [Twitter](https://twitter.com/Navdeep_Gill_).\n', '\n', '**Nick Schmidt**: Nick Schmidt is the director of the AI Practice at BLDS, a leading fair-lending advisory firm. At BLDS, Nick concentrates on creating real-world ethical AI systems for some of the largest financial institutions in the world. Prior to BLDS, Nick worked as an analyst and consultant at several well-respected economic and financial firms. Find out more about Nick on [Linkedin](https://www.linkedin.com/in/nickpschmidt/).\n']"
Responsible+AI,MarkMcKinney/responsible-ai-hot-takes,MarkMcKinney,https://api.github.com/repos/MarkMcKinney/responsible-ai-hot-takes,8,0,1,['https://api.github.com/users/MarkMcKinney'],JavaScript,2022-03-19T04:36:20Z,https://raw.githubusercontent.com/MarkMcKinney/responsible-ai-hot-takes/main/README.md,"['# Responsible AI Hot Takes\n', '\n', 'Generate and tweet awesome #techtwitter content with OpenAI via Telegram.\n', '\n', ""After following [FireShipIO's tutorial](https://github.com/fireship-io/gpt3-twitter-bot/) and hearing of OpenAI's new Twitter bot policy, I decided to create a slightly less automatic way to run a AI-backed Twitter bot.\n"", '\n', 'Instead of the bot automatically Tweeting, it will instead send the user potential options before you settle on the final result.\n', '\n', '![Screenshot of Telegram Chat](telegram_chat.JPG)\n', '\n', 'Check out my bot here: [@AIHotTakes](https://twitter.com/AIHotTakes)']"
Responsible+AI,crownpku/Responsible-AI,crownpku,https://api.github.com/repos/crownpku/Responsible-AI,6,0,1,['https://api.github.com/users/crownpku'],Python,2021-05-04T17:41:47Z,https://raw.githubusercontent.com/crownpku/Responsible-AI/master/README.md,"['# Responsible AI\n', '\n', '![](imgs/responsible-ai.png)\n', '\n', 'This is a demo project of using Responsible AI technology provided by Google to build responsible machine learning applications.\n', '\n', '## Content\n', '\n', '### Define Problem\n', '\n', '#### Who is my ML system for?\n', '\n', 'The way actual users experience your system is essential to assessing the true impact of its predictions, recommendations, and decisions. Make sure to get input from a diverse set of users early on in your development process.\n', '\n', '### Construct and prepare data\n', '\n', '#### Am I using a representative dataset?\n', '\n', 'Is your data sampled in a way that represents your users (e.g. will be used for all ages, but you only have training data from senior citizens) and the real-world setting (e.g. will be used year-round, but you only have training data from the summer)?\n', '\n', '#### Is there real-world/human bias in my data?\n', '\n', 'Underlying biases in data can contribute to complex feedback loops that reinforce existing stereotypes.\n', '\n', '### Build and train model\n', '\n', '#### What methods should I use to train my model?\n', '\n', 'Use training methods that build fairness, interpretability, privacy, and security into the model.\n', '\n', '### Evaluate model\n', '\n', '#### How is my model performing?\n', '\n', 'Evaluate user experience in real-world scenarios across a broad spectrum of users, use cases, and contexts of use. Test and iterate in dogfood first, followed by continued testing after launch.\n', '\n', '![](/imgs/equal_accuracy.png)\n', '\n', '### Deploy and monitor\n', '\n', '#### Are there complex feedback loops?\n', '\n', 'Even if everything in the overall system design is carefully crafted, ML-based models rarely operate with 100% perfection when applied to real, live data. When an issue occurs in a live product, consider whether it aligns with any existing societal disadvantages, and how it will be impacted by both short- and long-term solutions.\n', '\n', '# Reference\n', 'https://www.tensorflow.org/resources/responsible-ai\n']"
Responsible+AI,gulfaraz/responsible_ai,gulfaraz,https://api.github.com/repos/gulfaraz/responsible_ai,0,2,1,['https://api.github.com/users/gulfaraz'],JavaScript,2020-03-06T17:03:10Z,https://raw.githubusercontent.com/gulfaraz/responsible_ai/master/README.md,"['[![stable: 0.3.0](https://img.shields.io/badge/stable-0.3.0-ED2E26.svg?style=flat-square)](https://github.com/gulfaraz/responsible_ai)\n', '[![code style: prettier](https://img.shields.io/badge/code_style-prettier-ff69b4.svg?style=flat-square)](https://github.com/prettier/prettier)\n', '\n', '# Responsible A.I.\n', '\n', 'Estimate the responsibility of your A.I. project in terms of fairness,\n', 'accountability, confidentiality and transparency.\n', '\n', '\n', '## Contributing\n', '\n', 'We use [Prettier](https://github.com/prettier/prettier) to keep our code clean.\n']"
Responsible+AI,AI-Global/design-assistant,AI-Global,https://api.github.com/repos/AI-Global/design-assistant,0,2,12,"['https://api.github.com/users/dijonron', 'https://api.github.com/users/colinchoix', 'https://api.github.com/users/Micheal-Nguyen', 'https://api.github.com/users/aaronlugo', 'https://api.github.com/users/hmp31', 'https://api.github.com/users/geverit4', 'https://api.github.com/users/ErikLigai', 'https://api.github.com/users/ridwan888', 'https://api.github.com/users/colinphil', 'https://api.github.com/users/sshh12', 'https://api.github.com/users/lucindan', 'https://api.github.com/users/AIGlobalDev']",JavaScript,2022-06-28T20:16:28Z,https://raw.githubusercontent.com/AI-Global/design-assistant/main/README.md,"['# Responsible AI System Assessment\n', '\n', '#### [By AI Global](https://ai-global.org/)\n', '\n', '## Development\n', '\n', '[Original Documentation](https://github.com/AI-Global/design-assistant/tree/master/docs)\n', '\n', '> You will need to use [vscode](https://code.visualstudio.com/) in order to use our auto-formatting tools and linting.\n', '\n', '#### Getting Started\n', '\n', 'Set the following environment variables:\n', '\n', '```\n', 'MONGODB_URL=mongodb+srv...secret...\n', 'REACT_APP_API_BASE_URL=http://localhost:5000\n', '```\n', '\n', 'Then run:\n', '\n', '```\n', '$ git clone https://github.com/AI-Global/design-assistant && cd design-assistant\n', '$ yarn install\n', '$ yarn watch:react\n', '```\n', '\n', 'To start the backend, open another terminal and do:\n', '\n', '```\n', '$ yarn watch:api\n', '```\n', '\n', '#### Layout\n', '\n', '- `/src` - the react app\n', '- `/src/views` - each UI page\n', '- `/src/Components` - reusable react components\n', '- `/public` - static assets (images, compiled JS libraries, etc)\n', '- `/api` - the express backend\n', '- `/.vscode` - shared vscode settings for the project\n', '\n', '#### Helpful Docs\n', '\n', '- [ExpressJS](https://expressjs.com/en/5x/api.html)\n', '- [Mongoose](https://mongoosejs.com/docs/guide.html)\n']"
Responsible+AI,AI-Global/ai-portal,AI-Global,https://api.github.com/repos/AI-Global/ai-portal,0,2,6,"['https://api.github.com/users/sshh12', 'https://api.github.com/users/lucindan', 'https://api.github.com/users/colinphil', 'https://api.github.com/users/Marthacz', 'https://api.github.com/users/dependabot%5Bbot%5D', 'https://api.github.com/users/ameyand98']",JavaScript,2021-04-30T20:12:34Z,https://raw.githubusercontent.com/AI-Global/ai-portal/master/README.md,"['# Responsible AI Portal\n', '\n', '#### [By RAI](https://responsible.ai/)\n', '\n', '[[View Developer Docs]](https://github.com/AI-Global/ai-portal/blob/master/docs/development.md) | [[View All Docs]](https://github.com/AI-Global/ai-portal/blob/master/docs/general.md)\n', '\n', '![screenshot](https://user-images.githubusercontent.com/6625384/107436102-b2d70d00-6af2-11eb-8a48-05d9a963696e.png)\n']"
Synthetic+Data,Belval/TextRecognitionDataGenerator,Belval,https://api.github.com/repos/Belval/TextRecognitionDataGenerator,2635,842,30,"['https://api.github.com/users/Belval', 'https://api.github.com/users/FHainzl', 'https://api.github.com/users/Enzodtz', 'https://api.github.com/users/hendraet', 'https://api.github.com/users/nicolasmetallo', 'https://api.github.com/users/jtwsmeal', 'https://api.github.com/users/AghilesAzzoug', 'https://api.github.com/users/bakrianoo', 'https://api.github.com/users/astrocket', 'https://api.github.com/users/dc-chengchao', 'https://api.github.com/users/elahe-dastan', 'https://api.github.com/users/euihyun-lee', 'https://api.github.com/users/iknoorjobs', 'https://api.github.com/users/jinmingteo', 'https://api.github.com/users/junxnone', 'https://api.github.com/users/mohamadmansourX', 'https://api.github.com/users/JulienCoutault', 'https://api.github.com/users/PyaePhyoKhant', 'https://api.github.com/users/rkcosmos', 'https://api.github.com/users/Hrazhan', 'https://api.github.com/users/SunHaozhe', 'https://api.github.com/users/luangtatipsy', 'https://api.github.com/users/YacobBY', 'https://api.github.com/users/FLming', 'https://api.github.com/users/bact', 'https://api.github.com/users/edwardpwtsoi', 'https://api.github.com/users/gachiemchiep', 'https://api.github.com/users/wangershi', 'https://api.github.com/users/yifeitao', 'https://api.github.com/users/zhenglilei']",Python,2023-04-09T19:48:06Z,https://raw.githubusercontent.com/Belval/TextRecognitionDataGenerator/master/README.md,"['# TextRecognitionDataGenerator [![CircleCI](https://circleci.com/gh/Belval/TextRecognitionDataGenerator/tree/master.svg?style=svg)](https://circleci.com/gh/Belval/TextRecognitionDataGenerator/tree/master) [![PyPI version](https://badge.fury.io/py/trdg.svg)](https://badge.fury.io/py/trdg) [![codecov](https://codecov.io/gh/Belval/TextRecognitionDataGenerator/branch/master/graph/badge.svg)](https://codecov.io/gh/Belval/TextRecognitionDataGenerator) [![Documentation Status](https://readthedocs.org/projects/textrecognitiondatagenerator/badge/?version=latest)](https://textrecognitiondatagenerator.readthedocs.io/en/latest/?badge=latest)\n', '\n', 'A synthetic data generator for text recognition\n', '\n', '## What is it for?\n', '\n', 'Generating text image samples to train an OCR software. Now supporting non-latin text! For a more thorough tutorial see [the official documentation](https://textrecognitiondatagenerator.readthedocs.io/en/latest/index.html).\n', '\n', '## What do I need to make it work?\n', '\n', 'Install the pypi package\n', '\n', '```\n', 'pip install trdg\n', '```\n', '\n', 'Afterwards, you can use `trdg` from the CLI. I recommend using a virtualenv instead of installing with `sudo`.\n', '\n', 'If you want to add another language, you can clone the repository instead. Simply run `pip install -r requirements.txt`\n', '\n', '## Docker image\n', '\n', 'If you would rather not have to install anything to use TextRecognitionDataGenerator, you can pull the docker image.\n', '\n', '```\n', 'docker pull belval/trdg:latest\n', '\n', 'docker run -v /output/path/:/app/out/ -t belval/trdg:latest trdg [args]\n', '```\n', '\n', 'The path (`/output/path/`) must be absolute.\n', '\n', '## New\n', '- Add `--stroke_width` argument to set the width of the text stroke (Thank you [@SunHaozhe](https://github.com/SunHaozhe))\n', '- Add `--stroke_fill` argument to set the color of the text contour if stroke > 0 (Thank you [@SunHaozhe](https://github.com/SunHaozhe))\n', '- Add `--word_split` argument to split on word instead of per-character. This is useful for ligature-based languages\n', '- Add `--dict` argument to specify a custom dictionary (Thank you [@luh0907](https://github.com/luh0907))\n', '- Add `--font_dir` argument to specify the fonts to use\n', '- Add `--output_mask` to output character-level mask for each image\n', '- Add `--character_spacing` to control space between characters (in pixels)\n', '- Add python module\n', '- Add `--font` to use only one font for all the generated images (Thank you [@JulienCoutault](https://github.com/JulienCoutault)!)\n', '- Add `--fit` and `--margins` for finer layout control\n', '- Change the text orientation using the `-or` parameter\n', ""- Specify text color range using `-tc '#000000,#FFFFFF'`, please note that the quotes are **necessary**\n"", '- Add support for Simplified and Traditional Chinese\n', '\n', '## How does it work?\n', '\n', 'Words will be randomly chosen from a dictionary of a specific language. Then an image of those words will be generated by using font, background, and modifications (skewing, blurring, etc.) as specified.\n', '\n', '### Basic (Python module)\n', '\n', 'The usage as a Python module is very similar to the CLI, but it is more flexible if you want to include it directly in your training pipeline, and will consume less space and memory. There are 4 generators that can be used.\n', '\n', '```py\n', 'from trdg.generators import (\n', '    GeneratorFromDict,\n', '    GeneratorFromRandom,\n', '    GeneratorFromStrings,\n', '    GeneratorFromWikipedia,\n', ')\n', '\n', '# The generators use the same arguments as the CLI, only as parameters\n', 'generator = GeneratorFromStrings(\n', ""    ['Test1', 'Test2', 'Test3'],\n"", '    blur=2,\n', '    random_blur=True\n', ')\n', '\n', 'for img, lbl in generator:\n', '    # Do something with the pillow images here.\n', '```\n', '\n', 'You can see the full class definition here:\n', '\n', '- [`GeneratorFromDict`](trdg/generators/from_dict.py)\n', '- [`GeneratorFromRandom`](trdg/generators/from_random.py)\n', '- [`GeneratorFromStrings`](trdg/generators/from_strings.py)\n', '- [`GeneratorFromWikipedia`](trdg/generators/from_wikipedia.py)\n', '\n', '### Basic (CLI)\n', '\n', '`trdg -c 1000 -w 5 -f 64`\n', '\n', 'You get 1,000 randomly generated images with random text on them like:\n', '\n', '![1](samples/1.jpg ""1"")\n', '![2](samples/2.jpg ""2"")\n', '![3](samples/3.jpg ""3"")\n', '![4](samples/4.jpg ""4"")\n', '![5](samples/5.jpg ""5"")\n', '\n', 'By default, they will be generated to `out/` in the current working directory.\n', '\n', '### Text skewing\n', '\n', 'What if you want random skewing? Add `-k` and `-rk` (`trdg -c 1000 -w 5 -f 64 -k 5 -rk`)\n', '\n', '![6](samples/6.jpg ""6"")\n', '![7](samples/7.jpg ""7"")\n', '![8](samples/8.jpg ""8"")\n', '![9](samples/9.jpg ""9"")\n', '![10](samples/10.jpg ""10"")\n', '\n', '### Text distortion\n', 'You can also add distorsion to the generated text with `-d` and `-do`\n', '\n', '![23](samples/24.jpg ""0"")\n', '![24](samples/25.jpg ""1"")\n', '![25](samples/26.jpg ""2"")\n', '\n', '### Text blurring\n', '\n', ""But scanned document usually aren't that clear are they? Add `-bl` and `-rbl` to get gaussian blur on the generated image with user-defined radius (here 0, 1, 2, 4):\n"", '\n', '![11](samples/11.jpg ""0"")\n', '![12](samples/12.jpg ""1"")\n', '![13](samples/13.jpg ""2"")\n', '![14](samples/14.jpg ""4"")\n', '\n', '### Background\n', '\n', 'Maybe you want another background? Add `-b` to define one of the three available backgrounds: gaussian noise (0), plain white (1), quasicrystal (2) or image (3).\n', '\n', '![15](samples/15.jpg ""0"")\n', '![16](samples/16.jpg ""1"")\n', '![17](samples/17.jpg ""2"")\n', '![23](samples/23.jpg ""3"")\n', '\n', 'When using image background (3). A image from the images/ folder will be randomly selected and the text will be written on it.\n', '\n', '### Handwritten\n', '\n', 'Or maybe you are working on an OCR for handwritten text? Add `-hw`! (Experimental)\n', '\n', '![18](samples/18.jpg ""0"")\n', '![19](samples/19.jpg ""1"")\n', '![20](samples/20.jpg ""2"")\n', '![21](samples/21.jpg ""3"")\n', '![22](samples/22.jpg ""4"")\n', '\n', 'It uses a Tensorflow model trained using [this excellent project](https://github.com/Grzego/handwriting-generation) by Grzego.\n', '\n', ""**The project does not require TensorFlow to run if you aren't using this feature**\n"", '\n', '### Dictionary\n', '\n', 'The text is chosen at random in a dictionary file (that can be found in the *dicts* folder) and drawn on a white background made with Gaussian noise. The resulting image is saved as [text]\\_[index].jpg\n', '\n', 'There are a lot of parameters that you can tune to get the results you want, therefore I recommend checking out `trdg -h` for more information.\n', '\n', '## Create images with Chinese text\n', '\n', 'It is simple! Just do `trdg -l cn -c 1000 -w 5`!\n', '\n', 'Generated texts come both in simplified and traditional Chinese scripts.\n', '\n', 'Traditional:\n', '\n', '![27](samples/27.jpg ""0"")\n', '\n', 'Simplified:\n', '\n', '![28](samples/28.jpg ""1"")\n', '\n', '## Create images with Japanese text \n', '\n', 'It is simple! Just do `trdg -l ja -c 1000 -w 5`!\n', '\n', 'Output \n', '\n', '![29](samples/29.jpg ""2"")\n', '\n', '\n', '## Add new fonts\n', '\n', 'The script picks a font at random from the *fonts* directory.\n', '\n', '| Directory | Languages |\n', '|:----|:-----|\n', '| fonts/latin | English, French, Spanish, German |\n', '| fonts/cn | Chinese |\n', '| fonts/ko | Korean |\n', '| fonts/ja | Japanese |\n', '| fonts/th | Thai |\n', '\n', 'Simply add/remove fonts until you get the desired output.\n', '\n', 'If you want to add a new non-latin language, the amount of work is minimal.\n', '\n', '1. Create a new folder with your language [two-letters code](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes)\n', '2. Add a .ttf font in it\n', '3. Edit `run.py` to add an if statement in `load_fonts()`\n', '4. Add a text file in `dicts` with the same two-letters code\n', '5. Run the tool as you normally would but add `-l` with your two-letters code\n', '\n', 'It only supports .ttf for now.\n', '\n', '## Benchmarks\n', '\n', 'Number of images generated per second.\n', '\n', '- Intel Core i7-4710HQ @ 2.50Ghz + SSD (-c 1000 -w 1)\n', '    - `-t 1` : 363 img/s\n', '    - `-t 2` : 694 img/s\n', '    - `-t 4` : 1300 img/s\n', '    - `-t 8` : 1500 img/s\n', '- AMD Ryzen 7 1700 @ 4.0Ghz + SSD (-c 1000 -w 1)\n', '    - `-t 1` : 558 img/s\n', '    - `-t 2` : 1045 img/s\n', '    - `-t 4` : 2107 img/s\n', '    - `-t 8` : 3297 img/s\n', '\n', '## Contributing\n', '\n', ""1. Create an issue describing the feature you'll be working on\n"", '2. Code said feature\n', '3. Create a pull request\n', '\n', '## Feature request & issues\n', '\n', 'If anything is missing, unclear, or simply not working, open an issue on the repository.\n', '\n', '## What is left to do?\n', '- Better background generation\n', '- Better handwritten text generation\n', '- More customization parameters (mostly regarding background)\n']"
Synthetic+Data,ydataai/ydata-synthetic,ydataai,https://api.github.com/repos/ydataai/ydata-synthetic,916,198,19,"['https://api.github.com/users/fabclmnt', 'https://api.github.com/users/jfsantos-ds', 'https://api.github.com/users/dependabot%5Bbot%5D', 'https://api.github.com/users/renovate%5Bbot%5D', 'https://api.github.com/users/gmartinsribeiro', 'https://api.github.com/users/portellaa', 'https://api.github.com/users/aquemy', 'https://api.github.com/users/vascoalramos', 'https://api.github.com/users/miriamspsantos', 'https://api.github.com/users/ubabe53', 'https://api.github.com/users/arunnthevapalan', 'https://api.github.com/users/strickvl', 'https://api.github.com/users/archity', 'https://api.github.com/users/ceshine', 'https://api.github.com/users/fanconic', 'https://api.github.com/users/crownpku', 'https://api.github.com/users/ricardodcpereira', 'https://api.github.com/users/rajeshai', 'https://api.github.com/users/mglcampos']",Python,2023-04-09T17:09:54Z,https://raw.githubusercontent.com/ydataai/ydata-synthetic/dev/README.md,"['![](https://img.shields.io/github/workflow/status/ydataai/ydata-synthetic/prerelease)\n', '![](https://img.shields.io/pypi/status/ydata-synthetic)\n', '[![](https://pepy.tech/badge/ydata-synthetic)](https://pypi.org/project/ydata-synthetic/)\n', '![](https://img.shields.io/badge/python-3.9%20%7C%203.10-blue)\n', '[![](https://img.shields.io/pypi/v/ydata-synthetic)](https://pypi.org/project/ydata-synthetic/)\n', '![](https://img.shields.io/github/license/ydataai/ydata-synthetic)\n', '\n', '<p align=""center""><img width=""200"" src=""https://user-images.githubusercontent.com/3348134/177604157-11181f6c-57e5-44b1-8f6c-774edbba5512.png"" alt=""Synthetic Data Logo""></p>\n', '\n', 'Join us on [![Discord](https://img.shields.io/badge/Discord-7289DA?style=for-the-badge&logo=discord&logoColor=white)](https://discord.gg/mw7xjJ7b7s)\n', '\n', '# YData Synthetic\n', 'A package to generate synthetic tabular and time-series data leveraging the state of the art generative models.\n', '\n', '## 🎊 We have **big news**: v1.0.0 is here\n', '> We have exciting news for you. The new version of `ydata-synthetic` include new and exciting features:\n', '  > - A conditional architecture for tabular data: CTGAN, which will make the process of synthetic data generation easier and with higher quality!\n', '  > - A new streamlit app that delivers the synthetic data generation experience with a UI interface\n', '\n', '## Synthetic data\n', '### What is synthetic data?\n', ""Synthetic data is artificially generated data that is not collected from real world events. It replicates the statistical components of real data without containing any identifiable information, ensuring individuals' privacy.\n"", '\n', '### Why Synthetic Data?\n', 'Synthetic data can be used for many applications:\n', '  - Privacy\n', '  - Remove bias\n', '  - Balance datasets\n', '  - Augment datasets\n', '\n', '# ydata-synthetic\n', 'This repository contains material related with Generative Adversarial Networks for synthetic data generation, in particular regular tabular data and time-series.\n', 'It consists a set of different GANs architectures developed using Tensorflow 2.0. Several example Jupyter Notebooks and Python scripts are included, to show how to use the different architectures.\n', '\n', '## Quickstart\n', 'The source code is currently hosted on GitHub at: https://github.com/ydataai/ydata-synthetic\n', '\n', 'Binary installers for the latest released version are available at the [Python Package Index (PyPI).](https://pypi.org/project/ydata-synthetic/)\n', '```commandline\n', 'pip install ydata-synthetic\n', '```\n', '\n', '### The UI guide for synthetic data generation\n', '\n', 'YData synthetic has now a UI interface to guide you through the steps and inputs to generate structure tabular data.\n', 'The streamlit app is available form *v1.0.0* onwards, and supports the following flows:\n', '- Train a synthesizer model\n', '- Generate & profile synthetic data samples\n', '\n', '#### Installation\n', '\n', '```commandline\n', 'pip install ydata-syntehtic[streamlit]\n', '```\n', '#### Quickstart\n', 'Use the code snippet below in a python file (Jupyter Notebooks are not supported):\n', '```python\n', 'from ydata_synthetic import streamlit_app\n', '\n', 'streamlit_app.run()\n', '```\n', '\n', 'Or use the file streamlit_app.py that can be found in the [examples folder](https://github.com/ydataai/ydata-synthetic/tree/master/examples/streamlit_app.py).\n', '\n', '```commandline\n', 'python -m streamlit_app\n', '```\n', '\n', 'The below models are supported:\n', '  - CGAN\n', '  - WGAN\n', '  - WGANGP\n', '  - DRAGAN\n', '  - CRAMER\n', '  - CTGAN\n', '\n', '[![Watch the video](assets/streamlit_app.png)](https://youtu.be/ep0PhwsFx0A)\n', '\n', '### Examples\n', 'Here you can find usage examples of the package and models to synthesize tabular data.\n', '  \n', '  - Tabular synthetic data generation with CTGAN on adult census income dataset [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ydataai/ydata-synthetic/blob/master/examples/regular/models/CTGAN_Adult_Census_Income_Data.ipynb)\n', '  - Time Series synthetic data generation with TimeGAN on stock dataset [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ydataai/ydata-synthetic/blob/master/examples/timeseries/TimeGAN_Synthetic_stock_data.ipynb)\n', '  - More examples are continuously added and can be found in `/examples` directory.\n', '\n', '### Datasets for you to experiment\n', 'Here are some example datasets for you to try with the synthesizers:\n', '#### Tabular datasets\n', '- [Adult Census Income](https://www.kaggle.com/datasets/uciml/adult-census-income)\n', '- [Credit card fraud](https://www.kaggle.com/mlg-ulb/creditcardfraud)\n', '- [Cardiovascular Disease dataset](https://www.kaggle.com/datasets/sulianova/cardiovascular-disease-dataset)\n', '\n', '#### Sequential datasets\n', '- [Stock data](https://github.com/ydataai/ydata-synthetic/tree/master/data)\n', '\n', '## Project Resources\n', '\n', 'In this repository you can find the several GAN architectures that are used to create synthesizers:\n', '\n', '### Tabular data\n', '  - [GAN](https://arxiv.org/abs/1406.2661)\n', '  - [CGAN (Conditional GAN)](https://arxiv.org/abs/1411.1784)\n', '  - [WGAN (Wasserstein GAN)](https://arxiv.org/abs/1701.07875)\n', '  - [WGAN-GP (Wassertein GAN with Gradient Penalty)](https://arxiv.org/abs/1704.00028)\n', '  - [DRAGAN (On Convergence and stability of GANS)](https://arxiv.org/pdf/1705.07215.pdf)\n', '  - [Cramer GAN (The Cramer Distance as a Solution to Biased Wasserstein Gradients)](https://arxiv.org/abs/1705.10743)\n', '  - [CWGAN-GP (Conditional Wassertein GAN with Gradient Penalty)](https://cameronfabbri.github.io/papers/conditionalWGAN.pdf)\n', '  - [CTGAN (Conditional Tabular GAN)](https://arxiv.org/pdf/1907.00503.pdf)\n', '\n', '### Sequential data\n', '  - [TimeGAN](https://papers.nips.cc/paper/2019/file/c9efe5f26cd17ba6216bbe2a7d26d490-Paper.pdf)\n', '\n', '## Contributing\n', 'We are open to collaboration! If you want to start contributing you only need to:\n', '  1. Search for an issue in which you would like to work. Issues for newcomers are labeled with good first issue.\n', '  2. Create a PR solving the issue.\n', '  3. We would review every PRs and either accept or ask for revisions.\n', '\n', '## Support\n', 'For support in using this library, please join our Discord server. Our Discord community is very friendly and great about quickly answering questions about the use and development of the library. [Click here to join our Discord community!](https://discord.com/invite/mw7xjJ7b7s)\n', '\n', '## License\n', '[MIT License](https://github.com/ydataai/ydata-synthetic/blob/master/LICENSE)\n']"
Synthetic+Data,sdv-dev/CTGAN,sdv-dev,https://api.github.com/repos/sdv-dev/CTGAN,848,225,17,"['https://api.github.com/users/csala', 'https://api.github.com/users/fealho', 'https://api.github.com/users/pvk-developer', 'https://api.github.com/users/leix28', 'https://api.github.com/users/amontanez24', 'https://api.github.com/users/katxiao', 'https://api.github.com/users/kevinykuo', 'https://api.github.com/users/npatki', 'https://api.github.com/users/oregonpillow', 'https://api.github.com/users/JDTheRipperPC', 'https://api.github.com/users/tejuafonja', 'https://api.github.com/users/Baukebrenninkmeijer', 'https://api.github.com/users/lurosenb', 'https://api.github.com/users/matheusccouto', 'https://api.github.com/users/Deathn0t', 'https://api.github.com/users/timvink', 'https://api.github.com/users/mfhbree']",Python,2023-04-08T08:18:22Z,https://raw.githubusercontent.com/sdv-dev/CTGAN/master/README.md,"['<div align=""center"">\n', '<br/>\n', '<p align=""center"">\n', '    <i>This repository is part of <a href=""https://sdv.dev"">The Synthetic Data Vault Project</a>, a project from <a href=""https://datacebo.com"">DataCebo</a>.</i>\n', '</p>\n', '\n', '[![Development Status](https://img.shields.io/badge/Development%20Status-2%20--%20Pre--Alpha-yellow)](https://pypi.org/search/?c=Development+Status+%3A%3A+2+-+Pre-Alpha)\n', '[![PyPI Shield](https://img.shields.io/pypi/v/ctgan.svg)](https://pypi.python.org/pypi/ctgan)\n', '[![Unit Tests](https://github.com/sdv-dev/CTGAN/actions/workflows/unit.yml/badge.svg)](https://github.com/sdv-dev/CTGAN/actions/workflows/unit.yml)\n', '[![Downloads](https://pepy.tech/badge/ctgan)](https://pepy.tech/project/ctgan)\n', '[![Coverage Status](https://codecov.io/gh/sdv-dev/CTGAN/branch/master/graph/badge.svg)](https://codecov.io/gh/sdv-dev/CTGAN)\n', '\n', '<div align=""left"">\n', '<br/>\n', '<p align=""center"">\n', '<a href=""https://github.com/sdv-dev/CTGAN"">\n', '<img align=""center"" width=40% src=""https://github.com/sdv-dev/SDV/blob/master/docs/images/CTGAN-DataCebo.png""></img>\n', '</a>\n', '</p>\n', '</div>\n', '\n', '</div>\n', '\n', '# Overview\n', '\n', 'CTGAN\xa0is a collection of Deep Learning based\xa0synthetic data generators\xa0for\xa0single table\xa0data, which are able to learn from real data and generate synthetic data with high fidelity.\n', '\n', '| Important Links                               |                                                                      |\n', '| --------------------------------------------- | -------------------------------------------------------------------- |\n', '| :computer: **[Website]**                      | Check out the SDV Website for more information about our overall synthetic data ecosystem.|\n', '| :orange_book: **[Blog]**                      | A deeper look at open source, synthetic data creation and evaluation.|\n', '| :book: **[Documentation]**                    | Quickstarts, User and Development Guides, and API Reference.         |\n', '| :octocat: **[Repository]**                    | The link to the Github Repository of this library.                   |\n', '| :keyboard: **[Development Status]**           | This software is in its Pre-Alpha stage.                             |\n', '| [![][Slack Logo] **Community**][Community]    | Join our Slack Workspace for announcements and discussions.          |\n', '\n', '[Website]: https://sdv.dev\n', '[Blog]: https://datacebo.com/blog\n', '[Documentation]: https://bit.ly/sdv-docs\n', '[Repository]: https://github.com/sdv-dev/CTGAN\n', '[License]: https://github.com/sdv-dev/CTGAN/blob/master/LICENSE\n', '[Development Status]: https://pypi.org/search/?c=Development+Status+%3A%3A+2+-+Pre-Alpha\n', '[Slack Logo]: https://github.com/sdv-dev/SDV/blob/master/docs/images/slack.png\n', '[Community]: https://bit.ly/sdv-slack-invite\n', '\n', 'Currently, this library implements the **CTGAN** and **TVAE** models described in the [Modeling Tabular data using Conditional GAN](https://arxiv.org/abs/1907.00503) paper, presented at the 2019 NeurIPS conference.\n', '\n', '# Install\n', '\n', '## Use CTGAN through the SDV library\n', '\n', "":warning: If you're just getting started with synthetic data, we recommend installing the SDV library which provides user-friendly APIs for accessing CTGAN. :warning:\n"", '\n', 'The SDV library provides wrappers for preprocessing your data as well as additional usability features like constraints. See the [SDV documentation](https://bit.ly/sdv-docs) to get started.\n', '\n', '## Use the CTGAN standalone library\n', '\n', 'Alternatively, you can also install and use **CTGAN** directly, as a standalone library:\n', '\n', '**Using `pip`:**\n', '\n', '```bash\n', 'pip install ctgan\n', '```\n', '\n', '**Using `conda`:**\n', '\n', '```bash\n', 'conda install -c pytorch -c conda-forge ctgan\n', '```\n', '\n', 'When using the CTGAN library directly, you may need to manually preprocess your data into the correct format, for example:\n', '\n', '* Continuous data must be represented as floats\n', '* Discrete data must be represented as ints or strings\n', '* The data should not contain any missing values\n', '\n', '# Usage Example\n', '\n', 'In this example we load the [Adult Census Dataset](https://archive.ics.uci.edu/ml/datasets/adult)* which is a built-in demo dataset. We use CTGAN to learn from the real data and then generate some synthetic data.\n', '\n', '```python3\n', 'from ctgan import CTGAN\n', 'from ctgan import load_demo\n', '\n', 'real_data = load_demo()\n', '\n', '# Names of the columns that are discrete\n', 'discrete_columns = [\n', ""    'workclass',\n"", ""    'education',\n"", ""    'marital-status',\n"", ""    'occupation',\n"", ""    'relationship',\n"", ""    'race',\n"", ""    'sex',\n"", ""    'native-country',\n"", ""    'income'\n"", ']\n', '\n', 'ctgan = CTGAN(epochs=10)\n', 'ctgan.fit(real_data, discrete_columns)\n', '\n', '# Create synthetic data\n', 'synthetic_data = ctgan.sample(1000)\n', '```\n', '\n', '*For more information about the dataset see:\n', 'Dua, D. and Graff, C. (2019). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml].\n', 'Irvine, CA: University of California, School of Information and Computer Science.\n', '\n', '# Join our community\n', '\n', 'Join our [Slack channel](https://bit.ly/sdv-slack-invite) to discuss more about CTGAN and synthetic data. If you find a bug or have a feature request, you can also [open an issue](https://github.com/sdv-dev/CTGAN/issues) on our GitHub.\n', '\n', '**Interested in contributing to CTGAN?** Read our [Contribution Guide](CONTRIBUTING.rst) to get started.\n', '\n', '# Citing CTGAN\n', '\n', 'If you use CTGAN, please cite the following work:\n', '\n', '*Lei Xu, Maria Skoularidou, Alfredo Cuesta-Infante, Kalyan Veeramachaneni.* **Modeling Tabular data using Conditional GAN**. NeurIPS, 2019.\n', '\n', '```LaTeX\n', '@inproceedings{ctgan,\n', '  title={Modeling Tabular data using Conditional GAN},\n', '  author={Xu, Lei and Skoularidou, Maria and Cuesta-Infante, Alfredo and Veeramachaneni, Kalyan},\n', '  booktitle={Advances in Neural Information Processing Systems},\n', '  year={2019}\n', '}\n', '```\n', '\n', '# Related Projects\n', 'Please note that these projects are external to the SDV Ecosystem. They are not affiliated with or maintained by DataCebo.\n', '\n', '* **R Interface for CTGAN**: A wrapper around **CTGAN** that brings the functionalities to **R** users.\n', 'More details can be found in the corresponding repository: https://github.com/kasaai/ctgan\n', '* **CTGAN Server CLI**: A package to easily deploy CTGAN onto a remote server. Created by Timothy Pillow @oregonpillow at: https://github.com/oregonpillow/ctgan-server-cli\n', '\n', '---\n', '\n', '\n', '<div align=""center"">\n', '<a href=""https://datacebo.com""><img align=""center"" width=40% src=""https://github.com/sdv-dev/SDV/blob/master/docs/images/DataCebo.png""></img></a>\n', '</div>\n', '<br/>\n', '<br/>\n', '\n', ""[The Synthetic Data Vault Project](https://sdv.dev) was first created at MIT's [Data to AI Lab](\n"", 'https://dai.lids.mit.edu/) in 2016. After 4 years of research and traction with enterprise, we\n', 'created [DataCebo](https://datacebo.com) in 2020 with the goal of growing the project.\n', 'Today, DataCebo is the proud developer of SDV, the largest ecosystem for\n', 'synthetic data generation & evaluation. It is home to multiple libraries that support synthetic\n', 'data, including:\n', '\n', '* 🔄 Data discovery & transformation. Reverse the transforms to reproduce realistic data.\n', '* 🧠 Multiple machine learning models -- ranging from Copulas to Deep Learning -- to create tabular,\n', '  multi table and time series data.\n', '* 📊 Measuring quality and privacy of synthetic data, and comparing different synthetic data\n', '  generation models.\n', '\n', '[Get started using the SDV package](https://sdv.dev/SDV/getting_started/install.html) -- a fully\n', 'integrated solution and your one-stop shop for synthetic data. Or, use the standalone libraries\n', 'for specific needs.\n']"
Synthetic+Data,sdv-dev/SDV,sdv-dev,https://api.github.com/repos/sdv-dev/SDV,1349,214,19,"['https://api.github.com/users/csala', 'https://api.github.com/users/ManuelAlvarezC', 'https://api.github.com/users/amontanez24', 'https://api.github.com/users/JDTheRipperPC', 'https://api.github.com/users/katxiao', 'https://api.github.com/users/fealho', 'https://api.github.com/users/pvk-developer', 'https://api.github.com/users/frances-h', 'https://api.github.com/users/npatki', 'https://api.github.com/users/kveerama', 'https://api.github.com/users/xamm', 'https://api.github.com/users/sarahmish', 'https://api.github.com/users/Aylr', 'https://api.github.com/users/R-Palazzo', 'https://api.github.com/users/dyuliu', 'https://api.github.com/users/ludovicc', 'https://api.github.com/users/Deathn0t', 'https://api.github.com/users/rollervan', 'https://api.github.com/users/tssbas']",Python,2023-04-08T08:59:13Z,https://raw.githubusercontent.com/sdv-dev/SDV/master/README.md,"['<div align=""center"">\n', '<br/>\n', '<p align=""center"">\n', '    <i>This repository is part of <a href=""https://sdv.dev"">The Synthetic Data Vault Project</a>, a project from <a href=""https://datacebo.com"">DataCebo</a>.</i>\n', '</p>\n', '\n', '[![Dev Status](https://img.shields.io/badge/Dev%20Status-5%20--%20Production%2fStable-green)](https://pypi.org/search/?c=Development+Status+%3A%3A+5+-+Production%2FStable)\n', '[![PyPi Shield](https://img.shields.io/pypi/v/SDV.svg)](https://pypi.python.org/pypi/SDV)\n', '[![Unit Tests](https://github.com/sdv-dev/SDV/actions/workflows/unit.yml/badge.svg?branch=master)](https://github.com/sdv-dev/SDV/actions/workflows/unit.yml?query=branch%3Amaster)\n', '[![Integration Tests](https://github.com/sdv-dev/SDV/actions/workflows/integration.yml/badge.svg?branch=master)](https://github.com/sdv-dev/SDV/actions/workflows/integration.yml?query=branch%3Amaster)\n', '[![Coverage Status](https://codecov.io/gh/sdv-dev/SDV/branch/master/graph/badge.svg)](https://codecov.io/gh/sdv-dev/SDV)\n', '[![Downloads](https://static.pepy.tech/personalized-badge/sdv?period=total&units=international_system&left_color=grey&right_color=blue&left_text=Downloads)](https://pepy.tech/project/sdv)\n', '[![Colab](https://img.shields.io/badge/Tutorials-Try%20now!-orange?logo=googlecolab)](https://docs.sdv.dev/sdv/demos)\n', '[![Slack](https://img.shields.io/badge/Slack-Join%20now!-36C5F0?logo=slack)](https://bit.ly/sdv-slack-invite)\n', '\n', '<div align=""left"">\n', '<br/>\n', '<p align=""center"">\n', '<a href=""https://github.com/sdv-dev/SDV"">\n', '<img align=""center"" width=40% src=""https://github.com/sdv-dev/SDV/blob/master/docs/images/SDV-logo.png""></img>\n', '</a>\n', '</p>\n', '</div>\n', '\n', '</div>\n', '\n', '# Overview\n', '\n', 'The **Synthetic Data Vault** (SDV) is a Python library designed to be your one-stop shop for\n', 'creating tabular synthetic data. The SDV uses a variety of machine learning algorithms to learn\n', 'patterns from your real data and emulate them in synthetic data.\n', '\n', '## Features\n', ':brain: **Create synthetic data using machine learning.** The SDV offers multiple models, ranging\n', 'from classical statistical methods (GaussianCopula) to deep learning methods (CTGAN). Generate\n', 'data for single tables, multiple connected tables or sequential tables.\n', '\n', ':bar_chart: **Evaluate and visualize data.** Compare the synthetic data to the real data against a\n', 'variety of measures. Diagnose problems and generate a quality report to get more insights.\n', '\n', ':arrows_counterclockwise: **Preprocess, anonymize and define constraints.** Control data\n', 'processing to improve the quality of synthetic data, choose from different types of anonymization\n', 'and define business rules in the form of logical constraints.\n', '\n', '| Important Links                               |                                                                                                     |\n', '| --------------------------------------------- | ----------------------------------------------------------------------------------------------------|\n', '| [![][Colab Logo] **Tutorials**][Tutorials]    | Get some hands-on experience with the SDV. Launch the tutorial notebooks and run the code yourself. |\n', '| :book: **[Docs]**                             | Learn how to use the SDV library with user guides and API references.                               |\n', '| :orange_book: **[Blog]**                      | Get more insights about using the SDV, deploying models and our synthetic data community.          |\n', '| [![][Slack Logo] **Community**][Community]    | Join our Slack workspace for announcements and discussions.                                         |\n', '| :computer: **[Website]**                      | Check out the SDV website for more information about the project.                                   |\n', '\n', '[Website]: https://sdv.dev\n', '[Blog]: https://datacebo.com/blog\n', '[Docs]: https://bit.ly/sdv-docs\n', '[Repository]: https://github.com/sdv-dev/SDV\n', '[License]: https://github.com/sdv-dev/SDV/blob/master/LICENSE\n', '[Development Status]: https://pypi.org/search/?c=Development+Status+%3A%3A+5+-+Production%2FStable\n', '[Slack Logo]: https://github.com/sdv-dev/SDV/blob/master/docs/images/slack.png\n', '[Community]: https://bit.ly/sdv-slack-invite\n', '[Colab Logo]: https://github.com/sdv-dev/SDV/blob/master/docs/images/google_colab.png\n', '[Tutorials]: https://docs.sdv.dev/sdv/demos\n', '\n', '# Install\n', 'The SDV is publicly available under the [Business Source License](https://github.com/sdv-dev/SDV/blob/master/LICENSE).\n', 'Install SDV using pip or conda. We recommend using a virtual environment to avoid conflicts with\n', 'other software on your device.\n', '\n', '```bash\n', 'pip install sdv\n', '```\n', '\n', '```bash\n', 'conda install -c pytorch -c conda-forge sdv\n', '```\n', '\n', '# Getting Started\n', 'Load a demo dataset to get started. This dataset is a single table describing guests staying at a\n', 'fictional hotel.\n', '\n', '```python\n', 'from sdv.datasets.demo import download_demo\n', '\n', 'real_data, metadata = download_demo(\n', ""    modality='single_table',\n"", ""    dataset_name='fake_hotel_guests')\n"", '```\n', '\n', '![Single Table Metadata Example](https://github.com/sdv-dev/SDV/blob/master/docs/images/Single-Table-Metadata-Example.png)\n', '\n', 'The demo also includes **metadata**, a description of the dataset, including the data types in each\n', 'column and the primary key (`guest_email`).\n', '\n', '## Synthesizing Data\n', 'Next, we can create an **SDV synthesizer**,  an object that you can use to create synthetic data.\n', ""It learns patterns from the real data and replicates them to generate synthetic data. Let's use\n"", 'the `FAST_ML` preset synthesizer, which is optimized for performance.\n', '\n', '```python\n', 'from sdv.lite import SingleTablePreset\n', '\n', ""synthesizer = SingleTablePreset(metadata, name='FAST_ML')\n"", 'synthesizer.fit(data=real_data)\n', '```\n', '\n', 'And now the synthesizer is ready to create synthetic data!\n', '\n', '```python\n', 'synthetic_data = synthesizer.sample(num_rows=500)\n', '```\n', '\n', 'The synthetic data will have the following properties:\n', '- **Sensitive columns are fully anonymized.** The email, billing address and credit card number\n', ""columns contain new data so you don't expose the real values.\n"", '- **Other columns follow statistical patterns.** For example, the proportion of room types, the\n', 'distribution of check in dates and the correlations between room rate and room type are preserved.\n', '- **Keys and other relationships are intact.** The primary key (guest email) is unique for each row.\n', 'If you have multiple tables, the connection between a primary and foreign keys makes sense.\n', '\n', '## Evaluating Synthetic Data\n', 'The SDV library allows you to evaluate the synthetic data by comparing it to the real data. Get\n', 'started by generating a quality report.\n', '\n', '```python\n', 'from sdv.evaluation.single_table import evaluate_quality\n', '\n', 'quality_report = evaluate_quality(\n', '    real_data,\n', '    synthetic_data,\n', '    metadata)\n', '```\n', '\n', '```\n', 'Creating report: 100%|██████████| 4/4 [00:00<00:00, 19.30it/s]\n', 'Overall Quality Score: 89.12%\n', 'Properties:\n', 'Column Shapes: 90.27%\n', 'Column Pair Trends: 87.97%\n', '```\n', '\n', 'This object computes an overall quality score on a scale of 0 to 100% (100 being the best) as well\n', 'as detailed breakdowns. For more insights, you can also visualize the synthetic vs. real data.\n', '\n', '```python\n', 'from sdv.evaluation.single_table import get_column_plot\n', '\n', 'fig = get_column_plot(\n', '    real_data=real_data,\n', '    synthetic_data=synthetic_data,\n', ""    column_name='amenities_fee',\n"", '    metadata=metadata\n', ')\n', '    \n', 'fig.show()\n', '```\n', '\n', '![Real vs. Synthetic Data](https://github.com/sdv-dev/SDV/blob/master/docs/images/Real-vs-Synthetic-Evaluation.png)\n', '\n', ""# What's Next?\n"", 'Using the SDV library, you can synthesize single table, multi table and sequential data. You can\n', 'also customize the full synthetic data workflow, including preprocessing, anonymization and adding\n', 'constraints.\n', '\n', 'To learn more, visit the [SDV Demo page](https://docs.sdv.dev/sdv/demos).\n', '\n', '# Credits\n', 'Thank you to our team of contributors who have built and maintained the SDV ecosystem over the\n', 'years!\n', '\n', '[View Contributors](https://github.com/sdv-dev/SDV/graphs/contributors)\n', '\n', '## Citation\n', 'If you use SDV for your research, please cite the following paper:\n', '\n', '*Neha Patki, Roy Wedge, Kalyan Veeramachaneni*. [The Synthetic Data Vault](https://dai.lids.mit.edu/wp-content/uploads/2018/03/SDV.pdf). [IEEE DSAA 2016](https://ieeexplore.ieee.org/document/7796926).\n', '\n', '```\n', '@inproceedings{\n', '    SDV,\n', '    title={The Synthetic data vault},\n', '    author={Patki, Neha and Wedge, Roy and Veeramachaneni, Kalyan},\n', '    booktitle={IEEE International Conference on Data Science and Advanced Analytics (DSAA)},\n', '    year={2016},\n', '    pages={399-410},\n', '    doi={10.1109/DSAA.2016.49},\n', '    month={Oct}\n', '}\n', '```\n', '\n', '---\n', '\n', '\n', '<div align=""center"">\n', '  <a href=""https://datacebo.com""><picture>\n', '      <source media=""(prefers-color-scheme: dark)"" srcset=""https://github.com/sdv-dev/SDV/blob/master/docs/images/datacebo-logo-dark-mode.png"">\n', '      <img align=""center"" width=40% src=""https://github.com/sdv-dev/SDV/blob/master/docs/images/datacebo-logo.png""></img>\n', '  </picture></a>\n', '</div>\n', '<br/>\n', '<br/>\n', '\n', ""[The Synthetic Data Vault Project](https://sdv.dev) was first created at MIT's [Data to AI Lab](\n"", 'https://dai.lids.mit.edu/) in 2016. After 4 years of research and traction with enterprise, we\n', 'created [DataCebo](https://datacebo.com) in 2020 with the goal of growing the project.\n', 'Today, DataCebo is the proud developer of SDV, the largest ecosystem for\n', 'synthetic data generation & evaluation. It is home to multiple libraries that support synthetic\n', 'data, including:\n', '\n', '* 🔄 Data discovery & transformation. Reverse the transforms to reproduce realistic data.\n', '* 🧠 Multiple machine learning models -- ranging from Copulas to Deep Learning -- to create tabular,\n', '  multi table and time series data.\n', '* 📊 Measuring quality and privacy of synthetic data, and comparing different synthetic data\n', '  generation models.\n', '\n', '[Get started using the SDV package](https://bit.ly/sdv-docs) -- a fully\n', 'integrated solution and your one-stop shop for synthetic data. Or, use the standalone libraries\n', 'for specific needs.\n']"
Synthetic+Data,wang-tf/Chinese_OCR_synthetic_data,wang-tf,https://api.github.com/repos/wang-tf/Chinese_OCR_synthetic_data,256,86,0,[],Python,2023-04-06T09:36:31Z,https://raw.githubusercontent.com/wang-tf/Chinese_OCR_synthetic_data/master/README.md,"['# Chinese_OCR_synthetic_data\n', '---\n', '## The progress was used to generate synthetic dataset for Chinese OCR.\n', 'Here we used [Augmenter](https://github.com/mdbloice/Augmentor) to augment out output characters in images, including rotate, skew, shear and distort.\n', 'And you can change characters.txt file to use other characters.\n', 'The main function can be found in the synthetic_data.py file.\n', '\n', 'The python package you may need:\n', '- tqdm\n', '- PIL(pillow)\n', '- pathlib\n', '- cv2(opencv)\n', '- numpy\n', '- codecs\n', '- glob\n', '\n', '---\n', '## 本程序用于合成中文OCR数据库。\n', '本程序使用了[Augmenter](https://github.com/mdbloice/Augmentor)库，以对输出的图像进行增强图片中的文本，其中包括旋转、倾斜、剪切和扭曲。这些形变的参数可以在utils.py中找到并修改。\n', '在characters.txt中存放着所有的中文字符，如果想更换训练的字符请替换该文件。\n', 'main函数在synthetic_data.py中，可以按需要做修改。\n', '\n', '使用之前可能需要安装一下的包：\n', '- tqdm\n', '- PIL(pillow)\n', '- pathlib\n', '- cv2(opencv)\n', '- numpy\n', '- codecs\n', '- glob\n', '\n', '\n', '![test](https://github.com/wang-tf/Chinese_OCR_synthetic_data/blob/master/test_ocrdataset/train_part_image/0_0.jpg)\n']"
Synthetic+Data,GeostatsGuy/GeoDataSets,GeostatsGuy,https://api.github.com/repos/GeostatsGuy/GeoDataSets,46,108,1,['https://api.github.com/users/GeostatsGuy'],,2023-03-24T08:25:41Z,https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/README.md,"['<p>\n', '    <img src=""https://github.com/GeostatsGuy/GeostatsPy/blob/master/TCG_color_logo.png"" width=""220"" height=""200"" />\n', '</p>\n', '\n', '# GeoDataSets: Synthetic Subsurface Data Repository (1.0.0) \n', '\n', '## Prof. Michael J. Pyrcz, Associate Professor, The University of Texas at Austin\n', '\n', 'A collection of synthetic subsurface datasets to support education, publications, and prototyping.\n', '\n', 'Please cite as:\n', '\n', 'Pyrcz, Michael J. (2021). GeoDataSets: Synthetic Subsurface Data Repository (1.0.0). Zenodo. https://doi.org/10.5281/zenodo.5564874\n', '\n', 'This repository includes a wide variety of synthetic, subsurface datasets with a variety of:\n', '\n', '#### Data Dimensionality\n', '\n', 'To support education with easy visualization and interactivity the datasets are 1D and 2D.\n', '\n', '* 1D cores from wells and 2D seismic maps. \n', '\n', '#### Number of Features\n', '\n', 'For multivariate analysis some of the datasets include up to 6 features with a variety of structures.\n', '\n', '* linear and nonlinear, homoscedastic and heteroscedastic, and multivariate constraints \n', '\n', '#### Data Issues\n', '\n', 'The datasets attempt to include typical issues such as non-physical values, random and structured noise\n', '\n', '#### Use and Attribution\n', '\n', 'You are welcome to use these datasets for any purpose. Please cite the repository as:\n', '\n', 'Pyrcz, M.J., 2021, GeoDataSets Repository, GitHub Respository, https://github.com/GeostatsGuy/GeoDataSets/.\n', '\n', 'I hope this is helpful,\n', '\n', 'Michael\n']"
Synthetic+Data,gretelai/gretel-synthetics,gretelai,https://api.github.com/repos/gretelai/gretel-synthetics,383,61,21,"['https://api.github.com/users/zredlined', 'https://api.github.com/users/johntmyers', 'https://api.github.com/users/drew', 'https://api.github.com/users/kboyd', 'https://api.github.com/users/misberner', 'https://api.github.com/users/tylersbray', 'https://api.github.com/users/pimlock', 'https://api.github.com/users/lipikaramaswamy', 'https://api.github.com/users/santhosh97', 'https://api.github.com/users/anthager', 'https://api.github.com/users/lememta', 'https://api.github.com/users/andrewnc', 'https://api.github.com/users/arronhunt', 'https://api.github.com/users/Marjan-emd', 'https://api.github.com/users/mckornfield', 'https://api.github.com/users/anastasia-nesterenko', 'https://api.github.com/users/dni138', 'https://api.github.com/users/hgascon', 'https://api.github.com/users/Jeesh96', 'https://api.github.com/users/csbailey5t', 'https://api.github.com/users/theonlyrob']",Python,2023-04-07T07:17:55Z,https://raw.githubusercontent.com/gretelai/gretel-synthetics/master/README.md,"['# Gretel Synthetics\n', '\n', '<p align=""center"">\n', '    <a href=""https://gretel.ai""><img width=""128px"" src=""https://gretel-public-website.s3.amazonaws.com/assets/gobs_the_cat_@1x.png"" alt=""Gobs the Gretel.ai cat"" /></a><br />\n', '    <i>A permissive synthetic data library from Gretel.ai</i>\n', '</p>\n', '\n', '[![Documentation Status](https://readthedocs.org/projects/gretel-synthetics/badge/?version=stable)](https://gretel-synthetics.readthedocs.io/en/stable/?badge=stable)\n', '[![CLA assistant](https://cla-assistant.io/readme/badge/gretelai/gretel-synthetics)](https://cla-assistant.io/gretelai/gretel-synthetics)\n', '[![PyPI](https://badge.fury.io/py/gretel-synthetics.svg)](https://badge.fury.io/py/gretel-synthetics)\n', '[![Python](https://img.shields.io/pypi/pyversions/gretel-synthetics.svg)](https://github.com/gretelai/gretel-synthetics)\n', '[![Downloads](https://pepy.tech/badge/gretel-synthetics)](https://pepy.tech/project/gretel-synthetics)\n', '[![GitHub stars](https://img.shields.io/github/stars/gretelai/gretel-synthetics?style=social)](https://github.com/gretelai/gretel-synthetics)\n', '[![Discord](https://img.shields.io/discord/1007817822614847500?label=Discord&logo=Discord)](https://gretel.ai/discord)\n', '\n', '## Documentation\n', '\n', '- [Get started with gretel-synthetics](https://gretel-synthetics.readthedocs.io/en/stable/)\n', '- [Configuration](https://gretel-synthetics.readthedocs.io/en/stable/api/config.html)\n', '- [Train your model](https://gretel-synthetics.readthedocs.io/en/stable/api/train.html)\n', '- [Generate synthetic records](https://gretel-synthetics.readthedocs.io/en/stable/api/generate.html)\n', '\n', '## Try it out now!\n', '\n', 'If you want to quickly discover gretel-synthetics, simply click the button below and follow the tutorials!\n', '\n', '[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/gretelai/gretel-synthetics/blob/master/examples/synthetic_records.ipynb)\n', '\n', 'Check out additional examples [here](https://github.com/gretelai/gretel-synthetics/tree/master/examples).\n', '\n', '## Getting Started\n', '\n', 'This section will guide you through installation of `gretel-synthetics` and dependencies that are not directly installed by the Python package manager.\n', '\n', '### Dependency Requirements\n', '\n', 'By default, we do not install certain core requirements, the following dependencies should be installed _external to the installation_\n', 'of `gretel-synthetics`, depending on which model(s) you plan to use.\n', '\n', '- Tensorflow: Used by the LSTM model, we recommend version 2.8.x\n', '- Torch: Used by Timeseries DGAN and ACTGAN (for ACTGAN, Torch is installed by SDV)\n', '- SDV (Synthetic Data Vault): Used by ACTGAN, we recommned version 0.17.x\n', '\n', 'These dependencies can be installed by doing the following:\n', '\n', '```\n', 'pip install tensorflow==2.8 # for LSTM\n', 'pip install sdv<0.18 # for ACTGAN\n', 'pip install torch==1.13.1 # for Timeseries DGAN\n', '```\n', '\n', 'To install the actual `gretel-synthetics` package, first clone the repo and then...\n', '\n', '```\n', 'pip install -U .\n', '```\n', '\n', '_or_\n', '\n', '```\n', 'pip install gretel-synthetics\n', '```\n', '\n', '_then..._\n', '\n', '```\n', '$ pip install jupyter\n', '$ jupyter notebook\n', '```\n', '\n', 'When the UI launches in your browser, navigate to `examples/synthetic_records.ipynb` and get generating!\n', '\n', 'If you want to install `gretel-synthetics` locally and use a GPU (recommended):\n', '\n', '1. Create a virtual environment (e.g. using `conda`)\n', '\n', '```\n', '$ conda create --name tf python=3.9\n', '```\n', '\n', '2. Activate the virtual environment\n', '\n', '```\n', '$ conda activate tf\n', '```\n', '\n', '3. Run the setup script `./setup-utils/setup-gretel-synthetics-tensorflow24-with-gpu.sh`\n', '\n', 'The last step will install all the necessary software packages for GPU usage, `tensorflow=2.8` and `gretel-synthetics`.\n', 'Note that this script works only for Ubuntu 18.04. You might need to modify it for other OS versions.\n', '\n', '## Timeseries DGAN Overview\n', '\n', 'The [timeseries DGAN module](https://synthetics.docs.gretel.ai/en/stable/models/timeseries_dgan.html#timeseries-dgan) contains a PyTorch implementation of a DoppelGANger model that is optimized for timeseries data. Similar to tensorflow, you will need to manually install pytorch:\n', '\n', '```\n', 'pip install torch==1.13.1\n', '```\n', '\n', '[This notebook](https://github.com/gretelai/gretel-synthetics/blob/master/examples/timeseries_dgan.ipynb) shows basic usage on a small data set of smart home sensor readings.\n', '\n', '## ACTGAN Overview\n', '\n', 'ACTGAN (Anyway CTGAN) is an extension of the popular [CTGAN implementation](https://sdv.dev/SDV/user_guides/single_table/ctgan.html) that provides\n', 'some additiona functionality to improve memory usage, autodetection and transformation of columns, and more.\n', '\n', 'To use this model, you will need to manually install SDV:\n', '\n', '```\n', 'pip install sdv<0.18\n', '```\n', '\n', 'Keep in mind that this will also install several dependencies like PyTorch that SDV relies on, which may conflict with PyTorch\n', 'versions installed for use with other models like Timeseries DGAN.\n', '\n', 'The ACTGAN interface is a superset of the CTGAN interface. To see the additional features, please take a look at the ACTGAN demo notebook in the `examples` directory of this repo.\n', '\n', '## LSTM Overview\n', '\n', 'This package allows developers to quickly get immersed with synthetic data generation through the use of neural networks. The more complex pieces of working with libraries like Tensorflow and differential privacy are bundled into friendly Python classes and functions. There are two high level modes that can be utilized.\n', '\n', '### Simple Mode\n', '\n', 'The simple mode will train line-per-line on an input file of text. When generating data, the generator will yield a custom object that can be used a variety of different ways based on your use case. [This notebook](https://github.com/gretelai/gretel-synthetics/blob/master/examples/tensorflow/simple-character-model.ipynb) demonstrates this mode.\n', '\n', '### DataFrame Mode\n', '\n', 'This library supports CSV / DataFrames natively using the DataFrame ""batch"" mode. This module provided a wrapper around our simple mode that is geared for working with tabular data. Additionally, it is capabable of handling a high number of columns by breaking the input DataFrame up into ""batches"" of columns and training a model on each batch. [This notebook](https://github.com/gretelai/gretel-synthetics/blob/master/examples/dataframe_batch.ipynb) shows an overview of using this library with DataFrames natively.\n', '\n', '### Components\n', '\n', 'There are four primary components to be aware of when using this library.\n', '\n', '1. Configurations. Configurations are classes that are specific to an underlying ML engine used to train and generate data. An example would be using `TensorFlowConfig` to create all the necessary parameters to train a model based on TF. `LocalConfig` is aliased to `TensorFlowConfig` for backwards compatability with older versions of the library. A model is saved to a designated directory, which can optionally be archived and utilized later.\n', '\n', '2. Tokenizers. Tokenizers convert input text into integer based IDs that are used by the underlying ML engine. These tokenizers can be created and sent to the training input. This is optional, and if no specific tokenizer is specified then a default one will be used. You can find [an example](https://github.com/gretelai/gretel-synthetics/blob/master/examples/tensorflow/batch-df-char-tokenizer.ipynb) here that uses a simple char-by-char tokenizer to build a model from an input CSV. When training in a non-differentially private mode, we suggest using the default `SentencePiece` tokenizer, an unsupervised tokenizer that learns subword units (e.g., **byte-pair-encoding (BPE)** [[Sennrich et al.](http://www.aclweb.org/anthology/P16-1162)]) and **unigram language model** [[Kudo.](https://arxiv.org/abs/1804.10959)]) for faster training and increased accuracy of the synthetic model.\n', '\n', '3. Training. Training a model combines the configuration and tokenizer and builds a model, which is stored in the designated directory, that can be used to generate new records.\n', '\n', '4. Generation. Once a model is trained, any number of new lines or records can be generated. Optionally, a record validator can be provided to ensure that the generated data meets any constraints that are necessary. See our notebooks for examples on validators.\n', '\n', '### Utilities\n', '\n', 'In addition to the four primary components, the `gretel-synthetics` package also ships with a set of utilities that are helpful for training advanced synthetics models and evaluating synthetic datasets.\n', '\n', 'Some of this functionality carries large dependencies, so they are shipped as an extra called `utils`. To install these dependencies, you may run\n', '\n', '```\n', 'pip install gretel-synthetics[utils]\n', '```\n', '\n', 'For additional details, please refer to the [Utility module API docs](https://synthetics.docs.gretel.ai/en/latest/utils/index.html).\n', '\n', '### Differential Privacy\n', '\n', 'Differential privacy support for our TensorFlow mode is built on the great work being done by the Google TF team and their [TensorFlow Privacy library](https://github.com/tensorflow/privacy).\n', '\n', 'When utilizing DP, we currently recommend using the character tokenizer as it will only create a vocabulary of single tokens and removes the risk of sensitive data being memorized as actual tokens that can be replayed during generation.\n', '\n', 'There are also a few configuration options that are notable such as:\n', '\n', '- `predict_batch_size` should be set to 1\n', '- `dp` should be enabled\n', '- `learning_rate`, `dp_noise_multiplier`, `dp_l2_norm_clip`, and `dp_microbatches` can be adjusted to achieve various epsilon values.\n', '- `reset_states` should be disabled\n', '\n', 'Please see our [example Notebook](https://github.com/gretelai/gretel-synthetics/blob/master/examples/tensorflow/diff_privacy.ipynb) for training a DP model based on the [Netflix Prize](https://en.wikipedia.org/wiki/Netflix_Prize) dataset.\n']"
Synthetic+Data,sdv-dev/SDGym,sdv-dev,https://api.github.com/repos/sdv-dev/SDGym,204,55,13,"['https://api.github.com/users/csala', 'https://api.github.com/users/katxiao', 'https://api.github.com/users/leix28', 'https://api.github.com/users/fealho', 'https://api.github.com/users/pvk-developer', 'https://api.github.com/users/ManuelAlvarezC', 'https://api.github.com/users/amontanez24', 'https://api.github.com/users/Elesa', 'https://api.github.com/users/tejuafonja', 'https://api.github.com/users/Baukebrenninkmeijer', 'https://api.github.com/users/JDTheRipperPC', 'https://api.github.com/users/k15z', 'https://api.github.com/users/sbrugman']",Python,2023-04-09T16:37:22Z,https://raw.githubusercontent.com/sdv-dev/SDGym/master/README.md,"['<div align=""center"">\n', '<br/>\n', '<p align=""center"">\n', '    <i>This repository is part of <a href=""https://sdv.dev"">The Synthetic Data Vault Project</a>, a project from <a href=""https://datacebo.com"">DataCebo</a>.</i>\n', '</p>\n', '\n', '[![Development Status](https://img.shields.io/badge/Development%20Status-2%20--%20Pre--Alpha-yellow)](https://pypi.org/search/?c=Development+Status+%3A%3A+2+-+Pre-Alpha)\n', '[![Travis](https://travis-ci.org/sdv-dev/SDGym.svg?branch=master)](https://travis-ci.org/sdv-dev/SDGym)\n', '[![PyPi Shield](https://img.shields.io/pypi/v/sdgym.svg)](https://pypi.python.org/pypi/sdgym)\n', '[![Downloads](https://pepy.tech/badge/sdgym)](https://pepy.tech/project/sdgym)\n', '[![Slack](https://img.shields.io/badge/Community-Slack-blue?style=plastic&logo=slack)](https://bit.ly/sdv-slack-invite)\n', '\n', '<div align=""left"">\n', '<br/>\n', '<p align=""center"">\n', '<a href=""https://github.com/sdv-dev/SDGym"">\n', '<img align=""center"" width=40% src=""https://github.com/sdv-dev/SDV/blob/master/docs/images/SDGym-DataCebo.png""></img>\n', '</a>\n', '</p>\n', '</div>\n', '\n', '</div>\n', '\n', '# Overview\n', '\n', 'The Synthetic Data Gym (SDGym) is a benchmarking framework for modeling and generating\n', 'synthetic data. Measure performance and memory usage across different synthetic data modeling\n', 'techniques – classical statistics, deep learning and more!\n', '\n', '<img align=""center"" src=""docs/images/SDGym_Results.png""></img>\n', '\n', 'The SDGym library integrates with the Synthetic Data Vault ecosystem. You can use any of its\n', 'synthesizers, datasets or metrics for benchmarking. You also customize the process to include\n', 'your own work.\n', '\n', '* **Datasets**: Select any of the publicly available datasets from the SDV project, or input your own data.\n', '* **Synthesizers**: Choose from any of the SDV synthesizers and baselines. Or write your own custom\n', 'machine learning model.\n', '* **Evaluation**: In addition to performance and memory usage, you can also measure synthetic data\n', 'quality and privacy through a variety of metrics\n', '\n', '# Install\n', '\n', 'Install SDGym using pip or conda. We recommend using a virtual environment to avoid conflicts with other software on your device.\n', '\n', '```bash\n', 'pip install sdgym\n', '```\n', '\n', '```bash\n', 'conda install -c pytorch -c conda-forge sdgym\n', '```\n', '\n', 'For more information about using SDGym, visit the [SDGym Documentation](https://docs.sdv.dev/sdgym).\n', '\n', '# Usage\n', '\n', ""Let's benchmark synthetic data generation for single tables. First, let's define which modeling\n"", ""techniques we want to use. Let's choose a few synthesizers from the SDV library and a few others\n"", 'to use as baselines.\n', '\n', '```python\n', '# these synthesizers come from the SDV library\n', '# each one uses different modeling techniques\n', ""sdv_synthesizers = ['GaussianCopulaSynthesizer', 'CTGANSynthesizer']\n"", '\n', '# these basic synthesizers are available in SDGym\n', '# as baselines\n', ""baseline_synthesizers = ['UniformSynthesizer']\n"", '```\n', '\n', 'Now, we can benchmark the different techniques:\n', '```python\n', 'import sdgym\n', '\n', 'sdgym.benchmark_single_table(\n', '    synthesizers=(sdv_synthesizers + baseline_synthesizers)\n', ')\n', '```\n', '\n', 'The result is a detailed performance, memory and quality evaluation across the synthesizers\n', 'on a variety of publicly available datasets.\n', '\n', '## Supplying a custom synthesizer\n', '\n', 'Benchmark your own synthetic data generation techniques. Define your synthesizer by\n', 'specifying the training logic (using machine learning) and the sampling logic.\n', '\n', '```python\n', 'def my_training_logic(data, metadata):\n', '    # create an object to represent your synthesizer\n', '    # train it using the data\n', '    return synthesizer\n', '\n', 'def my_sampling_logic(trained_synthesizer, num_rows):\n', '    # use the trained synthesizer to create\n', '    # num_rows of synthetic data\n', '    return synthetic_data\n', '```\n', '\n', 'Learn more in the [Custom Synthesizers Guide](https://docs.sdv.dev/sdgym/customization/synthesizers/custom-synthesizers).\n', '\n', '## Customizing your datasets\n', '\n', 'The SDGym library includes many publicly available datasets that you can include right away.\n', 'List these using the ``get_available_datasets`` feature.\n', '\n', '```python\n', 'sdgym.get_available_datasets()\n', '```\n', '\n', '```\n', 'dataset_name   size_MB     num_tables\n', 'KRK_v1         0.072128    1\n', 'adult          3.907448    1\n', 'alarm          4.520128    1\n', 'asia           1.280128    1\n', '...\n', '```\n', '\n', 'You can also include any custom, private datasets that are stored on your computer on an\n', 'Amazon S3 bucket.\n', '\n', '```\n', ""my_datasets_folder = 's3://my-datasets-bucket'\n"", '```\n', '\n', 'For more information, see the docs for [Customized Datasets](https://docs.sdv.dev/sdgym/customization/datasets).\n', '\n', ""# What's next?\n"", '\n', 'Visit the [SDGym Documentation](https://docs.sdv.dev/sdgym) to learn more!\n', '\n', '---\n', '\n', '\n', '<div align=""center"">\n', '<a href=""https://datacebo.com""><img align=""center"" width=40% src=""https://github.com/sdv-dev/SDV/blob/master/docs/images/DataCebo.png""></img></a>\n', '</div>\n', '<br/>\n', '<br/>\n', '\n', ""[The Synthetic Data Vault Project](https://sdv.dev) was first created at MIT's [Data to AI Lab](\n"", 'https://dai.lids.mit.edu/) in 2016. After 4 years of research and traction with enterprise, we\n', 'created [DataCebo](https://datacebo.com) in 2020 with the goal of growing the project.\n', 'Today, DataCebo is the proud developer of SDV, the largest ecosystem for\n', 'synthetic data generation & evaluation. It is home to multiple libraries that support synthetic\n', 'data, including:\n', '\n', '* 🔄 Data discovery & transformation. Reverse the transforms to reproduce realistic data.\n', '* 🧠 Multiple machine learning models -- ranging from Copulas to Deep Learning -- to create tabular,\n', '  multi table and time series data.\n', '* 📊 Measuring quality and privacy of synthetic data, and comparing different synthetic data\n', '  generation models.\n', '\n', '[Get started using the SDV package](https://sdv.dev/SDV/getting_started/install.html) -- a fully\n', 'integrated solution and your one-stop shop for synthetic data. Or, use the standalone libraries\n', 'for specific needs.\n']"
Synthetic+Data,ankush-me/SynthText,ankush-me,https://api.github.com/repos/ankush-me/SynthText,1877,608,3,"['https://api.github.com/users/ankush-me', 'https://api.github.com/users/carandraug', 'https://api.github.com/users/codeVerySlow']",Python,2023-04-05T14:11:34Z,https://raw.githubusercontent.com/ankush-me/SynthText/master/README.md,"['# SynthText\n', 'Code for generating synthetic text images as described in [""Synthetic Data for Text Localisation in Natural Images"", Ankush Gupta, Andrea Vedaldi, Andrew Zisserman, CVPR 2016](https://www.robots.ox.ac.uk/~vgg/data/scenetext/).\n', '\n', '\n', '**Synthetic Scene-Text Image Samples**\n', '![Synthetic Scene-Text Samples](samples.png ""Synthetic Samples"")\n', '\n', 'The code in the `master` branch is for Python2. Python3 is supported in the `python3` branch.\n', '\n', 'The main dependencies are:\n', '\n', '```\n', 'pygame==2.0.0, opencv (cv2), PIL (Image), numpy, matplotlib, h5py, scipy\n', '```\n', '\n', '### Generating samples\n', '\n', '```\n', 'python gen.py --viz [--datadir <path-to-dowloaded-renderer-data>]\n', '```\n', 'where, `--datadir` points to the `renderer_data` directory included in the\n', '[data torrent](https://academictorrents.com/details/2dba9518166cbd141534cbf381aa3e99a087e83c).\n', 'Specifying this `datadir` is optional, and if not specified, the script will\n', 'automatically download and extract the same `renderer.tar.gz` data file (~24 M).\n', 'This data file includes:\n', '\n', '  - **sample.h5**: This is a sample h5 file which contains a set of 5 images along with their depth and segmentation information. Note, this is just given as an example; you are encouraged to add more images (along with their depth and segmentation information) to this database for your own use.\n', '  - **fonts**: three sample fonts (add more fonts to this folder and then update `fonts/fontlist.txt` with their paths).\n', '  - **newsgroup**: Text-source (from the News Group dataset). This can be subsituted with any text file. Look inside `text_utils.py` to see how the text inside this file is used by the renderer.\n', '  - **models/colors_new.cp**: Color-model (foreground/background text color model), learnt from the IIIT-5K word dataset.\n', '  - **models**: Other cPickle files (**char\\_freq.cp**: frequency of each character in the text dataset; **font\\_px2pt.cp**: conversion from pt to px for various fonts: If you add a new font, make sure that the corresponding model is present in this file, if not you can add it by adapting `invert_font_size.py`).\n', '\n', 'This script will generate random scene-text image samples and store them in an h5 file in `results/SynthText.h5`. If the `--viz` option is specified, the generated output will be visualized as the script is being run; omit the `--viz` option to turn-off the visualizations. If you want to visualize the results stored in  `results/SynthText.h5` later, run:\n', '\n', '```\n', 'python visualize_results.py\n', '```\n', '### Pre-generated Dataset\n', 'A dataset with approximately 800000 synthetic scene-text images generated with this code can be found [here](https://www.robots.ox.ac.uk/~vgg/data/scenetext/).\n', '\n', '### Adding New Images\n', 'Segmentation and depth-maps are required to use new images as background. Sample scripts for obtaining these are available [here](https://github.com/ankush-me/SynthText/tree/master/prep_scripts).\n', '\n', '* `predict_depth.m` MATLAB script to regress a depth mask for a given RGB image; uses the network of [Liu etal.](https://bitbucket.org/fayao/dcnf-fcsp/) However, more recent works (e.g., [this](https://github.com/iro-cp/FCRN-DepthPrediction)) might give better results.\n', '* `run_ucm.m` and `floodFill.py` for getting segmentation masks using [gPb-UCM](https://github.com/jponttuset/mcg).\n', '\n', 'For an explanation of the fields in `sample.h5` (e.g.: `seg`,`area`,`label`), please check this [comment](https://github.com/ankush-me/SynthText/issues/5#issuecomment-274490044).\n', '\n', '### Pre-processed Background Images\n', '\n', 'The 8,000 background images used in the paper, along with their\n', 'segmentation and depth masks, are included in the [same\n', 'torrent](https://academictorrents.com/details/2dba9518166cbd141534cbf381aa3e99a087e83c)\n', 'as the pre-generated dataset under the `bg_data` directory.  The files are:\n', '\n', '|    filenames    |                      description                     |\n', '|:--------------- |:---------------------------------------------------- |\n', '| `imnames.cp`    | names of images which do not contain background text |\n', '| `bg_img.tar.gz` | images (filter these using `imnames.cp`)             |\n', '| `depth.h5`      | depth maps                                           |\n', '| `seg.h5`        | segmentation maps                                    |\n', '\n', '#### Downloading without BitTorrent\n', '\n', 'Downloading with BitTorrent is strongly recommended.  If that is not\n', 'possible, the files are also available to download over http from\n', '`https://thor.robots.ox.ac.uk/~vgg/data/scenetext/preproc/<filename>`,\n', 'where, `<filename>` can be:\n', '\n', '|    filenames    | size |             md5 hash             |\n', '|:--------------- | ----:|:-------------------------------- |\n', '| `imnames.cp`    | 180K |                                  |\n', '| `bg_img.tar.gz` | 8.9G | 3eac26af5f731792c9d95838a23b5047 |\n', '| `depth.h5`      |  15G | af97f6e6c9651af4efb7b1ff12a5dc1b |\n', '| `seg.h5`        | 6.9G | 1605f6e629b2524a3902a5ea729e86b2 |\n', '\n', 'Note: due to large size, `depth.h5` is also available for download as 3-part split-files of 5G each.\n', 'These part files are named: `depth.h5-00, depth.h5-01, depth.h5-02`. Download using the path above, and put them together using `cat depth.h5-0* > depth.h5`.\n', 'To download, use the something like the following:\n', '```\n', 'wget --continue https://thor.robots.ox.ac.uk/~vgg/data/scenetext/preproc/<filename>\n', '```\n', '[`use_preproc_bg.py`](https://github.com/ankush-me/SynthText/blob/master/use_preproc_bg.py) provides sample code for reading this data.\n', '\n', 'Note: I do not own the copyright to these images.\n', '\n', '### Generating Samples with Text in non-Latin (English) Scripts\n', '- @JarveeLee has modified the pipeline for generating samples with Chinese text [here](https://github.com/JarveeLee/SynthText_Chinese_version).\n', '- @adavoudi has modified it for arabic/persian script, which flows from right-to-left [here](https://github.com/adavoudi/SynthText).\n', '- @MichalBusta has adapted it for a number of languages (e.g. Bangla, Arabic, Chinese, Japanese, Korean) [here](https://github.com/MichalBusta/E2E-MLT).\n', '- @gachiemchiep has adapted for Japanese [here](https://github.com/gachiemchiep/SynthText).\n', '- @gungui98 has adapted for Vietnamese [here](https://github.com/gungui98/SynthText).\n', '- @youngkyung has adapted for Korean [here](https://github.com/youngkyung/SynthText_kr).\n', '- @kotomiDu has developed an interactive UI for generating images with text [here](https://github.com/kotomiDu/GameSynthText).\n', '- @LaJoKoch has adapted for German [here](https://github.com/LaJoKoch/SynthTextGerman).\n', '\n', '### Further Information\n', 'Please refer to the paper for more information, or contact me (email address in the paper).\n']"
Synthetic+Data,tirthajyoti/Synthetic-data-gen,tirthajyoti,https://api.github.com/repos/tirthajyoti/Synthetic-data-gen,68,37,1,['https://api.github.com/users/tirthajyoti'],Python,2022-11-08T22:55:34Z,https://raw.githubusercontent.com/tirthajyoti/Synthetic-data-gen/master/README.md,"['# Synthetic-data-gen\n', 'Various methods for generating synthetic data for data science and ML.\n', '\n', 'Read my article on Medium **""[Synthetic data generation — a must-have skill for new data scientists](https://towardsdatascience.com/synthetic-data-generation-a-must-have-skill-for-new-data-scientists-915896c0c1ae)""**\n', '\n', 'Also, a related article on generating random variables from scratch: **""[How to generate random variables from scratch (no library used)](https://towardsdatascience.com/how-to-generate-random-variables-from-scratch-no-library-used-4b71eb3c8dc7)""**\n', '\n', '---\n', '## Notebooks\n', '\n', '* [Scikit-learn data generation (regression/classification/clustering) methods](https://github.com/tirthajyoti/Synthetic-data-gen/blob/master/Notebooks/Scikit-learn-data-generation.ipynb)\n', '* [Random regression and classification problem generation from symbolic expressions (using `SymPy`)](https://github.com/tirthajyoti/Synthetic-data-gen/blob/master/Notebooks/Symbolic%20regression%20classification%20generator.ipynb)\n', '* [Synthesizing time series](https://github.com/tirthajyoti/Synthetic-data-gen/blob/master/Notebooks/Synth_Time_series.ipynb)\n', '* [Generating Gaussian mixture model data](https://github.com/tirthajyoti/Synthetic-data-gen/blob/master/Notebooks/GMM_generator.ipynb)\n', '\n', '## Why do you need the skill of synthetic data generation?\n', '\n', 'Imagine you are tinkering with a cool machine learning algorithm like SVM or a deep neural net. What kind of dataset you should practice them on? If you are learning from scratch, the advice is to start with simple, small-scale datasets which you can plot in two dimensions to understand the patterns visually and see for yourself the working of the ML algorithm in an intuitive fashion. For example, [here is an excellent article](https://www.analyticsvidhya.com/blog/2018/05/24-ultimate-data-science-projects-to-boost-your-knowledge-and-skills/) on various datasets you can try at various level of learning.\n', '\n', 'This is a great start. But it is not all.\n', '\n', 'Sure, you can go up a level and find yourself a real-life large dataset to practice the algorithm on. But that is still a fixed dataset, with a fixed number of samples, a fixed pattern, and a fixed degree of class separation between positive and negative samples (if we assume it to be a classification problem). Are you learning all the intricacies of the algorithm in terms of\n', '- sample complexity,\n', '- computational efficiency,\n', '- ability to handle class imbalance,\n', '- robustness of the metrics in the face of varying degree of class separation\n', '- bias-variance trade-off as a function of data complexity\n', '\n', 'Probably not. **Perhaps, no single dataset can lend all these deep insights for a given ML algorithm**. But, these are extremely important insights to master for you to become a true expert practitioner of machine learning. So, you will need an **extremely rich and sufficiently large dataset, which is amenable enough for all these experimentation**.\n', '\n', 'So, what can you do in this situation? Scour the internet for more datasets and just hope that some of them will bring out the limitations and challenges, associated with a particular algorithm, and help you learn?\n', '\n', 'Yes, it is a possible approach but may not be the most viable or optimal one in terms of time and effort. Good datasets may not be clean or easily obtainable. You may spend much more time looking for, extracting, and wrangling with a suitable dataset than putting that effort to understand the ML algorithm.\n', '\n', 'Make no mistake. **The experience of searching for a real life dataset, extracting it, running exploratory data analysis, and wrangling with it to make it suitably prepared for a machine learning based modeling is invaluable**. I know because I wrote a book about it :-)\n', '\n', 'But that can be taught and practiced separately. In many situations, however, **you may just want to have access to a flexible dataset (or several of them) to ‘teach’ you the ML algorithm in all its gory details**.\n', '\n', 'Surprisingly enough, in many cases, such teaching can be done with **synthetic datasets**.\n', '\n', '## What is a synthetic dataset?\n', 'As the name suggests, quite obviously, a synthetic dataset is a repository of data that is generated programmatically. So, it is not collected by any real-life survey or experiment. Its main purpose, therefore, is **to be flexible and rich enough to help an ML practitioner conduct fascinating experiments with various classification, regression, and clustering algorithms**. Desired properties are,\n', '\n', '* It can be numerical, binary, or categorical (ordinal or non-ordinal),\n', '* The number of features and length of the dataset should be arbitrary\n', '* It should preferably be random and the user should be able to choose a wide variety of statistical distribution to base this data upon i.e. the underlying random process can be precisely controlled and tuned,\n', '* If it is used for classification algorithms, then the degree of class separation should be controllable to make the learning problem easy or hard,\n', '* Random noise can be interjected in a controllable manner\n', '* For a regression problem, a complex, non-linear generative process can be used for sourcing the data\n']"
Synthetic+Data,stefan-jansen/synthetic-data-for-finance,stefan-jansen,https://api.github.com/repos/stefan-jansen/synthetic-data-for-finance,79,29,1,['https://api.github.com/users/stefan-jansen'],Python,2023-04-05T12:46:11Z,https://raw.githubusercontent.com/stefan-jansen/synthetic-data-for-finance/main/README.md,"['# Generative Adversarial Nets for Synthetic Time Series Data\n', '\n', 'This repo shows how to create synthetic time-series data using generative adversarial networks (GAN). GANs train a generator and a discriminator network in a competitive setting so that the generator learns to produce samples that the discriminator cannot distinguish from a given class of training data. The goal is to yield a generative model capable of producing synthetic samples representative of this class.\n', 'While most popular with image data, GANs have also been used to generate synthetic time-series data in the medical domain. Subsequent experiments with financial data explored whether GANs can produce alternative price trajectories useful for ML training or strategy backtests. \n', '\n', 'We replicate the 2019 NeurIPS [Time-Series GAN](https://proceedings.neurips.cc/paper/2019/file/c9efe5f26cd17ba6216bbe2a7d26d490-Paper.pdf) paper by Jinsung Yoon, et al., to illustrate the approach and demonstrate the results. The material is based on the 2<sup>nd</sup> edition of my book on [Machine Learning for Trading]((https://www.amazon.com/Machine-Learning-Algorithmic-Trading-alternative/dp/1839217715?pf_rd_r=GZH2XZ35GB3BET09PCCA&pf_rd_p=c5b6893a-24f2-4a59-9d4b-aff5065c90ec&pd_rd_r=91a679c7-f069-4a6e-bdbb-a2b3f548f0c8&pd_rd_w=2B0Q0&pd_rd_wg=GMY5S&ref_=pd_gw_ci_mcx_mr_hp_d)) (see [GitHub repo](https://github.com/stefan-jansen/machine-learning-for-trading)).  \n', '\n', '<p align=""center"">\n', '<img src=""https://i.imgur.com/W1Rp89K.png"" width=""60%"">\n', '</p>\n', '\n', '## Content\n', '\n', '1. [Generative adversarial networks for synthetic data](#generative-adversarial-networks-for-synthetic-data)\n', '    * [Comparing generative and discriminative models](#comparing-generative-and-discriminative-models)\n', '    * [Adversarial training: a zero-sum game of trickery](#adversarial-training-a-zero-sum-game-of-trickery)\n', '2. [Code example: TimeGAN: Adversarial Training for Synthetic Financial Data](#code-example-timegan-adversarial-training-for-synthetic-financial-data)\n', '    * [Learning the data generation process across features and time](#learning-the-data-generation-process-across-features-and-time)\n', '    * [Combining adversarial and supervised training with time-series embedding](#combining-adversarial-and-supervised-training-with-time-series-embedding)\n', '    * [The four components of the TimeGAN architecture](#the-four-components-of-the-timegan-architecture)\n', '    * [Implementing TimeGAN using TensorFlow 2](#implementing-timegan-using-tensorflow-2)\n', '    * [Evaluating the quality of synthetic time-series data](#evaluating-the-quality-of-synthetic-time-series-data)\n', '3. [Resources](#resources)\n', ""    * [How GAN's work](#how-gans-work)\n"", '    * [Implementation](#implementation)\n', '    * [The rapid evolution of the GAN architecture zoo](#the-rapid-evolution-of-the-gan-architecture-zoo)\n', '    * [Applications](#applications)\n', '\n', '## Generative adversarial networks for synthetic data\n', '\n', 'The [book](https://www.amazon.com/Machine-Learning-Algorithmic-Trading-alternative/dp/1839217715?pf_rd_r=GZH2XZ35GB3BET09PCCA&pf_rd_p=c5b6893a-24f2-4a59-9d4b-aff5065c90ec&pd_rd_r=91a679c7-f069-4a6e-bdbb-a2b3f548f0c8&pd_rd_w=2B0Q0&pd_rd_wg=GMY5S&ref_=pd_gw_ci_mcx_mr_hp_d) mostly focuses on supervised learning algorithms that receive input data and predict an outcome, which we can compare to the ground truth to evaluate their performance. Such algorithms are also called discriminative models because they learn to differentiate between different output values.\n', 'Generative adversarial networks (GANs) are an instance of generative models like the variational autoencoder covered in [Chapter 20](https://github.com/stefan-jansen/machine-learning-for-trading/tree/master/20_autoencoders_for_conditional_risk_factors).\n', '\n', '### Comparing generative and discriminative models\n', '\n', 'Discriminative models learn how to differentiate among outcomes y, given input data X. In other words, they learn the probability of the outcome given the data: p(y | X). Generative models, on the other hand, learn the joint distribution of inputs and outcome p(y, X). \n', '\n', 'While generative models can be used as discriminative models using Bayes Rule to compute which class is most likely (see [Chapter 10](https://github.com/stefan-jansen/machine-learning-for-trading/tree/master/10_bayesian_machine_learning)), it appears often preferable to solve the prediction problem directly rather than by solving the more general generative challenge first.\n', '\n', '### Adversarial training: a zero-sum game of trickery\n', '\n', 'The key innovation of GANs is a new way of learning the data-generating probability distribution. The algorithm sets up a competitive, or adversarial game between two neural networks called the generator and the discriminator.\n', '\n', '<p align=""center"">\n', '<img src=""https://i.imgur.com/0vuUsY0.png"" width=""80%"">\n', '</p>\n', '\n', '## Code example: How to build a GAN using TensorFlow 2\n', '\n', 'To illustrate the implementation of a generative adversarial network using Python, we use the deep convolutional GAN (DCGAN) example discussed earlier in this section to synthesize images from the fashion MNIST dataset that we first encountered in Chapter 13. \n', '\n', 'The notebook [deep_convolutional_generative_adversarial_network](https://github.com/stefan-jansen/machine-learning-for-trading/blob/master/21_gans_for_synthetic_time_series/01_deep_convolutional_generative_adversarial_network.ipynb) illustrates the implementation of a GAN using Python. It uses the Deep Convolutional GAN (DCGAN) example to synthesize images from the fashion MNIST dataset\n', '\n', '## Code example: TimeGAN: Adversarial Training for Synthetic Financial Data\n', '\n', 'Generating synthetic time-series data poses specific challenges above and beyond those encountered when designing GANs for images. \n', 'In addition to the distribution over variables at any given point, such as pixel values or the prices of numerous stocks, a generative model for time-series data should also learn the temporal dynamics that shapes how one sequence of observations follows another (see also discussion in Chapter 9: [Time Series Models for Volatility Forecasts and Statistical Arbitrage](../09_time_series_models)).\n', '\n', 'Very recent and promising research by Yoon, Jarrett, and van der Schaar, presented at NeurIPS in December 2019, introduces a novel [Time-Series Generative Adversarial Network](https://papers.nips.cc/paper/8789-time-series-generative-adversarial-networks.pdf) (TimeGAN) framework that aims to account for temporal correlations by combining supervised and unsupervised training. \n', 'The model learns a time-series embedding space while optimizing both supervised and adversarial objectives that encourage it to adhere to the dynamics observed while sampling from historical data during training. \n', 'The authors test the model on various time series, including historical stock prices, and find that the quality of the synthetic data significantly outperforms that of available alternatives.\n', '\n', '### Learning the data generation process across features and time\n', '\n', 'A successful generative model for time-series data needs to capture both the cross-sectional distribution of features at each point in time and the longitudinal relationships among these features over time. \n', 'Expressed in the image context we just discussed, the model needs to learn not only what a realistic image looks like, but also how one image evolves from the next as in a video.\n', '\n', '### Combining adversarial and supervised training with time-series embedding\n', '\n', 'Prior attempts at generating time-series data like the recurrent (conditional) GAN relied on recurrent neural networks (RNN, see Chapter 19, [RNN for Multivariate Time Series and Sentiment Analysis](../19_recurrent_neural_nets)) in the roles of generator and discriminator. \n', '\n', 'TimeGAN explicitly incorporates the autoregressive nature of time series by combining the unsupervised adversarial loss on both real and synthetic sequences familiar from the DCGAN example with a stepwise supervised loss with respect to the original data. \n', 'The goal is to reward the model for learning the distribution over transitions from one point in time to the next present in the historical data.\n', '\n', '### The four components of the TimeGAN architecture\n', '\n', 'The TimeGAN architecture combines an adversarial network with an autoencoder and has thus four network components as depicted in Figure 21.4:\n', 'Autoencoder: embedding and recovery networks\n', 'Adversarial Network: sequence generator and sequence discriminator components\n', '<p align=""center"">\n', '<img src=""https://i.imgur.com/WqoXbr8.png"" width=""80%"">\n', '</p>\n', '\n', '### Implementing TimeGAN using TensorFlow 2\n', '\n', 'In this section, we implement the TimeGAN architecture just described. The authors provide sample code using TensorFlow 1 that we port to TensorFlow 2. Building and training TimeGAN requires several steps:\n', '1. Selecting and preparing real and random time series inputs\n', '2. Creating the key TimeGAN model components\n', '3. Defining the various loss functions and train steps used during the three training phases\n', '4. Running the training loops and logging the results\n', '5. Generating synthetic time series and evaluating the results\n', '\n', 'The notebook [TimeGAN_TF2](02_TimeGAN_TF2.ipynb) shows how to implement these steps.\n', '\n', '### Installation\n', '\n', 'Using a GPU is recommended to speed up training. There are several options to run the notebook:\n', '1) Use a [Docker](https://docs.docker.com/get-started/overview/) image provided by TensorFlow with either CPU or GPU support. See [instructions](https://www.tensorflow.org/install/docker). \n', ""    - To start the container configured with TensorFlow and mount the project directory in the `/home` directory, run the following command in this repo's root folder on your machine:\n"", '        - With GPU support (using [nvidia-docker](https://github.com/NVIDIA/nvidia-docker) as describe in the linked [instructions](https://www.tensorflow.org/install/docker)):\n', '            ```bash\n', '            docker run --gpus all -it -v $(pwd):/home -p 8888:8888 --name ml4t tensorflow/tensorflow:latest-gpu-jupyter bash\n', '          ```\n', '      - With CPU support:\n', '          ```bash\n', '          docker run -it -v $(pwd):/home -p 8888:8888 --name ml4t tensorflow/tensorflow:latest-gpu-jupyter bash\n', '          ```\n', '    - Change into the `/home` folder of your container using `cd /home`\n', '    - Run the install script to get some requisite packages: `./install.sh`\n', '    - Then, launch the jupyter server to work with the notebooks as usual:\n', '        ```bash\n', '        jupyter notebook --ip 0.0.0.0 --no-browser --allow-root\n', '        ```\n', '2) Create a virtual environment using the `requirements.txt` file (Ubuntu only; other OS requires modifying the content).\n', '\n', '### Evaluating the quality of synthetic time-series data\n', '\n', 'The TimeGAN authors assess the quality of the generated data with respect to three practical criteria:\n', '1. **Diversity**: the distribution of the synthetic samples should roughly match that of the real data\n', '2. **Fidelity**: the sample series should be indistinguishable from the real data, and \n', '3. **Usefulness**: the synthetic data should be as useful as their real counterparts for solving a predictive task\n', '\n', 'The authors apply three methods to evaluate whether the synthetic data actually exhibits these characteristics:\n', '1. **Visualization**: for a qualitative diversity assessment of diversity, we use dimensionality reduction (principal components analysis (PCA) and t-SNE, see Chapter 13) to visually inspect how closely the distribution of the synthetic samples resembles that of the original data\n', '2. **Discriminative Score**: for a quantitative assessment of fidelity, the test error of a time-series classifier such as a 2-layer LSTM (see Chapter 18) let’s us evaluate whether real and synthetic time series can be differentiated or are, in fact, indistinguishable.\n', '3. **Predictive Score**: for a quantitative measure of usefulness, we can compare the test errors of a sequence prediction model trained on, alternatively, real or synthetic data to predict the next time step for the real data.\n', '\n', 'The notebook [evaluating_synthetic_data](03_evaluating_synthetic_data.ipynb) contains the relevant code samples.\n', '\n', '## Resources\n', '\n', ""### How GAN's work\n"", '\n', '- [NIPS 2016 Tutorial: Generative Adversarial Networks](https://arxiv.org/pdf/1701.00160.pdf), Ian Goodfellow, 2017\n', '- [Why is unsupervised learning important?](https://www.quora.com/Why-is-unsupervised-learning-important), Yoshua Bengio on Quora, 2018\n', '- [GAN Lab: Understanding Complex Deep Generative Models using Interactive Visual Experimentation](https://www.groundai.com/project/gan-lab-understanding-complex-deep-generative-models-using-interactive-visual-experimentation/), Minsuk Kahng, Nikhil Thorat, Duen Horng (Polo) Chau, Fernanda B. Viégas, and Martin Wattenberg, IEEE Transactions on Visualization and Computer Graphics, 25(1) (VAST 2018), Jan. 2019\n', '    - [GitHub](https://poloclub.github.io/ganlab/)\n', '- [Generative Adversarial Networks](https://arxiv.org/abs/1406.2661), Ian Goodfellow, et al, 2014\n', '- [Generative Adversarial Networks: an Overview](https://arxiv.org/pdf/1710.07035.pdf), Antonia Creswell, et al, 2017\n', '- [Generative Models](https://blog.openai.com/generative-models/), OpenAI Blog\n', '\n', '### Implementation\n', '\n', '- [Deep Convolutional Generative Adversarial Network](https://www.tensorflow.org/tutorials/generative/dcgan)\n', '- [CycleGAN](https://www.tensorflow.org/tutorials/generative/cyclegan)\n', '- [Keras-GAN](https://github.com/eriklindernoren/Keras-GAN), numerous Keras GAN implementations\n', '- [PyTorch-GAN](https://github.com/eriklindernoren/PyTorch-GAN), numerous PyTorch GAN implementations\n', '\n', '\n', '### The rapid evolution of the GAN architecture zoo\n', '\n', '- [Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks (DCGAN)](https://arxiv.org/pdf/1511.06434.pdf), Luke Metz et al, 2016\n', '- [Conditional Generative Adversarial Net](https://arxiv.org/pdf/1411.1784.pdf), Medhi Mirza and Simon Osindero, 2014\n', '- [Infogan: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets](https://arxiv.org/pdf/1606.03657.pdf), Xi Chen et al, 2016\n', '- [Stackgan: Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Networks](https://arxiv.org/pdf/1612.03242.pdf), Shaoting Zhang et al, 2016\n', '- [Photo-realistic Single Image Super-resolution Using a Generative Adversarial Network](https://arxiv.org/pdf/1609.04802.pdf), Alejando Acosta et al, 2016\n', '- [Unpaired Image-to-image Translation Using Cycle-consistent Adversarial Networks](https://arxiv.org/pdf/1703.10593.pdf), Juan-Yan Zhu et al, 2018\n', '- [Learning What and Where to Draw](https://arxiv.org/abs/1610.02454), Scott Reed, et al 2016\n', '- [Fantastic GANs and where to find them](http://guimperarnau.com/blog/2017/03/Fantastic-GANs-and-where-to-find-them)\n', '\n', '### Applications\n', '\n', '- [Real-valued (Medical) Time Series Generation with Recurrent Conditional GANs](https://arxiv.org/abs/1706.02633), Cristóbal Esteban, Stephanie L. Hyland, Gunnar Rätsch, 2016\n', '    - [GitHub Repo](https://github.com/ratschlab/RGAN)\n', '- [MAD-GAN: Multivariate Anomaly Detection for Time Series Data with Generative Adversarial Networks](https://arxiv.org/pdf/1901.04997.pdf), Dan Li, Dacheng Chen, Jonathan Goh, and See-Kiong Ng, 2019\n', '    - [GitHub Repo](https://github.com/LiDan456/MAD-GANs)\n', '- [GAN\u200a—\u200aSome cool applications](https://medium.com/@jonathan_hui/gan-some-cool-applications-of-gans-4c9ecca35900), Jonathan Hui, 2018\n', '- [gans-awesome-applications](https://github.com/nashory/gans-awesome-applications), curated list of awesome GAN applications\n', '\n', '\n', '\n']"
Synthetic+Data,microsoft/synthetic-data-showcase,microsoft,https://api.github.com/repos/microsoft/synthetic-data-showcase,76,25,8,"['https://api.github.com/users/rracanicci', 'https://api.github.com/users/dworthen', 'https://api.github.com/users/natoverse', 'https://api.github.com/users/darrenedge', 'https://api.github.com/users/katua', 'https://api.github.com/users/andresmor-ms', 'https://api.github.com/users/microsoftopensource', 'https://api.github.com/users/microsoft-github-operations%5Bbot%5D']",Rust,2023-04-09T06:50:54Z,https://raw.githubusercontent.com/microsoft/synthetic-data-showcase/main/README.md,"['[![Rust CI](https://github.com/microsoft/synthetic-data-showcase/actions/workflows/rust-ci.yml/badge.svg?branch=main&event=push)](https://github.com/microsoft/synthetic-data-showcase/actions/workflows/rust-ci.yml)\n', '[![Javascript CI](https://github.com/microsoft/synthetic-data-showcase/actions/workflows/javascript-ci.yml/badge.svg?branch=main&event=push)](https://github.com/microsoft/synthetic-data-showcase/actions/workflows/javascript-ci.yml)\n', '[![Python CI](https://github.com/microsoft/synthetic-data-showcase/actions/workflows/python-ci.yml/badge.svg?branch=main&event=push)](https://github.com/microsoft/synthetic-data-showcase/actions/workflows/python-ci.yml)\n', '\n', '# Synthetic data showcase\n', '\n', '> Generates synthetic data and user interfaces for privacy-preserving data sharing and analysis.\n', '\n', '> Free-to-use web application for private data release: https://microsoft.github.io/synthetic-data-showcase/\n', '\n', '# Overview\n', '\n', 'In many cases, the best way to share sensitive datasets is not to share the actual sensitive datasets, but user interfaces to derived datasets that are inherently anonymous. Our name for such an interface is a _data showcase_. In this project, we provide an automated set of tools for generating the three elements of a _synthetic data showcase_:\n', '\n', '1. _Synthetic data_ representing the overall structure and statistics of the input data, without describing actual identifiable individuals.\n', '2. _Aggregate data_ reporting the number of individuals with different combinations of attributes, without disclosing exact counts.\n', '3. _Data dashboards_ enabling exploratory visual analysis of both datasets, without the need for custom data science or interface development.\n', '\n', 'To generate these elements, our tool provides two approaches to create anonymous datasets that are safe to release: (i) differential privacy and (ii) k-anonymity.\n', '\n', '# Differential privacy\n', '\n', '## Privacy guarantees\n', '\n', 'The paradigm of differential privacy (DP) offers ""safety in noise"" &ndash; just enough calibrated noise is added to the data to control the maximum possible privacy loss, $\\varepsilon$ (epsilon). When applied in the context of private data release, $\\varepsilon$ bounds the ratio of probabilities of getting an arbitrary result to an arbitrary computation when using two synthetic datasets &ndash; one generated from the sensitive dataset itself and the other from a neighboring dataset missing a single arbitrary record.\n', '\n', 'Our approach to synthesizing data with differential privacy first protects attribute combination counts in the aggregate data using our [DP Marginals](./docs/dp/dp_marginals.pdf) algorithm and then uses the resulting DP aggregate counts to derive synthetic records that retain differential privacy under the post-processing property.\n', '\n', '> For a detailed explanation of how SDS uses differential privacy, please check our [DP documentation](./docs/dp/README.md).\n', '\n', '## Usage\n', '\n', 'Use of our differential privacy synthesizer is recommended for **repeated data releases** where cumulative privacy loss must be quantified and controlled and where provable guarantees against all possible privacy attacks are desired.\n', '\n', 'Any differentially-private dataset should be evaluated for potential risks in situations where missing, fabricated, or inaccurate counts of attribute combinations could trigger inappropriate downstream decisions or actions. Our DP synthesizer prioritises the release of accurate combination counts (with minimal noise) of actual combinations (with minimal fabrication).\n', '\n', '# K-anonymity\n', '\n', '## Privacy guarantees\n', '\n', 'The paradigm of k-anonymity offers ""safety in numbers"" &ndash; combinations of attributes are only released when they occur at least k times in the sensitive dataset. When applied in the context of private data release, we interpret k as a privacy resolution determining the minimum group size that will be (a) reported explicitly in the aggregate dataset and (b) represented implicitly by the records of the synthetic dataset. This makes it possible to offer privacy guarantees in clearly understandable terms, e.g.:\n', '\n', '""All attribute combinations in this synthetic dataset describe groups of 10 or more individuals in the original sensitive dataset, therefore may never be used to infer the presence of individuals or groups smaller than 10.""\n', '\n', 'Our approach to synthesizing data with k-anonymity overcomes many of the limitations of standard [k-anonymization](https://en.wikipedia.org/wiki/K-anonymity), in which attributes of sensitive data records are generalized and suppressed until k-anonymity is reached, and only for those attributes determined in advance to be potentially identifying when used in combination (so-called quasi-identifiers). In this standard approach, all remaining sensitive attributes are released so long as k-anonymity holds for the designated quasi-identifiers. This makes the records (and thus subjects) of k-anonymized datasets susceptible to linking attacks based on auxiliary data or background knowledge.\n', '\n', 'In contrast, our k-anonymity synthesizers generate synthetic records that do not represent actual individuals, yet are composed exclusively from common combinations of attributes in the sensitive dataset. The k-anonymity guarantee therefore holds for all data columns and all combinations of attributes.\n', '\n', '## Usage\n', '\n', 'Use of our k-anonymity synthesizers is recommended only for **one-off data releases** where there is a need for precise counts of attribute combinations (at a given privacy resolution).\n', '\n', 'These synthesizers are designed to offer strong group-level protection against membership inference, i.e., preventing an adversary from inferring whether a known individual or small group of individuals is present in the sensitive dataset.\n', '\n', 'They should not be used in situations where attribute inference from homogeneity attacks are a concern, i.e., when an adversary knows that a certain individual is present in the sensitive dataset, identifies them as part of a group sharing known attributes, and then infers previously unknown attributes of the individual because those attributes are common to the group.\n', '\n', '# Quick setup\n', '\n', 'The easiest way to start is to [run the web application locally with docker](./packages/webapp/README.md#locally-run-the-web-application-with-docker). You will be able to experiment with your data and see the result in real time using the UI.\n', '\n', 'If you are looking for faster alternatives to process bigger datasets, please refer to our [python pipeline tool](./packages/python-pipeline/README.md), [CLI application tool](./packages/cli/README.md) or [python synthesizer library](./packages/lib-pacsynth/README.md).\n', '\n', '# All available tools\n', '\n', 'We provide a set of tools to synthesize, aggregate and evaluate your data, which can be used according to your use case/preference. The available tools are described below:\n', '\n', '- **Python pipeline**: if you want to synthesize, aggregate your data and also generate the dashboards for visual analysis with a single command line command in python, please check the [python pipeline tool](./packages/python-pipeline/README.md).\n', '- **Web application**: if you want to locally run a web application capable of synthesize, aggregate and evaluate your data directly on your browser using Javascript and Web Assembly, this is the tool for you. The data is processed locally and never leaves your machine. Please check the [web application tool](./packages/webapp/README.md).\n', '- **Raw CLI application**: if you only want a command line interface (CLI) around our [core Rust library](./packages/core/README.md) for data synthesis and aggregation, please check the [CLI application tool](./packages/cli/README.md).\n', '- **pac-synth library**: if want to aggregate and synthesize data locally with python, please check the [python synthesizer library](./packages/lib-pacsynth/README.md).\n', '\n', '# Quick references\n', '\n', '- [python-pipeline](./packages/python-pipeline/README.md)\n', '- [webapp](./packages/webapp/README.md)\n', '- [cli](./packages/cli/README.md)\n', '- [core](./packages/core/README.md)\n', '- [lib-wasm](./packages/lib-wasm/README.md)\n', '- [lib-python](./packages/lib-python/README.md)\n', '- [lib-pacsynth](./packages/lib-pacsynth/README.md)\n', '\n', '# License\n', '\n', 'Synthetic data showcase\n', '\n', 'MIT License\n', '\n', 'Copyright (c) Microsoft Corporation.\n', '\n', 'Permission is hereby granted, free of charge, to any person obtaining a copy\n', 'of this software and associated documentation files (the ""Software""), to deal\n', 'in the Software without restriction, including without limitation the rights\n', 'to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n', 'copies of the Software, and to permit persons to whom the Software is\n', 'furnished to do so, subject to the following conditions:\n', '\n', 'The above copyright notice and this permission notice shall be included in all\n', 'copies or substantial portions of the Software.\n', '\n', 'THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n', 'IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n', 'FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n', 'AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n', 'LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n', 'OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n', 'SOFTWARE\n', '\n', '# Contributing\n', '\n', 'This project welcomes contributions and suggestions. Most contributions require you to agree to a\n', 'Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\n', 'the rights to use your contribution. For details, visit https://cla.opensource.microsoft.com.\n', '\n', 'When you submit a pull request, a CLA bot will automatically determine whether you need to provide\n', 'a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions\n', 'provided by the bot. You will only need to do this once across all repos using our CLA.\n', '\n', 'This project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\n', 'For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\n', 'contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n', '\n', '# Acknowledgements\n', '\n', 'This project resulted from a [Tech Against Trafficking (TAT)](https://techagainsttrafficking.org/) accelerator program with the [Counter Trafficking Data Collaborative (CTDC)](https://www.ctdatacollaborative.org/) and the [International Organization for Migration (IOM)](https://www.iom.int/) on how to safely share data on identified victims of human trafficking. Read more in this [TAT blog post](https://techagainsttrafficking.org/accelerating-toward-data-insights-tech-against-trafficking-successfully-concludes-its-pilot-accelerator/).\n', '\n', '# Contact\n', '\n', 'Feedback and suggestions are welcome via email to sds-team@microsoft.com.\n']"
Synthetic+Data,theodi/synthetic-data-tutorial,theodi,https://api.github.com/repos/theodi/synthetic-data-tutorial,71,26,2,"['https://api.github.com/users/fionntan', 'https://api.github.com/users/olivierthereaux']",Python,2023-02-03T09:27:35Z,https://raw.githubusercontent.com/theodi/synthetic-data-tutorial/master/README.md,"['_Last tested: 2022-04-14. Updated the requirements and ran in Python 3.10 (although a few warnings from Pandas)._\n', '\n', '# Anonymisation with Synthetic Data Tutorial\n', '\n', '## Some questions\n', '\n', '**What is this?**\n', '\n', 'A hands-on tutorial showing how to use Python to create synthetic data.\n', '\n', '**Wait, what is this ""synthetic data"" you speak of?**\n', '\n', ""It's data that is created by an automated process which contains many of the statistical patterns of an original dataset. It is also sometimes used as a way to release data that has no personal information in it, even if the original did contain lots of data that could identify people. This means programmers and data scientists can crack on with building software and algorithms that they know will work similarly on the real data.\n"", '\n', '**Who is this tutorial for?**\n', '\n', 'For any person who programs who wants to learn about data anonymisation in general or more specifically about synthetic data.\n', '\n', '**What is it not for?**\n', '\n', ""Non-programmers. Although we think this tutorial is still worth a browse to get some of the main ideas in what goes in to anonymising a dataset. However, if you're looking for info on how to create synthetic data using the latest and greatest deep learning techniques, this is not the tutorial for you.\n"", '\n', '**Who are you?**\n', '\n', ""We're the Open Data Institute. We work with companies and governments to build an open, trustworthy data ecosystem. Anonymisation and synthetic data are some of the many, many ways we can responsibly increase access to data. If you want to learn more, [check out our site](http://theodi.org).\n"", '\n', '**Why did you make this?**\n', '\n', ""We have an [R&D program](https://theodi.org/project/data-innovation-for-uk-research-and-development/) that has a number of projects looking in to how to support innovation, improve data infrastructure and encourage ethical data sharing. One of our projects is about [managing the risks of re-identification](https://theodi.org/project/rd-broaden-access-to-personal-data-while-protecting-privacy-and-creating-a-fair-market/) in shared and open data. As you can see in the *Key outputs* section, we have other material from the project, but we thought it'd be good to have something specifically aimed at programmers who are interested in learning by doing.\n"", '\n', '**Speaking of which, can I just get to the tutorial now?**\n', '\n', ""Sure! Let's go.\n"", '\n', '## Overview\n', '\n', ""In this tutorial you are aiming to create a safe version of accident and emergency (A&E) admissions data, collected from multiple hospitals. This data contains some sensitive personal information about people's health and can't be openly shared. By removing and altering certain identifying information in the data we can greatly reduce the risk that patients can be re-identified and therefore hope to release the data.\n"", '\n', ""Just to be clear, we're not using actual A&E data but are creating our own simple, mock, version of it.\n"", '\n', 'The practical steps involve:\n', '\n', '1. Create an A&E admissions dataset which will contain (pretend) personal information.\n', '2. Run some anonymisation steps over this dataset to generate a new dataset with much less re-identification risk.\n', '3. Take this de-identified dataset and generate multiple synthetic datasets from it to reduce the re-identification risk even further.\n', '4. Analyse the synthetic datasets to see how similar they are to the original data.\n', '\n', ""You may be wondering, why can't we just do synthetic data step? If it's synthetic surely it won't contain any personal information?\n"", '\n', 'Not exactly. Patterns picked up in the original data can be transferred to the synthetic data. This is especially true for outliers. For instance if there is only one person from an certain area over 85 and this shows up in the synthetic data, we would be able to re-identify them.\n', '\n', '## Credit to others\n', '\n', ""This tutorial is inspired by the [NHS England and ODI Leeds' research](https://odileeds.org/events/synae/) in creating a synthetic dataset from NHS England's accident and emergency admissions. Please do read about their project, as it's really interesting and great for learning about the benefits and risks in creating synthetic data.\n"", '\n', ""Also, the synthetic data generating library we use is [DataSynthetizer](https://homes.cs.washington.edu/~billhowe//projects/2017/07/20/Data-Synthesizer.html) and comes as part of this codebase. Coming from researchers in Drexel University and University of Washington, it's an excellent piece of software and their research and papers are well worth checking out. It's available as a [repo on Github](https://github.com/DataResponsibly/DataSynthesizer) which includes some short tutorials on how to use the toolkit and an accompanying research paper describing the theory behind it.\n"", '\n', '---\n', '\n', '## Setup\n', '\n', 'First, make sure you have [Python3 installed](https://www.python.org/downloads/). Minimum Python 3.6.\n', '\n', 'Download this repository either as a zip or clone using Git.\n', '\n', 'Install required dependent libraries. You can do that, for example, with a _virtualenv_.\n', '\n', '```bash\n', 'cd /path/to/repo/synthetic_data_tutorial/\n', 'pip install -r requirements.txt\n', '```\n', '\n', ""Next we'll go through how to create, de-identify and synthesise the code. We'll show this using code snippets but the full code is contained within the `/tutorial` directory.\n"", '\n', ""There's small differences between the code presented here and what's in the Python scripts but it's mostly down to variable naming. I'd encourage you to run, edit and play with the code locally.\n"", '\n', '## Generate mock NHS A&E dataset\n', '\n', 'The data already exists in `data/nhs_ae_mock.csv` so feel free to browse that. But you should generate your own fresh dataset using the `tutorial/generate.py` script.\n', '\n', ""To do this, you'll need to download one dataset first. It's a list of all postcodes in London. You can find it at this page on [doogal.co.uk](https://www.doogal.co.uk/PostcodeDownloads.php), at the _London_ link under the _By English region_ section. Or just download it directly at [this link](https://www.doogal.co.uk/UKPostcodesCSV.ashx?region=E12000007) (just take note, it's 133MB in size), then place the `London postcodes.csv` file in to the `data/` directory.\n"", '\n', 'Or you can just do it using `curl`.\n', '\n', '```bash\n', 'curl -o ""./data/London postcodes.csv"" https://www.doogal.co.uk/UKPostcodesCSV.ashx?region=E12000007\n', '```\n', '\n', 'Then, to generate the data, from the project root directory run the `generate.py` script.\n', '\n', '```bash\n', 'python tutorial/generate.py\n', '```\n', '\n', ""Voila! You'll now see a new `hospital_ae_data.csv` file in the `/data` directory. Open it up and have a browse. It's contains the following columns:\n"", '\n', '- **Health Service ID**: NHS number of the admitted patient  \n', '- **Age**: age of patient\n', '- **Time in A&E (mins)**: time in minutes of how long the patient spent in A&E. This is generated to correlate with the age of the patient.\n', '- **Hospital**: which hospital admitted the patient - with some hospitals being more prevalent in the data than others\n', '- **Arrival Time**: what time and date the patient was admitted - with weekends as busier and and a different peak time for each day\n', '- **Treatment**: what the person was treated for - with certain treatments being more common than others\n', '- **Gender**: patient gender - based on [NHS patient gender codes](https://www.datadictionary.nhs.uk/data_dictionary/attributes/p/person/person_gender_code_de.asp?shownav=1)\n', '- **Postcode**: postcode of patient - random, in use, London postcodes extracted from the `London postcodes.csv` file.\n', '\n', ""We can see this dataset obviously contains some personal information. For instance, if we knew roughly the time a neighbour went to A&E we could use their postcode to figure out exactly what ailment they went in with. Or, if a list of people's Health Service ID's were to be leaked in future, lots of people could be re-identified.\n"", '\n', ""Because of this, we'll need to take some de-identification steps.\n"", '\n', '---\n', '\n', '## De-identification\n', '\n', ""For this stage, we're going to be loosely following the de-identification techniques used by Jonathan Pearson of NHS England, and described in a blog post about [creating its own synthetic data](https://odileeds.org/blog/2019-01-24-exploring-methods-for-creating-synthetic-a-e-data).\n"", '\n', ""If you look in `tutorial/deidentify.py` you'll see the full code of all de-identification steps. You can run this code easily.\n"", '\n', '```bash\n', 'python tutorial/deidentify.py\n', '```\n', '\n', 'It takes the `data/hospital_ae_data.csv` file, run the steps, and saves the new dataset to `data/hospital_ae_data_deidentify.csv`.\n', '\n', 'Breaking down each of these steps. It first loads the `data/nhs_ae_data.csv` file in to the Pandas DataFrame as `hospital_ae_df`.\n', '\n', '```python\n', '# _df is a common way to refer to a Pandas DataFrame object\n', 'hospital_ae_df = pd.read_csv(filepaths.hospital_ae_data)\n', '```\n', '\n', '(`filepaths.py` is, surprise, surprise, where all the filepaths are listed)\n', '\n', '### Remove Health Service ID numbers\n', '\n', ""Health Service ID numbers are direct identifiers and should be removed. So we'll simply drop the entire column.\n"", '\n', '```python\n', ""hospital_ae_df = hospital_ae_df.drop('Health Service ID', 1)\n"", '```\n', '\n', '### Where a patient lives\n', '\n', ""Pseudo-identifiers, also known as [quasi-identifiers](https://en.wikipedia.org/wiki/Quasi-identifier), are pieces of information that don't directly identify people but can used with other information to identify a person. If we were to take the age, postcode and gender of a person we could combine these and check the dataset to see what that person was treated for in A&E.\n"", '\n', 'The data scientist from NHS England, Jonathan Pearson, describes this in the blog post:\n', '\n', '> I started with the postcode of the patients resident lower super output area (LSOA). This is a geographical definition with an average of 1500 residents created to make reporting in England and Wales easier. I wanted to keep some basic information about the area where the patient lives whilst completely removing any information regarding any actual postcode. A key variable in health care inequalities is the patients Index of Multiple deprivation (IMD) decile (broad measure of relative deprivation) which gives an average ranked value for each LSOA. By replacing the patients resident postcode with an IMD decile I have kept a key bit of information whilst making this field non-identifiable.\n', '\n', ""We'll do just the same with our dataset.\n"", '\n', ""First we'll map the rows' postcodes to their LSOA and then drop the postcodes column.\n"", '\n', '```python\n', 'postcodes_df = pd.read_csv(filepaths.postcodes_london)\n', 'hospital_ae_df = pd.merge(\n', '    hospital_ae_df,\n', ""    postcodes_df[['Postcode', 'Lower layer super output area']],\n"", ""    on='Postcode'\n"", ')\n', ""hospital_ae_df = hospital_ae_df.drop('Postcode', 1)\n"", '```\n', '\n', 'Then we\'ll add a mapped column of ""Index of Multiple Deprivation"" column for each entry\'s LSOA.\n', '\n', '```python\n', 'hospital_ae_df = pd.merge(\n', '    hospital_ae_df,\n', ""    postcodes_df[['Lower layer super output area', 'Index of Multiple Deprivation']].drop_duplicates(),\n"", ""    on='Lower layer super output area'\n"", ')\n', '```\n', '\n', ""Next calculate the decile bins for the IMDs by taking all the IMDs from large list of London. We'll use the Pandas `qcut` (quantile cut), function for this.\n"", '\n', '```python\n', '_, bins = pd.qcut(\n', ""    postcodes_df['Index of Multiple Deprivation'],\n"", '    10,\n', '    retbins=True,\n', '    labels=False\n', ')\n', '```\n', '\n', ""Then we'll use those decile `bins` to map each row's IMD to its IMD decile.\n"", '\n', '```python\n', '# add +1 to get deciles from 1 to 10 (not 0 to 9)\n', ""hospital_ae_df['Index of Multiple Deprivation Decile'] = pd.cut(\n"", ""    hospital_ae_df['Index of Multiple Deprivation'],\n"", '    bins=bins,\n', '    labels=False,\n', '    include_lowest=True) + 1\n', '```\n', '\n', 'And finally drop the columns we no longer need.\n', '\n', '```python\n', ""hospital_ae_df = hospital_ae_df.drop('Index of Multiple Deprivation', 1)\n"", ""hospital_ae_df = hospital_ae_df.drop('Lower layer super output area', 1)\n"", '```\n', '\n', '### Individual hospitals\n', '\n', 'The data scientist at NHS England masked individual hospitals giving the following reason.\n', '\n', '> As each hospital has its own complex case mix and health system, using these data to identify poor performance or possible improvements would be invalid and un-helpful. Therefore, I decided to replace the hospital code with a random number.\n', '\n', ""So we'll do as they did, replacing hospitals with a random six-digit ID.\n"", '\n', '```python\n', ""hospitals = hospital_ae_df['Hospital'].unique().tolist()\n"", 'random.shuffle(hospitals)\n', 'hospitals_map = {\n', ""    hospital : ''.join(random.choices(string.digits, k=6))\n"", '    for hospital in hospitals\n', '}\n', ""hospital_ae_df['Hospital ID'] = hospital_ae_df['Hospital'].map(hospitals_map)\n"", '```\n', '\n', 'And remove the `Hospital` column.\n', '\n', '```python\n', ""hospital_ae_df = hospital_ae_df.drop('Hospital', 1)\n"", '```\n', '\n', '### Time in the data\n', '\n', ""> The next obvious step was to simplify some of the time information I have available as health care system analysis doesn't need to be responsive enough to work on a second and minute basis. Thus, I removed the time information from the 'arrival date', mapped the 'arrival time' into 4-hour chunks\n"", '\n', ""First we'll split the `Arrival Time` column in to `Arrival Date` and `Arrival Hour`.\n"", '\n', '```python\n', ""arrival_times = pd.to_datetime(hospital_ae_df['Arrival Time'])\n"", ""hospital_ae_df['Arrival Date'] = arrival_times.dt.strftime('%Y-%m-%d')\n"", ""hospital_ae_df['Arrival Hour'] = arrival_times.dt.hour\n"", ""hospital_ae_df = hospital_ae_df.drop('Arrival Time', 1)\n"", '```\n', '\n', ""Then we'll map the hours to 4-hour chunks and drop the `Arrival Hour` column.\n"", '\n', '```python\n', ""hospital_ae_df['Arrival hour range'] = pd.cut(\n"", ""    hospital_ae_df['Arrival Hour'],\n"", '    bins=[0, 4, 8, 12, 16, 20, 24],\n', ""    labels=['00-03', '04-07', '08-11', '12-15', '16-19', '20-23'],\n"", '    include_lowest=True\n', ')\n', ""hospital_ae_df = hospital_ae_df.drop('Arrival Hour', 1)\n"", '```\n', '\n', '### Patient demographics\n', '\n', '> I decided to only include records with a sex of male or female in order to reduce risk of re identification through low numbers.\n', '\n', '```python\n', ""hospital_ae_df = hospital_ae_df[hospital_ae_df['Gender'].isin(['Male', 'Female'])]\n"", '```\n', '\n', ""> For the patients age it is common practice to group these into bands and so I've used a standard set - 1-17, 18-24, 25-44, 45-64, 65-84, and 85+ - which although are non-uniform are well used segments defining different average health care usage.\n"", '\n', '```python\n', ""hospital_ae_df['Age bracket'] = pd.cut(\n"", ""    hospital_ae_df['Age'],\n"", '    bins=[0, 18, 25, 45, 65, 85, 150],\n', ""    labels=['0-17', '18-24', '25-44', '45-64', '65-84', '85-'],\n"", '    include_lowest=True\n', ')\n', ""hospital_ae_df = hospital_ae_df.drop('Age', 1)\n"", '```\n', '\n', ""That's all the steps we'll take. We'll finally save our new de-identified dataset.\n"", '\n', '```python\n', 'hospital_ae_df.to_csv(filepaths.hospital_ae_data_deidentify, index=False)\n', '```\n', '\n', '---\n', '\n', '## Synthesise\n', '\n', 'Synthetic data exists on a spectrum from merely the same columns and datatypes as the original data all the way to carrying nearly all of the statistical patterns of the original dataset.\n', '\n', ""The UK's Office of National Statistics has a great report on synthetic data and the [_Synthetic Data Spectrum_](https://www.ons.gov.uk/methodology/methodologicalpublications/generalmethodology/onsworkingpaperseries/onsmethodologyworkingpaperseriesnumber16syntheticdatapilot?utm_campaign=201903_UK_DataPolicyNetwork&utm_source=hs_email&utm_medium=email&utm_content=70377606&_hsenc=p2ANqtz-9W6ByBext_HsgkTPG1lw2JJ_utRoJSTIeVC5Z2lz3QkzwFQpZ0dp2ns9SZLPqxLJrgWzsjC_zt7FQcBvtIGoeSjZtwNg&_hsmi=70377606#synthetic-dataset-spectrum) section is very good in explaining the nuances in more detail.\n"", '\n', ""In this tutorial we'll create not one, not two, but *three* synthetic datasets, that are on a range across the synthetic data spectrum: *Random*, *Independent* and *Correlated*.\n"", '\n', '> In **correlated attribute mode**, we learn a differentially private Bayesian network capturing the correlation structure between attributes, then draw samples from this model to construct the result dataset.\n', '>\n', '> In cases where the correlated attribute mode is too computationally expensive or when there is insufficient data to derive a reasonable model, one can use **independent attribute mode**. In this mode, a histogram is derived for each attribute, noise is added to the histogram to achieve differential privacy, and then samples are drawn for each attribute.\n', '>\n', '> Finally, for cases of extremely sensitive data, one can use **random mode** that simply generates type-consistent random values for each attribute.\n', '\n', ""We'll go through each of these now, moving along the synthetic data spectrum, in the order of random to independent to correlated.\n"", '\n', 'The toolkit we will be using to generate the three synthetic datasets is DataSynthetizer.\n', '\n', '### DataSynthesizer\n', '\n', ""As described in the introduction, this is an open-source toolkit for generating synthetic data. And I'd like to lavish much praise on the researchers who made it as it's excellent.\n"", '\n', ""Instead of explaining it myself, I'll use the researchers' own words from their paper:\n"", '\n', '> DataSynthesizer infers the domain of each attribute and derives a description of the distribution of attribute values in the private dataset. This information is saved in a dataset description file, to which we refer as data summary. Then DataSynthesizer is able to generate synthetic datasets of arbitrary size by sampling from the probabilistic model in the dataset description file.\n', '\n', ""We'll create and inspect our synthetic datasets using three modules within it.\n"", '\n', '> DataSynthesizer consists of three high-level modules:\n', '>\n', '> 1. **DataDescriber**: investigates the data types, correlations and distributions of the attributes in the private dataset, and produces a data summary.\n', '> 2. **DataGenerator**: samples from the summary computed by DataDescriber and outputs synthetic data\n', '> 3. **ModelInspector**: shows an intuitive description of the data summary that was computed by DataDescriber, allowing the data owner to evaluate the accuracy of the summarization process and adjust any parameters, if desired.\n', '\n', 'If you want to browse the code for each of these modules, you can find the Python classes for in the `DataSynthetizer` directory (all code in here from the [original repo](https://github.com/DataResponsibly/DataSynthesizer)).\n', '\n', '\n', '### An aside about differential privacy and Bayesian networks\n', '\n', 'You might have seen the phrase ""differentially private Bayesian network"" in the *correlated mode* description earlier, and got slightly panicked. But fear not! You don\'t need to worry *too* much about these to get DataSynthesizer working.\n', '\n', ""First off, while DataSynthesizer has the option of using differential privacy for anonymisation, we are turning it off and won't be using it in this tutorial. So you can ignore that part. However, if you care about anonymisation you really should read up on differential privacy. I've read a lot of explainers on it and the best I found was [this article from Access Now](https://www.accessnow.org/understanding-differential-privacy-matters-digital-rights/).\n"", '\n', 'Now the next term, Bayesian networks. These are graphs with directions which model the statistical relationship between a dataset\'s variables. It does this by saying certain variables are ""parents"" of others, that is, their value influences their ""children"" variables. Parent variables can influence children but children can\'t influence parents. In our case, if patient age is a parent of waiting time, it means the age of patient influences how long they wait, but how long they doesn\'t influence their age. So by using Bayesian Networks, DataSynthesizer can model these influences and use this model in generating the synthetic data.\n', '\n', 'It can be a slightly tricky topic to grasp but a nice, introductory tutorial on them is at the [Probabilistic World site](https://www.probabilisticworld.com/bayesian-belief-networks-part-1/). Give it a read.\n', '\n', '### Random mode\n', '\n', ""If we were just to generate A&E data for testing our software, we wouldn't care too much about the statistical patterns within the data. Just that it was roughly a similar size and that the datatypes and columns aligned.\n"", '\n', 'In this case, we can just generate the data at random using the `generate_dataset_in_random_mode` function within the `DataGenerator` class.\n', '\n', '#### Data Description: Random\n', '\n', 'The first step is to create a description of the data, defining the datatypes and which are the categorical variables.\n', '\n', '```python\n', 'attribute_to_datatype = {\n', ""    'Time in A&E (mins)': 'Integer',\n"", ""    'Treatment': 'String',\n"", ""    'Gender': 'String',\n"", ""    'Index of Multiple Deprivation Decile': 'Integer',\n"", ""    'Hospital ID': 'String',\n"", ""    'Arrival Date': 'String',\n"", ""    'Arrival hour range': 'String',  \n"", ""    'Age bracket': 'String'\n"", '}\n', '\n', 'attribute_is_categorical = {\n', ""    'Hospital ID': True,\n"", ""    'Time in A&E (mins)': False,\n"", ""    'Treatment': True,\n"", ""    'Gender': True,\n"", ""    'Index of Multiple Deprivation Decile': False,\n"", ""    'Arrival Date': True,\n"", ""    'Arrival hour range': True,  \n"", ""    'Age bracket': True\n"", '}\n', '```\n', '\n', ""We'll be feeding these in to a `DataDescriber` instance.\n"", '\n', '```python\n', 'describer = DataDescriber()\n', '```\n', '\n', 'Using this `describer` instance, feeding in the attribute descriptions, we create a description file.\n', '\n', '```python\n', 'describer.describe_dataset_in_random_mode(\n', '    filepaths.hospital_ae_data_deidentify,\n', '    attribute_to_datatype=attribute_to_datatype,\n', '    attribute_to_is_categorical=attribute_is_categorical)\n', 'describer.save_dataset_description_to_file(\n', '    filepaths.hospital_ae_description_random)\n', '```\n', '\n', 'You can see an example description file in `data/hospital_ae_description_random.json`.\n', '\n', '#### Data Generation: Random\n', '\n', ""Next, generate the random data. We'll just generate the same amount of rows as was in the original data but, importantly, we could generate much more or less if we wanted to.\n"", '\n', '```python\n', 'num_rows = len(hospital_ae_df)\n', '```\n', '\n', 'Now generate the random data.\n', '\n', '```python\n', 'generator = DataGenerator()\n', 'generator.generate_dataset_in_random_mode(\n', '    num_rows, filepaths.hospital_ae_description_random)\n', 'generator.save_synthetic_data(filepaths.hospital_ae_data_synthetic_random)\n', '```\n', '\n', 'You can view this random synthetic data in the file `data/hospital_ae_data_synthetic_random.csv`.\n', '\n', '#### Attribute Comparison: Random\n', '\n', ""We'll compare each attribute in the original data to the synthetic data by generating plots of histograms using the `ModelInspector` class.\n"", '\n', ""`figure_filepath` is just a variable holding where we'll write the plot out to.\n"", '\n', '```python\n', 'synthetic_df = pd.read_csv(filepaths.hospital_ae_data_synthetic_random)\n', '\n', '# Read attribute description from the dataset description file.\n', 'attribute_description = read_json_file(\n', ""    filepaths.hospital_ae_description_random)['attribute_description']\n"", '\n', 'inspector = ModelInspector(hospital_ae_df, synthetic_df, attribute_description)\n', '\n', 'for attribute in synthetic_df.columns:\n', '    inspector.compare_histograms(attribute, figure_filepath)\n', '```\n', '\n', ""Let's look at the histogram plots now for a few of the attributes. We can see that the generated data is completely random and doesn't contain any information about averages or distributions.\n"", '\n', '*Comparison of ages in original data (left) and random synthetic data (right)*\n', '![Random mode age bracket histograms](plots/random_Age_bracket.png)\n', '\n', '*Comparison of hospital attendance in original data (left) and random synthetic data (right)*\n', '![Random mode age bracket histograms](plots/random_Hospital_ID.png)\n', '\n', '*Comparison of arrival date in original data (left) and random synthetic data (right)*\n', '![Random mode age bracket histograms](plots/random_Arrival_Date.png)\n', '\n', 'You can see more comparison examples in the `/plots` directory.\n', '\n', '#### Compare pairwise mutual information: Random\n', '\n', ""DataSynthesizer has a function to compare the _mutual information_ between each of the variables in the dataset and plot them. We'll avoid the mathematical definition of mutual information but [Scholarpedia notes](http://www.scholarpedia.org/article/Mutual_information) it:\n"", '\n', '> can be thought of as the reduction in uncertainty about one random variable given knowledge of another.\n', '\n', 'To create this plot we run.\n', '\n', '```python\n', 'synthetic_df = pd.read_csv(filepaths.hospital_ae_data_synthetic_random)\n', '\n', 'inspector = ModelInspector(hospital_ae_df, synthetic_df, attribute_description)\n', 'inspector.mutual_information_heatmap(figure_filepath)\n', '```\n', '\n', 'We can see the original, private data has a correlation between `Age bracket` and `Time in A&E (mins)`. Not surprisingly, this correlation is lost when we generate our random data.\n', '\n', '*Mutual Information Heatmap in original data (left) and random synthetic data (right)*\n', '![Random mode age mutual information](plots/mutual_information_heatmap_random.png)\n', '\n', '### Independent attribute mode\n', '\n', ""What if we had the use case where we wanted to build models to analyse the medians of ages, or hospital usage in the synthetic data? In this case we'd use independent attribute mode.\n"", '\n', '#### Data Description: Independent\n', '\n', '```python\n', 'describer.describe_dataset_in_independent_attribute_mode(\n', '    attribute_to_datatype=attribute_to_datatype,\n', '    attribute_to_is_categorical=attribute_is_categorical)\n', 'describer.save_dataset_description_to_file(\n', '    filepaths.hospital_ae_description_independent)\n', '```\n', '\n', '#### Data Generation: Independent\n', '\n', 'Next generate the data which keep the distributions of each column but not the data correlations.\n', '\n', '```python\n', 'generator = DataGenerator()\n', 'generator.generate_dataset_in_independent_mode(\n', '    num_rows, filepaths.hospital_ae_description_independent)\n', 'generator.save_synthetic_data(\n', '    filepaths.hospital_ae_data_synthetic_independent)\n', '```\n', '\n', '#### Attribute Comparison: Independent\n', '\n', 'Comparing the attribute histograms we see the independent mode captures the distributions pretty accurately. You can see the synthetic data is _mostly_ similar but not exactly.\n', '\n', '```python\n', 'synthetic_df = pd.read_csv(filepaths.hospital_ae_data_synthetic_independent)\n', 'attribute_description = read_json_file(\n', ""    filepaths.hospital_ae_description_random)['attribute_description']\n"", 'inspector = ModelInspector(hospital_ae_df, synthetic_df, attribute_description)\n', '\n', 'for attribute in synthetic_df.columns:\n', '    inspector.compare_histograms(attribute, figure_filepath)\n', '```\n', '\n', '*Comparison of ages in original data (left) and independent synthetic data (right)*\n', '![Random mode age bracket histograms](plots/independent_Age_bracket.png)\n', '\n', '*Comparison of hospital attendance in original data (left) and independent synthetic data (right)*\n', '![Random mode age bracket histograms](plots/independent_Hospital_ID.png)\n', '\n', '*Comparison of arrival date in original data (left) and independent synthetic data (right)*\n', '![Random mode age bracket histograms](plots/independent_Arrival_Date.png)\n', '\n', '#### Compare pairwise mutual information: Independent\n', '\n', '```python\n', 'synthetic_df = pd.read_csv(filepaths.hospital_ae_data_synthetic_independent)\n', '\n', 'inspector = ModelInspector(hospital_ae_df, synthetic_df, attribute_description)\n', 'inspector.mutual_information_heatmap(figure_filepath)\n', '```\n', '\n', 'We can see the independent data also does not contain any of the attribute correlations from the original data.\n', '\n', '*Mutual Information Heatmap in original data (left) and independent synthetic data (right)*\n', '![Independent mode mutual information](plots/mutual_information_heatmap_independent.png)\n', '\n', '### Correlated attribute mode - include correlations between columns in the data\n', '\n', ""If we want to capture correlated variables, for instance if patient is related to waiting times, we'll need correlated data. To do this we use *correlated mode*.\n"", '\n', '#### Data Description: Correlated\n', '\n', ""There's a couple of parameters that are different here so we'll explain them.\n"", '\n', ""`epsilon` is a value for DataSynthesizer's differential privacy which says the amount of noise to add to the data - the higher the value, the more noise and therefore more privacy. We're not using differential privacy so we can set it to zero.\n"", '\n', ""`k` is the maximum number of parents in a Bayesian network, i.e., the maximum number of incoming edges. For simplicity's sake, we're going to set this to 1, saying that for a variable only one other variable can influence it.\n"", '\n', '```python\n', 'describer.describe_dataset_in_correlated_attribute_mode(\n', '    dataset_file=filepaths.hospital_ae_data_deidentify,\n', '    epsilon=0,\n', '    k=1,\n', '    attribute_to_datatype=attribute_to_datatype,\n', '    attribute_to_is_categorical=attribute_is_categorical)\n', '\n', 'describer.save_dataset_description_to_file(filepaths.hospital_ae_description_correlated)\n', '```\n', '\n', '#### Data Generation: Correlated\n', '\n', '```python\n', 'generator.generate_dataset_in_correlated_attribute_mode(\n', '    num_rows, filepaths.hospital_ae_description_correlated)\n', 'generator.save_synthetic_data(filepaths.hospital_ae_data_synthetic_correlated)\n', '```\n', '\n', '#### Attribute Comparison: Correlated\n', '\n', 'We can see correlated mode keeps similar distributions also. It looks the exact same but if you look closely there are also small differences in the distributions.\n', '\n', '*Comparison of ages in original data (left) and correlated synthetic data (right)*\n', '![Random mode age bracket histograms](plots/correlated_Age_bracket.png)\n', '\n', '*Comparison of hospital attendance in original data (left) and independent synthetic data (right)*\n', '![Random mode age bracket histograms](plots/correlated_Hospital_ID.png)\n', '\n', '*Comparison of arrival date in original data (left) and independent synthetic data (right)*\n', '![Random mode age bracket histograms](plots/correlated_Arrival_Date.png)\n', '\n', '#### Compare pairwise mutual information: Correlated\n', '\n', 'Finally, we see in correlated mode, we manage to capture the correlation between `Age bracket` and `Time in A&E (mins)`.\n', '\n', '```python\n', 'synthetic_df = pd.read_csv(filepaths.hospital_ae_data_synthetic_correlated)\n', '\n', 'inspector = ModelInspector(hospital_ae_df, synthetic_df, attribute_description)\n', 'inspector.mutual_information_heatmap(figure_filepath)\n', '```\n', '\n', '*Mutual Information Heatmap in original data (left) and correlated synthetic data (right)*\n', '![Independent mode mutual information](plots/mutual_information_heatmap_correlated.png)\n', '\n', '---\n', '\n', '### Wrap-up\n', '\n', 'This is where our tutorial ends. But there is much, much more to the world of anonymisation and synthetic data. Please check out more in the references below.\n', '\n', 'If you have any queries, comments or improvements about this tutorial please do get in touch. You can send me a message through "
Synthetic+Data,sdv-dev/TGAN,sdv-dev,https://api.github.com/repos/sdv-dev/TGAN,240,82,6,"['https://api.github.com/users/ManuelAlvarezC', 'https://api.github.com/users/csala', 'https://api.github.com/users/leix28', 'https://api.github.com/users/JDTheRipperPC', 'https://api.github.com/users/pvk-developer', 'https://api.github.com/users/ppwwyyxx']",Python,2023-03-31T01:20:08Z,https://raw.githubusercontent.com/sdv-dev/TGAN/master/README.md,"['<p align=""left"">\n', '<img width=20% src=""https://dai.lids.mit.edu/wp-content/uploads/2018/06/Logo_DAI_highres.png"" alt=""sdv-dev"" />\n', '<i>An open source project from Data to AI Lab at MIT.</i>\n', '</p>\n', '\n', '[![Development Status](https://img.shields.io/badge/Development%20Status-2%20--%20Pre--Alpha-yellow)](https://pypi.org/search/?c=Development+Status+%3A%3A+2+-+Pre-Alpha)\n', '[![PyPi Shield](https://img.shields.io/pypi/v/TGAN.svg)](https://pypi.python.org/pypi/TGAN)\n', '[![Travis CI Shield](https://travis-ci.org/sdv-dev/TGAN.svg?branch=master)](https://travis-ci.org/sdv-dev/TGAN)\n', '[![CodeCov](https://codecov.io/gh/sdv-dev/TGAN/branch/master/graph/badge.svg)](https://codecov.io/gh/sdv-dev/TGAN)\n', '[![Downloads](https://pepy.tech/badge/tgan)](https://pepy.tech/project/tgan)\n', '\n', '__We are happy to announce that our new model for synthetic data called [CTGAN](https://github.com/sdv-dev/CTGAN) is open-sourced. Please check the new model in [this repo](https://github.com/sdv-dev/CTGAN). The new model is simpler and gives better performance on many datasets.__\n', '\n', '# TGAN\n', '\n', 'Generative adversarial training for synthesizing tabular data.\n', '\n', '* License: [MIT](https://github.com/sdv-dev/TGAN/blob/master/LICENSE)\n', '* Development Status: [Pre-Alpha](https://pypi.org/search/?c=Development+Status+%3A%3A+2+-+Pre-Alpha)\n', '* Homepage: https://github.com/sdv-dev/TGAN\n', '\n', '# Overview\n', '\n', 'TGAN is a tabular data synthesizer. It can generate fully synthetic data from real data. Currently, TGAN can\n', 'generate numerical columns and categorical columns.\n', '\n', '# Requirements\n', '\n', '## Python\n', '\n', '**TGAN** has been developed and runs on Python [3.5](https://www.python.org/downloads/release/python-356/),\n', '[3.6](https://www.python.org/downloads/release/python-360/) and\n', '[3.7](https://www.python.org/downloads/release/python-370/).\n', '\n', 'Also, although it is not strictly required, the usage of a [virtualenv](https://virtualenv.pypa.io/en/latest/)\n', 'is highly recommended in order to avoid interfering with other software installed in the system where **TGAN**\n', 'is run.\n', '\n', '# Installation\n', '\n', 'The simplest and recommended way to install TGAN is using `pip`:\n', '\n', '```\n', 'pip install tgan\n', '```\n', '\n', 'Alternatively, you can also clone the repository and install it from sources\n', '\n', '```\n', 'git clone git@github.com:sdv-dev/TGAN.git\n', 'cd TGAN\n', 'make install\n', '```\n', '\n', 'For development, you can use `make install-develop` instead in order to install all the required\n', 'dependencies for testing and code linting.\n', '\n', '# Data Format\n', '\n', '## Input Format\n', '\n', 'In order to be able to sample new synthetic data, **TGAN** first needs to be *fitted* to\n', 'existing data.\n', '\n', 'The input data for this *fitting* process has to be a single table that satisfies the following\n', 'rules:\n', '\n', '* Has no missing values.\n', '* Has columns of types `int`, `float`, `str` or `bool`.\n', '* Each column contains data of only one type.\n', '\n', 'An example of such a tables would be:\n', '\n', '| str_column | float_column | int_column | bool_column |\n', '|------------|--------------|------------|-------------|\n', ""|    'green' |         0.15 |         10 |        True |\n"", ""|     'blue' |         7.25 |         23 |       False |\n"", ""|      'red' |        10.00 |          1 |       False |\n"", ""|   'yellow' |         5.50 |         17 |        True |\n"", '\n', 'As you can see, this table contains 4 columns: `str_column`, `float_column`, `int_column` and\n', '`bool_column`, each one being an example of the supported value types. Notice aswell that there is\n', 'no missing values for any of the rows.\n', '\n', ""**NOTE**: It's important to have properly identifed which of the columns are numerical, which means\n"", 'that they represent a magnitude, and which ones are categorical, as during the preprocessing of\n', 'the data, numerical and categorical columns will be processed differently.\n', '\n', '## Output Format\n', '\n', 'The output of **TGAN** is a table of sampled data with the same columns as the input table and as\n', 'many rows as requested.\n', '\n', '## Demo Datasets\n', '\n', '**TGAN** includes a few datasets to use for development or demonstration purposes. These datasets\n', 'come from the [UCI Machine Learning repository](http://archive.ics.uci.edu/ml), and have been\n', 'preprocessed to be ready to use with **TGAN**, following the requirements specified in the\n', '[Input Format](#input-format) section.\n', '\n', 'These datasets can be browsed and directly downloaded from the\n', '[hdi-project-tgan AWS S3 Bucket](http://hdi-project-tgan.s3.amazonaws.com/index.html)\n', '\n', '### Census dataset\n', '\n', 'This dataset contains a single table, with information from the census, labeled with information of\n', ""wheter or not the income of is greater than 50.000 $/year. It's a single csv file, containing\n"", '199522 rows and 41 columns. From these 41 columns, only 7 are identified as continuous. In\n', '**TGAN** this dataset is called `census`.\n', '\n', '### Cover type\n', '\n', 'This dataset contains a single table with cartographic information labeled with the different\n', ""forrest cover types. It's a single csv file, containing 465588 rows and 55 columns. From these\n"", '55 columns, 10 are identified as continuous. In **TGAN** this dataset is called `covertype`.\n', '\n', '# Quickstart\n', '\n', 'In this short tutorial we will guide you through a series of steps that will help you getting\n', 'started with the most basic usage of **TGAN** in order to generate samples from a given dataset.\n', '\n', '**NOTE**: The following examples are also covered in a [Jupyter](https://jupyter.org/) notebook,\n', 'which you can execute by running the following commands inside your *virtualenv*:\n', '\n', '```\n', 'pip install jupyter\n', 'jupyter notebook examples/Usage_Example.ipynb\n', '```\n', '\n', '## 1. Load the data\n', '\n', 'The first step is to load the data wich we will use to fit TGAN. In order to do so, we will first\n', 'import the function `tgan.data.load_data` and call it with the name of the dataset that we want to\n', 'load.\n', '\n', 'In this case, we will load the `census` dataset, which we will use during the subsequent steps,\n', 'and obtain two objects:\n', '\n', '1. `data`, that will contain a `pandas.DataFrame` with the table of data from the `census`\n', 'dataset ready to be used to fit the model.\n', '\n', '2. `continuous_columns`, that will contain a `list` with the indices of continuous columns.\n', '\n', '```\n', '>>> from tgan.data import load_demo_data\n', "">>> data, continuous_columns = load_demo_data('census')\n"", '>>> data.head(3).T[:10]\n', '                              0                                     1                             2\n', '0                            73                                    58                            18\n', '1               Not in universe        Self-employed-not incorporated               Not in universe\n', '2                             0                                     4                             0\n', '3                             0                                    34                             0\n', '4          High school graduate            Some college but no degree                    10th grade\n', '5                             0                                     0                             0\n', '6               Not in universe                       Not in universe                   High school\n', '7                       Widowed                              Divorced                 Never married\n', '8   Not in universe or children                          Construction   Not in universe or children\n', '9               Not in universe   Precision production craft & repair               Not in universe\n', '\n', '>>> continuous_columns\n', '[0, 5, 16, 17, 18, 29, 38]\n', '\n', '```\n', '\n', '## 2. Create a TGAN instance\n', '\n', 'The next step is to import TGAN and create an instance of the model.\n', '\n', 'To do so, we need to import the `tgan.model.TGANModel` class and call it with the\n', '`continuous_columns` as unique argument.\n', '\n', 'This will create a TGAN instance with the default parameters:\n', '\n', '```\n', '>>> from tgan.model import TGANModel\n', '>>> tgan = TGANModel(continuous_columns)\n', '```\n', '\n', '## 3. Fit the model\n', '\n', ""Once you have a **TGAN** instance, you can proceed to call it's `fit` method passing the `data` that\n"", 'you loaded before in order to start the fitting process:\n', '\n', '```\n', '>>> tgan.fit(data)\n', '```\n', '\n', 'This process will not return anything, however, the progress of the fitting will be printed in the\n', 'screen.\n', '\n', '**NOTE** Depending on the performance of the system you are running, and the parameters selected\n', 'for the model, this step can take up to a few hours.\n', '\n', '## 4. Sample new data\n', '\n', 'After the model has been fitted, you are ready to generate new samples by calling the `sample`\n', 'method of the `TGAN` instance passing it the desired amount of samples:\n', '\n', '```\n', '>>> num_samples = 1000\n', '>>> samples = tgan.sample(num_samples)\n', '>>> samples.head(3).T[:10]\n', '                                         0                                     1                                   2\n', '0                                       12                                    27                                  56\n', '\n', '0                                       12                                    27                                  56\n', '1                          Not in universe        Self-employed-not incorporated                             Private\n', '2                                        0                                     4                                  35\n', '3                                        0                                    34                                  22\n', '4                                 Children            Some college but no degree          Some college but no degree\n', '5                                        0                                     0                                 500\n', '6                          Not in universe                       Not in universe                     Not in universe\n', '7                            Never married       Married-civilian spouse present     Married-civilian spouse present\n', '8              Not in universe or children                          Construction   Finance insurance and real estate\n', '9                          Not in universe   Precision production craft & repair      Adm support including clerical\n', '\n', '```\n', '\n', 'The returned object, `samples`, is a `pandas.DataFrame` containing a table of synthetic data with\n', 'the same format as the input data and 1000 rows as we requested.\n', '\n', '## 5. Save and Load a model\n', '\n', 'In the steps above we saw that the fitting process can take a lot of time, so we probably would\n', 'like to avoid having to fit every we want to generate samples. Instead we can fit a model once,\n', 'save it, and load it every time we want to sample new data.\n', '\n', ""If we have a fitted model, we can save it by calling it's `save` method, that only takes\n"", 'as argument the path where the model will be stored. Similarly, the `TGANModel.load` allows to load\n', 'a model stored on disk by passing as argument the path where the model is stored.\n', '\n', '```\n', "">>> model_path = 'models/mymodel.pkl'\n"", '>>> tgan.save(model_path)\n', 'Model saved successfully.\n', '```\n', '\n', 'Bear in mind that in case the file already exists, **TGAN** will avoid overwritting it unless the\n', '`force=True` argument is passed:\n', '\n', '```\n', '>>> tgan.save(model_path)\n', 'The indicated path already exists. Use `force=True` to overwrite.\n', '```\n', '\n', 'In order to do so:\n', '\n', '```\n', '>>> tgan.save(model_path, force=True)\n', 'Model saved successfully.\n', '```\n', '\n', 'Once the model is saved, it can be loaded back as a **TGAN** instance by using the `TGANModel.load`\n', 'method:\n', '\n', '```\n', '>>> new_tgan = TGANModel.load(model_path)\n', '>>> new_samples = new_tgan.sample(num_samples)\n', '>>> new_samples.head(3).T[:10]\n', '\n', '                                         0                                     1                                   2\n', '0                                       12                                    27                                  56\n', '\n', '0                                       12                                    27                                  56\n', '1                          Not in universe        Self-employed-not incorporated                             Private\n', '2                                        0                                     4                                  35\n', '3                                        0                                    34                                  22\n', '4                                 Children            Some college but no degree          Some college but no degree\n', '5                                        0                                     0                                 500\n', '6                          Not in universe                       Not in universe                     Not in universe\n', '7                            Never married       Married-civilian spouse present     Married-civilian spouse present\n', '8              Not in universe or children                          Construction   Finance insurance and real estate\n', '9                          Not in universe   Precision production craft & repair      Adm support including clerical\n', '```\n', '\n', 'At this point we could use this model instance to generate more samples.\n', '\n', '# Loading custom datasets\n', '\n', 'In the previous steps we used some demonstration data but we did not show you how to load your own\n', 'dataset.\n', '\n', 'In order to do so you will need to generate a `pandas.DataFrame` object from your dataset. If your\n', 'dataset is in a `csv` format you can do so by using `pandas.read_csv` and passing to it the path to\n', 'the CSV file that you want to load.\n', '\n', 'Additionally, you will need to create 0-indexed list of columns indices to be considered continuous.\n', '\n', 'For example, if we want to load a local CSV file, `path/to/my.csv`, that has as continuous columns\n', 'their first 4 columns, that is, indices `[0, 1, 2, 3]`, we would do it like this:\n', '\n', '```\n', '>>> import pandas as pd\n', "">>> data = pd.read_csv('data/census.csv')\n"", '>>> continuous_columns = [0, 1, 2, 3]\n', '```\n', '\n', 'Now you can use the `continuous_columns` to create a **TGAN** instance and use the `data` to `fit`\n', 'it, like we did before:\n', '\n', '```\n', '>>> from tgan.model import TGANModel\n', '>>> tgan = TGANModel(continuous_columns)\n', '>>> tgan.fit(data)\n', '```\n', '\n', '# Model Parameters\n', '\n', 'If you want to change the default behavior of `TGANModel`, such as as different `batch_size` or\n', '`num_epochs`, you can do so by passing different arguments when creating the instance.\n', '\n', '## Model general behavior\n', '\n', '* continous_columns (`list[int]`, required): List of columns indices to be considered continuous.\n', '* output (`str`, default=`output`): Path to store the model and its artifacts.\n', '\n', '## Neural network definition and fitting\n', '\n', '* max_epoch (`int`, default=`100`): Number of epochs to use during training.\n', '* steps_per_epoch (`int`, default=`10000`): Number of steps to run on each epoch.\n', '* save_checkpoints(`bool`, default=True): Whether or not to store checkpoints of the model after each training epoch.\n', '* restore_session(`bool`, default=True): Whether or not continue training from the last checkpoint.\n', '* batch_size (`int`, default=`200`): Size of the batch to feed the model at each step.\n', '* z_dim (`int`, default=`100`): Number of dimensions in the noise input for the generator.\n', '* noise (`float`, default=`0.2`): Upper bound to the gaussian noise added to categorical columns.\n', '* l2norm (`float`, default=`0.00001`): L2 reguralization coefficient when computing losses.\n', '* learning_rate (`float`, default=`0.001`): Learning rate for the optimizer.\n', '* num_gen_rnn (`int`, default=`400`): Number of units in rnn cell in generator.\n', '* num_gen_feature (`int`, default=`100`): Number of units in fully connected layer in generator.\n', '* num_dis_layers (`int`, default=`2`): Number of layers in discriminator.\n', '* num_dis_hidden (`int`, default=`200`): Number of units per layer in discriminator.\n', '* optimizer (`str`, default=`AdamOptimizer`): Name of the optimizer to use during `fit`, possible\n', '  values are: [`GradientDescentOptimizer`, `AdamOptimizer`, `AdadeltaOptimizer`].\n', '\n', 'If you wanted to create an identical instance to the one created on step 2, but passing the\n', 'arguments in a explicit way, this can be achieved with the following lines:\n', '\n', '```\n', '>>> from tgan.model import TGANModel\n', '>>> tgan = TGANModel(\n', '   ...:     continuous_columns,\n', ""   ...:     output='output',\n"", '   ...:     max_epoch=5,\n', '   ...:     steps_per_epoch=10000,\n', '   ...:     save_checkpoints=True,\n', '   ...:     restore_session=True,\n', '   ...:     batch_size=200,\n', '   ...:     z_dim=200,\n', '   ...:     noise=0.2,\n', '   ...:     l2norm=0.00001,\n', '   ...:     learning_rate=0.001,\n', '   ...:     num_gen_rnn=100,\n', '   ...:     num_gen_feature=100,\n', '   ...:     num_dis_layers=1,\n', '   ...:     num_dis_hidden=100,\n', ""   ...:     optimizer='AdamOptimizer'\n"", '   ...: )\n', '```\n', '\n', '# Command-line interface\n', '\n', 'We include a command-line interface that allows users to access TGAN functionality. Currently only\n', 'one action is supported.\n', '\n', '## Random hyperparameter search\n', '\n', '### Input\n', '\n', 'To run random searchs for the best model hyperparameters for a given dataset, we will need:\n', '\n', '* A dataset, in a csv file, without any missing value, only columns of type `bool`, `str`, `int` or\n', '  `float` and only one type for column, as specified in the [Input Format](#input-format).\n', '\n', '* A JSON file containing the configuration for the search. This configuration shall contain:\n', '\n', '  * `name`: Name of the experiment. A folder with this name will be created.\n', '  * `num_random_search`: Number of iterations in hyper parameter search.\n', '  * `train_csv`: Path to the csv file containing the dataset.\n', '  * `continuous_cols`: List of column indices, starting at 0, to be considered continuous.\n', '  * `epoch`: Number of epoches to train the model.\n', '  * `steps_per_epoch`: Number of optimization steps in each epoch.\n', '  * `sample_rows`: Number of rows to sample when evaluating the model.\n', '\n', 'You can see an example of such a json file in [examples/config.json](examples/config.json), which you\n', 'can download and use as a template.\n', '\n', '### Execution\n', '\n', 'Once we have prepared everything we can launch the random hyperparameter search with this command:\n', '\n', '``` bash\n', 'tgan experiments config.json results.json\n', '```\n', '\n', 'Where the first argument, `config.json`, is the path to your configuration JSON, and the second,\n', '`results.json`, is the path to store the summary of the execution.\n', '\n', 'This will run the random search, wich basically consist of the folling steps:\n', '\n', '1. We fetch and split our data between test and train.\n', '2. We randomly select the hyperparameters to test.\n', '3. Then, for each hyperparameter combination, we train a TGAN model using the real training data T\n', '   and generate a synthetic training dataset Tsynth.\n', '4. We then train machine learning models on both the real and synthetic datasets.\n', '5. We use these trained models on real test data and see how well they perform.\n', '\n', '### Output\n', '\n', 'After the experiment has finished, the following can be found:\n', '\n', '* A JSON file, in the example above called `results.json`, containing a summary of the experiments.\n', '  This JSON will contain a key for each experiment `name`, and on it, an array of length\n', '  `num_random_search`, with the selected parameters and its evaluation score. For a configuration\n', '  like the example, the summary will look like this:\n', '\n', '``` python\n', '{\n', ""    'census': [\n"", '        {\n', '            ""steps_per_epoch"" : 10000,\n', '            ""num_gen_feature"" : 300,\n', '            ""num_dis_hidden"" : 300,\n', '            ""batch_size"" : 100,\n', '            ""num_gen_rnn"" : 400,\n', '            ""score"" : 0.937802280415988,\n', '            ""max_epoch"" : 5,\n', '            ""num_dis_layers"" : 4,\n', '            ""learning_rate"" : 0.0002,\n', '            ""z_dim"" : 100,\n', '            ""noise"" : 0.2\n', '        },\n', '        ... # 9 more nodes\n', '    ]\n', '}\n', '```\n', '\n', '* A set of folders, each one names after the `name` specified in the JSON configuration, contained\n', 'in the `experiments` folder. In each folder, sampled data and the models can be found. For a configuration\n', 'like the example, this will look like this:\n', '\n', '```\n', 'experiments/\n', '  census/\n', '    data/       # Sampled data with each of the models in the random search.\n', '    model_0/\n', '      logs/     # Training logs\n', '      model/    # Tensorflow model checkpoints\n', '    model_1/    # 9 more folders, one for each model in the random search\n', '    ...\n', '```\n', '\n', '# Research\n', '\n', 'The first **TGAN** version was built as the supporting software for the [Synthesizing Tabular Data using Generative Adversarial Networks](https://arxiv.org/pdf/1811.11264.pdf) paper by Lei Xu and Kalyan Veeramachaneni.\n', '\n', 'The exact version of software mentioned in the paper can be found in the releases section as the [research pre-release](https://github.com/sdv-dev/TGAN/releases/tag/research)\n', '\n', '# Citing TGAN\n', '\n', 'If you use TGAN for yor research, please consider citing the following paper (https://arxiv.org/pdf/1811.11264.pdf):\n', '\n', 'If you use TGAN, please cite the following work:\n', '\n', '> Lei Xu, Kalyan Veeramachaneni. 2018. Synthesizing Tabular Data using Generative Adversarial Networks.\n', '\n', '```LaTeX\n', '@article{xu2018synthesizing,\n', '  title={Synthesizing Tabular Data using Generative Adversarial Networks},\n', '  author={Xu, Lei and Veeramachaneni, Kalyan},\n', '  journal={arXiv preprint arXiv:1811.11264},\n', '  year={2018}\n', '}\n', '```\n']"
Synthetic+Data,Unity-Technologies/datasetinsights,Unity-Technologies,https://api.github.com/repos/Unity-Technologies/datasetinsights,82,16,16,"['https://api.github.com/users/adason', 'https://api.github.com/users/Saurav-D', 'https://api.github.com/users/BlairLee', 'https://api.github.com/users/86sanj', 'https://api.github.com/users/AdamPalmarUnity', 'https://api.github.com/users/sanjayuconn', 'https://api.github.com/users/rutvij-unity', 'https://api.github.com/users/JonathanHUnity', 'https://api.github.com/users/masonrubenstein', 'https://api.github.com/users/StevenBorkman', 'https://api.github.com/users/kalyanijagdale', 'https://api.github.com/users/davidwang-unity', 'https://api.github.com/users/mkamalza', 'https://api.github.com/users/alextha-scale', 'https://api.github.com/users/salehe-ee', 'https://api.github.com/users/leopoldo-zugasti']",Python,2023-03-09T15:21:37Z,https://raw.githubusercontent.com/Unity-Technologies/datasetinsights/master/README.md,"['# Dataset Insights\n', '\n', '[![PyPI python](https://img.shields.io/pypi/pyversions/datasetinsights)](https://pypi.org/project/datasetinsights)\n', '[![PyPI version](https://badge.fury.io/py/datasetinsights.svg)](https://pypi.org/project/datasetinsights)\n', '[![Downloads](https://pepy.tech/badge/datasetinsights)](https://pepy.tech/project/datasetinsights)\n', '[![Tests](https://github.com/Unity-Technologies/datasetinsights/actions/workflows/linting-and-unittests.yaml/badge.svg?branch=master&event=push)](https://github.com/Unity-Technologies/datasetinsights/actions/workflows/linting-and-unittests.yaml?query=branch%3Amaster+event%3Apush)\n', '[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](LICENSE)\n', '\n', 'Unity Dataset Insights is a python package for downloading, parsing and analyzing synthetic datasets generated using the Unity [Perception package](https://github.com/Unity-Technologies/com.unity.perception).\n', '\n', '## Installation\n', '\n', 'Datasetinsights is published to PyPI. You can simply run `pip install datasetinsights` command under a supported python environments:\n', '\n', '## Getting Started\n', '\n', '### Dataset Statistics\n', '\n', 'We provide a sample [notebook](notebooks/Perception_Statistics.ipynb) to help you load synthetic datasets generated using [Perception package](https://github.com/Unity-Technologies/com.unity.perception) and visualize dataset statistics. We plan to support other sample Unity projects in the future.\n', '\n', '### Load Datasets\n', '\n', 'The [Unity Perception](https://datasetinsights.readthedocs.io/en/latest/datasetinsights.datasets.unity_perception.html#datasetinsights-datasets-unity-perception) package provides datasets under this [schema](https://datasetinsights.readthedocs.io/en/latest/Synthetic_Dataset_Schema.html#synthetic-dataset-schema). The datasetinsighs package also provide convenient python modules to parse datasets.\n', '\n', 'For example, you can load `AnnotationDefinitions` into a python dictionary by providing the corresponding annotation definition ID:\n', '\n', '```python\n', 'from datasetinsights.datasets.unity_perception import AnnotationDefinitions\n', '\n', 'annotation_def = AnnotationDefinitions(data_root=dest, version=""my_schema_version"")\n', 'definition_dict = annotation_def.get_definition(def_id=""my_definition_id"")\n', '```\n', '\n', 'Similarly, for `MetricDefinitions`:\n', '```python\n', 'from datasetinsights.datasets.unity_perception import MetricDefinitions\n', '\n', 'metric_def = MetricDefinitions(data_root=dest, version=""my_schema_version"")\n', 'definition_dict = metric_def.get_definition(def_id=""my_definition_id"")\n', '```\n', '\n', 'The `Captures` table provide the collection of simulation captures and annotations. You can load these records directly as a Pandas `DataFrame`:\n', '\n', '```python\n', 'from datasetinsights.datasets.unity_perception import Captures\n', '\n', 'captures = Captures(data_root=dest, version=""my_schema_version"")\n', 'captures_df = captures.filter(def_id=""my_definition_id"")\n', '```\n', '\n', '\n', 'The `Metrics` table can store simulation metrics for a capture or annotation. You can also load these records as a Pandas `DataFrame`:\n', '\n', '```python\n', 'from datasetinsights.datasets.unity_perception import Metrics\n', '\n', 'metrics = Metrics(data_root=dest, version=""my_schema_version"")\n', 'metrics_df = metrics.filter_metrics(def_id=""my_definition_id"")\n', '```\n', '\n', '### Download Datasets\n', '\n', 'You can download the datasets using the [download](https://datasetinsights.readthedocs.io/en/latest/datasetinsights.commands.html#datasetinsights-commands-download) command:\n', '\n', '```bash\n', 'datasetinsights download --source-uri=<xxx> --output=$HOME/data\n', '```\n', '\n', 'The download command supports HTTP(s), and GCS.\n', '\n', 'Alternatively, you can download dataset directly from python [interface](https://datasetinsights.readthedocs.io/en/latest/datasetinsights.io.downloader.html#module-datasetinsights.io.downloader).\n', '\n', '`GCSDatasetDownloader` can download a dataset from GCS locations.\n', '```python\n', 'from datasetinsights.io.downloader import GCSDatasetDownloader\n', '\n', 'source_uri=gs://url/to/file.zip # or gs://url/to/folder\n', 'dest = ""~/data""\n', 'downloader = GCSDatasetDownloader()\n', 'downloader.download(source_uri=source_uri, output=dest)\n', '```\n', '\n', '`HTTPDatasetDownloader` can a dataset from any HTTP(S) url.\n', '```python\n', 'from datasetinsights.io.downloader import HTTPDatasetDownloader\n', '\n', 'source_uri=http://url.to.file.zip\n', 'dest = ""~/data""\n', 'downloader = HTTPDatasetDownloader()\n', 'downloader.download(source_uri=source_uri, output=dest)\n', '```\n', '\n', '### Convert Datasets\n', '\n', 'If you are interested in converting the synthetic dataset to COCO format for\n', 'annotations that COCO supports, you can run the `convert` command:\n', '\n', '```bash\n', 'datasetinsights convert -i <input-directory> -o <output-directory> -f COCO-Instances\n', '```\n', 'or\n', '```bash\n', 'datasetinsights convert -i <input-directory> -o <output-directory> -f COCO-Keypoints\n', '```\n', '\n', 'You will need to provide 2D bounding box definition ID in the synthetic dataset. We currently only support 2D bounding box and human keypoint annotations for COCO format.\n', '\n', '## Docker\n', '\n', 'You can use the pre-build docker image [unitytechnologies/datasetinsights](https://hub.docker.com/r/unitytechnologies/datasetinsights) to interact with datasets.\n', '\n', '## Documentation\n', '\n', 'You can find the API documentation on [readthedocs](https://datasetinsights.readthedocs.io/en/latest/).\n', '\n', '## Contributing\n', '\n', 'Please let us know if you encounter a bug by filing an issue. To learn more about making a contribution to Dataset Insights, please see our Contribution [page](CONTRIBUTING.md).\n', '\n', '## License\n', '\n', 'Dataset Insights is licensed under the Apache License, Version 2.0. See [LICENSE](LICENCE) for the full license text.\n', '\n', '## Citation\n', 'If you find this package useful, consider citing it using:\n', '```\n', '@misc{datasetinsights2020,\n', '    title={Unity {D}ataset {I}nsights Package},\n', '    author={{Unity Technologies}},\n', '    howpublished={\\url{https://github.com/Unity-Technologies/datasetinsights}},\n', '    year={2020}\n', '}\n', '```\n']"
Synthetic+Data,yuliangguo/3D_Lane_Synthetic_Dataset,yuliangguo,https://api.github.com/repos/yuliangguo/3D_Lane_Synthetic_Dataset,117,21,1,['https://api.github.com/users/yuliangguo'],Python,2023-03-27T17:53:53Z,https://raw.githubusercontent.com/yuliangguo/3D_Lane_Synthetic_Dataset/master/README.md,"['# A Synthetic Dataset for 3D lane Detection\n', '\n', '## Introduction\n', '\n', 'This is a synthetic dataset constructed to stimulate the development and evaluation of 3D lane detection methods \n', '(download dataset from [[google drive](https://drive.google.com/open?id=1Kisxoj7mYl1YyA_4xBKTE8GGWiNZVain)] [[baidu netdisk](https://pan.baidu.com/s/1y_d73-SaNreesif5nVXIVg?pwd=a852)]). \n', 'This dataset is an extension to [Apollo Synthetic Dataset](http://apollo.auto/synthetic.html).\n', 'The detailed strategy of construction and the evaluation method refer to our ECCV 2020 paper:\n', '\n', '""Gen-LaneNet: a generalized and scalable approach for 3D lane detection"", Y. Guo, etal., ECCV, 2020 [[eccv](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123660664.pdf)][[arxiv](https://arxiv.org/abs/2003.10656)] [[code](https://github.com/yuliangguo/Pytorch_Generalized_3D_Lane_Detection)]\n', '\n', '<p align=""center"">\n', '  <img src=""figs/00_0000045.jpg"" width=""280"" />\n', '  <img src=""figs/08_0000003.jpg"" width=""280"" /> \n', '  <img src=""figs/16_0000077.jpg"" width=""280"" />\n', '</p>\n', '\n', '\n', '\n', '## Requirements\n', '\n', '* python                    3.7.3\n', '* numpy                     1.16.2\n', '* scipy                     1.2.1 \n', '* matplotlib                3.0.3 \n', '* opencv-python             4.1.0.25\n', '* py3-ortools               5.1.4041\n', '\n', '\n', '\n', '## Data preparation\n', '\n', '\n', 'You are welcome to proceed to the development and evaluation directly using the splits of the training and testing sets we provide.\n', 'Feel free to skip this section if you use our data split directly.\n', '\n', '    ```\n', '    data_splits\n', '    ├── standard\n', '    │   ├── 3D_LaneNet\n', '    |   |       └──test_pred_file.json\n', '    │   ├── Gen_LaneNet\n', '    |   |       └──test_pred_file.json\n', '    │   ├── train.json\n', '    │   └── test.json\n', '    │── rare_subset\n', '    │   ├── 3D_LaneNet\n', '    |   |       └──test_pred_file.json\n', '    │   ├── Gen_LaneNet\n', '    |   |       └──test_pred_file.json\n', '    │   ├── train.json\n', '    │   └── test.json\n', '    |── illus_chg\n', '    │   ├── 3D_LaneNet\n', '    |   |       └──test_pred_file.json\n', '    │   ├── Gen_LaneNet\n', '    |   |       └──test_pred_file.json\n', '    │   ├── train.json\n', '    │   └── test.json\n', '    ```\n', '\n', 'Meanwhile, we provide the helper functions needed to build your own split from the raw datasets downloaded. The following codes \n', 'need to be right in order.\n', '\n', '    parse_apollo_sim_raw_data.py\n', '\n', 'This code extracts lane-lanes and center-lanes in an interested top-view area. The code reasons about the foreground and background\n', 'occlusion based on the provided ground-truth depth maps and semantic segmentation map. Those lane segments in the distance occluded\n', ""by background are discarded, because in general they are not expected to recover from a lane detection method. By setting 'vis=True',\n"", 'this code will draw ground-true lane-lines and center-lines on each image and save them.\n', '\n', '    prepare_data_split.py\n', '\n', ""This code randomly splits the whole data into training and testing sets following a 'standard' five-fold split. Specifically, \n"", ""a subset generated from a difficult urban map are further extracted to be the test set for 'rare subset' data split.\n"", '\n', '    prepare_data_subset\n', ' \n', ""Given the standard split of data, this code excludes images corresponding to a certain 'illumination' condition (before dawn)\n"", 'from the training set. On contrary, in the testing set, only images corresponding to that illumination condition are kept.\n', '\n', '\n', '\n', '## Evaluation\n', '\n', '\n', '    eval_3D_lane.py\n', '    \n', ""You need to modify 'method_name', 'data_split' to specify the method and the data split to conduct evaluation.\n"", ""For example, the default setting compares 'data_splits/illus_chg/Gen_LaneNet/test_pred_file.json' against ground-truth\n"", ""'data_splits/illus_chg/test.json'.\n"", ""Optionally, set 'args.dataset_dir' to the folder containing the original dataset. The original images are only required for visualizing lane results, when setting 'vis = True'.\n"", '\n', 'In this dataset, each image sample is associated with a set of ground-truth 3D lane-lines and center-lines, as well as \n', 'the camera height and pitch angle. \n', 'Per image, the optimal bipartite match between a set of predicted lane curves and a set of ground-truth lane curves is sought via\n', 'solving a min-cost flow.\n', 'Precision and recall are computed via varying lane confidence thresholds. Overall, evaluation metrics include:\n', ' * Average Precision (AP)\n', ' * max F-score\n', ' * x-error in close range (0-40 m)\n', ' * x-error in far range (40-100 m)\n', ' * z-error in close range (0-40 m)\n', ' * z-error in far range (40-100 m)\n', '\n', ""Before running the evaluation, you need to make sure the predicted lanes are saved in the 'test_pred_file.json' file following\n"", ""the format included in our example. Specifically, each lane needs to be associated with a 'prob' score to calculate the\n"", ""precision and recall in full-range. Otherwise, you can only keep 'evaluator.bench_one_submit' in the main code to \n"", 'evaluate your algorithm at a single operation point.\n', '\n', '## Baselines Results\n', '\n', 'We show the evaluation results comparing two baseline methods: \n', '* ""3d-lanenet:  end-to-end 3d multiple lane detection"", N. Garnet, etal., ICCV 2019\n', '* ""Gen-LaneNet: a generalized and scalable approach for 3D lane detection"", Y. Guo, etal., Arxiv, 2020\n', '\n', 'Comparisons are conducted under three distinguished splits of the dataset. For simplicity, only lane-line results are reported here.\n', 'The results from the code is slightly different from that reported in the paper due to different random splits.\n', '\n', '- **Standard**\n', '\n', '| Method                 | AP     | F-Score | x error near (m) | x error far (m) | z error near (m) | z error far (m) |\n', '|------------------------|:---------:|:---------:|:---------:|:---------:|:---------:|:---------:|\n', '| 3D-LaneNet             |   89.3    | 86.4      | 0.068     | 0.477     | 0.015     | 0.202\n', '| Gen-LaneNet            |   90.1    | 88.1      | 0.061     | 0.496     | 0.012     | 0.214\n', '\n', '- **Rare Subset**\n', '\n', '| Method                 | AP     | F-Score | x error near (m) | x error far (m) | z error near (m) | z error far (m) |\n', '|------------------------|:---------:|:---------:|:---------:|:---------:|:---------:|:---------:|\n', '| 3D-LaneNet             |  74.6     | 72.0      | 0.166     | 0.855     | 0.039     | 0.521\n', '| Gen-LaneNet            |  79.0     | 78.0      | 0.139     | 0.903     | 0.030     | 0.539\n', '\n', '- **Illumination Change**\n', '\n', '| Method                 | AP     | F-Score | x error near (m) | x error far (m) | z error near (m) | z error far (m) |\n', '|------------------------|:---------:|:---------:|:---------:|:---------:|:---------:|:---------:|\n', '| 3D-LaneNet             |   74.9    | 72.5      | 0.115     | 0.601     | 0.032     | 0.230\n', '| Gen-LaneNet            |   87.2    | 85.3      | 0.074     | 0.538     | 0.015     | 0.232\n', '\n', '\n', '\n', '## Visualization\n', '\n', ""Visual comparisons to the ground truth can be generated per image when setting 'vis = True'.\n"", 'We show two examples for each method under the data split involving illumination change.\n', '\n', '* 3D-LaneNet\n', '\n', '<img src=""figs/3D_LaneNet/images_00_0000148.jpg"" width=""400""> <img src=""figs/3D_LaneNet/images_00_0000171.jpg"" width=""400"">\n', '\n', '* Gen-LaneNet\n', '\n', '<img src=""figs/Gen_LaneNet/images_00_0000148.jpg"" width=""400""> <img src=""figs/Gen_LaneNet/images_00_0000171.jpg"" width=""400"">\n', '\n', '\n', '## Citation\n', 'Please cite the paper in your publications if it helps your research: \n', '\n', '    @article{guo2020gen,\n', '      title={Gen-LaneNet: A Generalized and Scalable Approach for 3D Lane Detection},\n', '      author={Yuliang Guo, Guang Chen, Peitao Zhao, Weide Zhang, Jinghao Miao, Jingao Wang, and Tae Eun Choe},\n', '      booktitle={Computer Vision - {ECCV} 2020 - 16th European Conference},\n', '      year={2020}\n', '    }\n']"
Synthetic+Data,InsulatorData/InsulatorDataSet,InsulatorData,https://api.github.com/repos/InsulatorData/InsulatorDataSet,181,86,2,"['https://api.github.com/users/InsulatorData', 'https://api.github.com/users/RegisWang']",,2023-04-07T07:16:09Z,https://raw.githubusercontent.com/InsulatorData/InsulatorDataSet/master/README.md,"['# Insulator Data Set - Chinese Power Line Insulator Dataset (CPLID)\n', 'Provide normal insulator images captured by UAVs and synthetic defective insulator images.\n', '\n', '    \n', '    @article{tao2018detection,\n', '      title={Detection of Power Line Insulator Defects Using Aerial Images Analyzed With Convolutional Neural Networks},\n', '      author={Tao, Xian and Zhang, Dapeng and Wang, Zihao and Liu, Xilong and Zhang, Hongyan and Xu, De},\n', '      journal={IEEE Transactions on Systems, Man, and Cybernetics: Systems},\n', '      year={2018},\n', '      publisher={IEEE}\n', '    }\n', 'This dataset is divided into two part:\n', '\n', '- `Normal_Insulators` contains the normal insulators capture by UAVs. The number of the normal insulator images is **600**.\n', '\n', '\n', ""- `Defective_Insulators` contains the insulators with defect. The number of the defective insulator images is **248**. Since we don't have too much defective insulators, the data augmentation method is applied. These images are synthesized by following process:\n"", '    - Use the algorithm in [TVSeg](http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.154.6237) to segment the defective insulator from a small part original images, the segment results are the mask images;\n', '    - Use affine transform to augment the original images and their mask, the augmentation results is a lot of original-mask image pairs;\n', '    - Use these image pairs to train the [U-Net](https://link.springer.com/chapter/10.1007/978-3-319-24574-4_28);\n', '    - Use the trained U-Net to segment the rest part of images;\n', '    - Attach the insulators in different backgrounds.\n', '\n', 'Both these two directories contain two subdirectories, one called `images` contains the image files, the other called `labels` contains the VOC2007 format annotations.\n', '\n', '- The `labels` of `Normal_Insulators` contains **only** the annotations of insulators;\n', '- The `labels` of `Defective_Insulators` contains not only the annotations of insulators but also the annotations of defects which on the insulators.\n', '\n', 'The images is provided by the State Grid Corporation of China, and the dataset is made by WANG Zi-Hao.\n', 'If you have any question about this dataset, feel free to contact [zhwang0721@gmail.com](mailto:zhwang0721@gmail.com).\n']"
Synthetic+Data,namebrandon/Sparkov_Data_Generation,namebrandon,https://api.github.com/repos/namebrandon/Sparkov_Data_Generation,91,44,3,"['https://api.github.com/users/streamnsight', 'https://api.github.com/users/namebrandon', 'https://api.github.com/users/kartik2112']",Python,2023-04-05T06:07:46Z,https://raw.githubusercontent.com/namebrandon/Sparkov_Data_Generation/master/README.md,"['# Generate Fake Credit Card Transaction Data, Including Fraudulent Transactions\n', '\n', 'Note: Version v1.0 behavior has changed in such a way that it runs much faster, however transaction files are chunked, so that several files get generated per profile. If your downstream process expects 1 file per profile, please checkout the v0.5 release branch `release/v0.5`.\n', '\n', '## General Usage\n', '\n', 'In this version, the general usage has changed:\n', '\n', 'Please run the datagen script as follow:\n', '\n', '```bash\n', 'python datagen.py -n <NUMBER_OF_CUSTOMERS_TO_GENERATE> -o <OUTPUT_FOLDER> <START_DATE> <END_DATE>\n', '```\n', '\n', 'To see the full list of options, use:\n', '\n', '```bash\n', 'python datagen.py -h\n', '```\n', '\n', 'You can pass additional options with the following flags:\n', '\n', '- `-config <CONFIG_FILE>`: pass the name of the config file, defaults to `./profiles/main_config.json`\n', '- `-seed <INT>`: pass a seed to the Faker class\n', '- `-c <CUSTOMER_FILE>`: pass the path to an already generated customer file\n', '- `-o <OUTPUT_FOLDER>`: folder to save files into\n', '\n', 'This version is modified from the version v0.5 to parallelize the work using `multiprocessing`, so as to take advantage of all available CPUs and bring a huge speed improvement.\n', '\n', 'Because of the way it parallelize the work (chunking transaction generation by chunking the customer list), there will be multiple transaction files generated per profile. Also not that if the number of customers is small, there may be empty files (i.e. files where no customer in the chunk matched the profile). This is expected.\n', '\n', 'With standard profiles, it was benchmarked as generating ~95MB/thread/min. With a 64 cores/128 threads AMD E3, I was able to generate 1.4TB of data, 4.5B transactions, in just under 2h, as opposed to days when running the previous versions.\n', '\n', 'The generation code is originally based on code by [Josh Plotkin](https://github.com/joshplotkin/data_generation). Change log of modifications to original code are below.\n', '\n', '## Change Log\n', '\n', '### v1.0\n', '\n', '- Parallelized version, bringing orders of magnitude faster generation depending on the hardware used.\n', '\n', '### v0.5\n', '\n', '- 12x speed up thanks to some code refactoring.\n', '\n', '### v0.4\n', '\n', '- Only surface-level changes done in scripts so that simulation can be done using Python3\n', '- Corrected bat files to generate transactions files.\n', '\n', '### v0.3\n', '\n', '- Completely re-worked profiles / segmentation of customers\n', '- introduced fraudulent transactions\n', '- introduced fraudulent profiles\n', '- modification of transaction amount generation via Gamma distribution\n', '- added 150k_ shell scripts for multi-threaded data generation (one python process for each segment launched in the background)\n', '\n', '### v0.2\n', '\n', '- Added unix time stamp for transactions for easier programamtic evaluation.\n', '- Individual profiles modified so that there is more variation in the data.\n', '- Modified random generation of age/gender. Original code did not appear to work correctly?\n', '- Added batch files for windows users\n', '\n', '### v0.1\n', '\n', '- Transaction times are now included instead of just dates\n', '- Profile specific spending windows (AM/PM with weighting of transaction times)\n', '- Merchant names (specific to spending categories) are now included (along with code for generation)\n', '- Travel probability is added, with profile specific options\n', '- Travel max distances is added, per profile option\n', '- Merchant location is randomized based on home location and profile travel probabilities\n', '- Simulated transaction numbers via faker MD5 hash (replacing sequential 0..n numbering)\n', '- Includes credit card number via faker\n', '- improved cross-platform file path compatibility\n']"
Synthetic+Data,finos/datahub,finos,https://api.github.com/repos/finos/datahub,78,12,6,"['https://api.github.com/users/mcleo-d', 'https://api.github.com/users/grovesy', 'https://api.github.com/users/zheyu-wang-tony', 'https://api.github.com/users/maoo', 'https://api.github.com/users/finos-admin', 'https://api.github.com/users/pGrovesy']",Python,2023-03-27T17:32:06Z,https://raw.githubusercontent.com/finos/datahub/master/README.md,"['<H1>DataHub</H1> \n', '\n', '![DataHub logo](https://raw.githubusercontent.com/finos/datahub/master/docs/logo.png) \n', '\n', '_Synthetic data generation_\n', '\n', 'DataHub is a set of python libraries dedicated to the production of synthetic data to be used in tests, machine learning training, statistical analysis, and other use cases [wiki](https://en.wikipedia.org/wiki/Synthetic_data). DataHub uses existing datasets to generate synthetic models. If no existing data is available it will use user-provided scripts and data rules to generate synthetic data using out-of-the-box helper datasets.\n', '\n', 'Synthetic datasets are simply artificiality manufactured sets, produced to a desired degree of accuracy. Real Data does play a part in synthetic generation, all depending on the realism\xa0you require. The product roadmaps details out the functionality planned in this respect.\n', '\n', ""DataHub's core is predominantly based around pandas data frames and object generation.\n"", 'A common question: Now that I have a data frame of synthetic-data, what do I do with it? The Pandas library comes with an array of options\xa0here - so for the time being sinking to databases is out of the scope of the core library, however see that examples in the test folder for some common patterns.\n', '\n', '**note** As we build out a config based synthetic spec generator, we will bring this back into scope - please see our roadmap/issue list and get involved in the discussion.\n', '\n', '## Key documents\n', '\n', '1. For information on how to get started with DataHub see our [Getting Started Guide](https://github.com/finos/datahub/blob/master/docs/GettingStarted.md)\n', '2. For more technical information about DataHub and how to customize it, see the [Developer Guide](https://github.com/finos/datahub/blob/master/docs/DeveloperGuide.md)\n', '3. For high-level project direction see [Road Map](https://github.com/finos/datahub/blob/master/docs/synthetic-data-roadmap/roadmap.md), [Requirements Gathering Approach](https://github.com/finos/datahub/blob/master/docs/synthetic-data-roadmap/synthetic-data-requirements-gathering.md) and [Delegated Action Groups](https://github.com/finos/datahub/tree/master/docs/delegated-action-groups).\n', '4. For Feature Development, Good First Issues, Help Wanted and Bug Tracking see [DataHub GitHub Issues](https://github.com/finos/datahub/issues). \n', '5. This project uses [Gravizo](https://g.gravizo.com) for all diagrams and charts as highlighted in [DataHub Issue 41](https://github.com/finos/datahub/issues/41).   \n', '\n', '## Overview of Synthetic data\n', '\n', ""- Synthetic data is information that's is artificially manufactured rather than\xa0generated by *real-world events.\n"", '- Synthetic data is created algorithmically, and can be used as a stand-in for\xa0 test datasets of production data\n', '- **Real data** does play a part in synthetic data generation - depending on how\n', 'realistic you want the output\n', '\n', '## License\n', '\n', 'Copyright 2020 Citigroup\n', '\n', 'Distributed under the [Apache License, Version 2.0](http://www.apache.org/licenses/LICENSE-2.0).\n', '\n', 'SPDX-License-Identifier: [Apache-2.0](https://spdx.org/licenses/Apache-2.0)\n']"
Synthetic+Data,lmoroney/synthetic_datasets,lmoroney,https://api.github.com/repos/lmoroney/synthetic_datasets,35,16,1,['https://api.github.com/users/lmoroney'],Python,2022-06-16T17:57:18Z,https://raw.githubusercontent.com/lmoroney/synthetic_datasets/master/README.md,"['# synthetic_datasets\n', ""Repository for Synthetic datasets I'm creating\n"", '\n', 'This will contain subfolders that have the details on the specific dataset within.\n']"
Synthetic+Data,LBNL-ETA/AlphaBuilding-SyntheticDataset,LBNL-ETA,https://api.github.com/repos/LBNL-ETA/AlphaBuilding-SyntheticDataset,34,11,1,['https://api.github.com/users/tsbyq'],Python,2022-09-24T01:19:13Z,https://raw.githubusercontent.com/LBNL-ETA/AlphaBuilding-SyntheticDataset/master/README.md,"['# AlphaBuilding-SyntheticDataset\n', '\n', 'This repository is created for the AlphaBuilding-SyntheticDataset. Details about this dataset could be found on its [GitHub page](https://lbnl-eta.github.io/AlphaBuilding-SyntheticDataset/).\n', '\n', '## Generate synthetic building operation data\n', 'The source code to reproduce the dataset could be found in the code directory. Follow the steps below to generate synthetic building operation data:\n', '1. Install [OpenStudio v2.9.1](https://github.com/NREL/OpenStudio/releases/tag/v2.9.1). \n', 'Set up the full path of openstudio.rb in the [create_workflow.rb](https://github.com/LBNL-ETA/AlphaBuilding-SyntheticDataset/blob/master/code/create_workflow.rb#L23) script. \n', 'The openstudio.rb file could be found in the installed OpenStudio folder: <paht_to_openstudio_installation>/openstudio-2.9.1/Ruby/openstudio.rb.\n', '\n', '2. Clone the [OpenStudio-Standards](https://github.com/NREL/openstudio-standards) repository to your local machine. Set up the full path of openstudio-standards.rb in the [create_workflow.rb](https://github.com/LBNL-ETA/AlphaBuilding-SyntheticDataset/blob/master/code/create_workflow.rb#L24) scipt. The openstudio-standards.rb file could be found in the cloned OpenStudio-Standards repository.\n', '\n', '3. Make sure [Ruby v2.2.4](https://www.ruby-lang.org/en/downloads/) is installed.\n', '\n', '4. Set up the arguments in the [create_workflow.rb](https://github.com/LBNL-ETA/AlphaBuilding-SyntheticDataset/blob/master/code/create_workflow.rb#L340-L362).\n', 'This allows you to create models and run simulations for different building types, vintages, climate zones\n', '    * Step 1. Select the [climate zone(s)](https://github.com/LBNL-ETA/AlphaBuilding-SyntheticDataset/blob/master/code/create_workflow.rb#L376-L393) for simulation. \n', '    The available climate zones are in the following array. \n', '    Uncomment the line(s) to specify the climate zone(s) you want to include:\n', '        \n', '        ```ruby\n', '        climate_zones = [\n', ""            'ASHRAE 169-2006-1A',     # Considered in the synthetic operatin dataset\n"", ""            # 'ASHRAE 169-2006-2A',\n"", ""            # 'ASHRAE 169-2006-2B',\n"", ""            # 'ASHRAE 169-2006-3A',\n"", ""            # 'ASHRAE 169-2006-3B',\n"", ""            'ASHRAE 169-2006-3C',     # Considered in the synthetic operatin dataset\n"", ""            # 'ASHRAE 169-2006-4A',\n"", ""            # 'ASHRAE 169-2006-4B',\n"", ""            # 'ASHRAE 169-2006-4C',\n"", ""            'ASHRAE 169-2006-5A',     # Considered in the synthetic operatin dataset\n"", ""            # 'ASHRAE 169-2006-5B',\n"", ""            # 'ASHRAE 169-2006-6A',\n"", ""            # 'ASHRAE 169-2006-6B',\n"", ""            # 'ASHRAE 169-2006-7A',\n"", ""            # 'ASHRAE 169-2006-8A',\n"", '        ]\n', '        ```\n', '    * Step 2. [Prepare the weather files (EPWs) and map the their folder to the climate zones.](https://github.com/LBNL-ETA/AlphaBuilding-SyntheticDataset/blob/master/code/create_workflow.rb#L397-L402)\n', ""    For example, this repository provides 30 years' historical and a TMY3 weather files for three U.S. cities - \n"", '    Chicago, Miami, and San Francicso. The weather files are saved in ```./EPWs/<city name>_AMY```. And the Hash below\n', '    maps the climate zones of the three cities and the weather file to be used in the simulations. \n', '        ```ruby\n', '        hash_climate_epw = {\n', ""            # 'climate zone option' => 'EPWs folder name', (example convention)\n"", ""            'ASHRAE 169-2006-1A' => 'Miami_AMY',\n"", ""            'ASHRAE 169-2006-3C' => 'SF_AMY',\n"", ""            'ASHRAE 169-2006-5A' => 'Chicago_AMY',\n"", '        }\n', '        ```\n', '        You need to provide weather files and mapping rule for buildings in other climate zones.\n', '    \n', '    * Step 3. [Select the vintages you want to consider.](https://github.com/LBNL-ETA/AlphaBuilding-SyntheticDataset/blob/master/code/create_workflow.rb#L406-L411)\n', '        ```ruby\n', '        vintages = [\n', ""            # '90.1-2004',\n"", ""            # '90.1-2007',\n"", ""            # '90.1-2010',\n"", ""            '90.1-2013'     # Considered in the synthetic operatin dataset\n"", '        ]\n', '        ```\n', '    \n', '    * [Step 4. Select the building type to consider.](https://github.com/LBNL-ETA/AlphaBuilding-SyntheticDataset/blob/master/code/create_workflow.rb#L416-L442)\n', '      Please note that occupancy_simulator only works for office buildings.\n', '      ```ruby\n', '        building_types = [\n', '            ###############################################################\n', '            ## building types that support stochastic occupancy simulation\n', '            ###############################################################\n', ""            # 'SmallOffice',\n"", ""            # 'MediumOffice',\n"", ""            # 'LargeOffice',\n"", ""            # 'SmallOfficeDetailed',\n"", ""            'MediumOfficeDetailed',     # Considered in the synthetic operatin dataset\n"", ""            # 'LargeOfficeDetailed',\n"", '            ###############################################################\n', '            ## building types that do not support stochastic occupancy simulation\n', '            ###############################################################\n', ""            # 'SecondarySchool',\n"", ""            # 'PrimarySchool',\n"", ""            # 'SmallHotel',\n"", ""            # 'LargeHotel',\n"", ""            # 'Warehouse',\n"", ""            # 'RetailStandalone',\n"", ""            # 'RetailStripmall',\n"", ""            # 'QuickServiceRestaurant',\n"", ""            # 'FullServiceRestaurant',\n"", ""            # 'MidriseApartment',\n"", ""            # 'HighriseApartment',\n"", ""            # 'Hospital',\n"", ""            # 'Outpatient',\n"", '        ]\n', '        ```\n', '\n', '    * Step 5. [Set the number of stochastic occupancy simulations for each building model.](https://github.com/LBNL-ETA/AlphaBuilding-SyntheticDataset/blob/master/code/create_workflow.rb#L445)\n', '        ```ruby\n', '        number_of_stochastic_occupancy_simulation = 5\n', '        ```\n', '    \n', '    * Step 6. [Set the energy efficiency level (1 - low, 2 - standard, 3 - high) to run.](https://github.com/LBNL-ETA/AlphaBuilding-SyntheticDataset/blob/master/code/create_workflow.rb#L448)\n', '        ```ruby\n', '        efficiency_level = 2\n', '        ```\n', '\n', '5. Run the create_workflow.rb script with ```<ruby 2.2.4 command> create_workflow.rb``` The script will generate and run OpenStudio workflows to output the synthetic building operation data.\n', '\n', '6. Post-processing. The above routine automatically generates OpenStudio models and runs the simulations.\n', 'This [Python script](https://github.com/LBNL-ETA/AlphaBuilding-SyntheticDataset/blob/master/code/results_extraction_demo.py) shows an example of extracting the raw CSV outputs and saving them in a structured way.\n', 'Depending on their purpose, readers may need develop custom routines to process the simulation results. \n', '\n', '\n', '## License\n', 'Refer to [License.txt](https://github.com/LBNL-ETA/AlphaBuilding-SyntheticDataset/blob/master/License.txt)\n']"
Synthetic+Data,milaan9/Clustering-Datasets,milaan9,https://api.github.com/repos/milaan9/Clustering-Datasets,218,202,1,['https://api.github.com/users/milaan9'],,2023-04-05T12:57:03Z,https://raw.githubusercontent.com/milaan9/Clustering-Datasets/master/README.md,"['<p align=""center""> \n', '<a href=""https://github.com/milaan9""><img src=""https://img.shields.io/static/v1?logo=github&label=maintainer&message=milaan9&color=ff3300"" alt=""Last Commit""/></a> \n', '<!--<img src=""https://badges.pufler.dev/created/milaan9/Clustering-Datasets"" alt=""Created""/>-->\n', '<!--<a href=""https://github.com/milaan9/Clustering-Datasets/graphs/commit-activity""><img src=""https://img.shields.io/github/last-commit/milaan9/Clustering-Datasets.svg?colorB=ff8000&style=flat"" alt=""Last Commit""/></a>-->\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/pulse"" alt=""Activity""><img src=""https://img.shields.io/github/commit-activity/m/milaan9/Clustering-Datasets.svg?colorB=teal&style=flat"" /></a> \n', '<a href=""https://hits.seeyoufarm.com""><img src=""https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fgithub.com%2Fmilaan9%2FClustering-Datasets&count_bg=%231DC92C&title_bg=%23555555&icon=&icon_color=%23E7E7E7&title=views&edge_flat=false""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/stargazers""><img src=""https://img.shields.io/github/stars/milaan9/Clustering-Datasets.svg?colorB=1a53ff"" alt=""Stars Badge""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/network/members""><img src=""https://img.shields.io/github/forks/milaan9/Clustering-Datasets"" alt=""Forks Badge""/> </a>\n', '<img src=""https://img.shields.io/github/repo-size/milaan9/Clustering-Datasets.svg?colorB=CC66FF&style=flat"" alt=""Size""/>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/pulls""><img src=""https://img.shields.io/github/issues-pr/milaan9/Clustering-Datasets.svg?colorB=yellow&style=flat"" alt=""Pull Requests Badge""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/issues""><img src=""https://img.shields.io/github/issues/milaan9/Clustering-Datasets.svg?colorB=yellow&style=flat"" alt=""Issues Badge""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/blob/master/LICENSE""><img src=""https://img.shields.io/badge/License-MIT-blueviolet.svg"" alt=""MIT License""/></a> \n', '<a href=""https://github.com/milaan9/Clustering-Datasets""><img src=""https://img.shields.io/static/v1?label=%F0%9F%8C%9F&message=If%20Useful&style=style=flat&color=BC4E99"" alt=""Star Badge""/>\n', '</p> \n', '<!--<img src=""https://badges.pufler.dev/contributors/milaan9/01_Python_Introduction?size=50&padding=5&bots=true"" alt=""milaan9""/>-->\n', '\n', '\n', '\n', '# Clustering-Datasets\n', '\n', 'This repository contains the collection of UCI (real-life)datasets and Synthetic (artificial) datasets(with cluster labels).\n', '\n', '  * [UCI (real-world) datasets](https://github.com/milaan9/Clustering-Datasets/tree/master/01.%20UCI)\n', '  * [Synthetic (artificial) datasets](https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic)\n', '\n', '### Artificial data\n', '\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/2d-10c.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/2d-10c.png"" alt=""2d-10c"" title=""2d-10c"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/2d-20c.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/2d-20c.png"" alt=""2d-20c-no0"" title=""2d-20c"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/2d-3c.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/2d-3c.png"" alt=""2d-3c-no123"" title=""2d-3c"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/2d-4c-2.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/2d-4c-2.png"" alt=""2d-4c-no4"" title=""2d-4c-2"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/2d-4c-3.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/2d-4c-3.png"" alt=""2d-4c-no9"" title=""2d-4c-3"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/2d-4c-1.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/2d-4c-1.png"" alt=""2d-4c"" title=""2d-4c-1"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/2sp2glob.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/2sp2glob.png"" alt=""2sp2glob"" title=""2sp2glob"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/3-spiral.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/3-spiral.png"" alt=""3-spiral"" title=""3-spiral"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/3MC.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/3mc.png"" alt=""3MC"" title=""3MC"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/D31.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/d31.png"" alt=""D31"" title=""D31"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/DS577.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/ds577.png"" alt=""DS577"" title=""DS577"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/DS850.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/ds850.png"" alt=""DS850"" title=""DS850"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/R15.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/r15.png"" alt=""R15"" title=""R15"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/aggregation.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/aggregation.png"" alt=""aggregation"" title=""aggregation"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/atom.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/atom.png"" alt=""atom"" title=""atom"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/banana.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/banana.png"" alt=""banana"" title=""banana"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/birch-rg1.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/birch-rg1.png"" alt=""birch-rg1"" title=""birch-rg1"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/birch-rg2.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/birch-rg2.png"" alt=""birch-rg2"" title=""birch-rg2"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/birch-rg3.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/birch-rg3.png"" alt=""birch-rg3"" title=""birch-rg3"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/chainlink.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/chainlink.png"" alt=""chainlink"" title=""chainlink"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/cluto-t4.8k.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/cluto-t4.8k.png"" alt=""cluto-t4.8k"" title=""cluto-t4.8k"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/cluto-t5.8k.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/cluto-t5.8k.png"" alt=""cluto-t5.8k"" title=""cluto-t5.8k"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/cluto-t7.10k.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/cluto-t7.10k.png"" alt=""cluto-t7.10k"" title=""cluto-t7.10k"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/cluto-t8.8k.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/cluto-t8.8k.png"" alt=""cluto-t8.8k"" title=""cluto-t8.8k"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/complex8.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/complex8.png"" alt=""complex8"" title=""complex8"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/complex9.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/complex9.png"" alt=""complex9"" title=""complex9"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/compound.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/compound.png"" alt=""compound"" title=""compound"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/cure-t0-2000n-2D.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/cure-t0-2000n-2d.png"" alt=""cure-t0-2000n-2D"" title=""cure-t0-2000n-2D"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/cure-t1-2000n-2D.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/cure-t1-2000n-2d.png"" alt=""cure-t1-2000n-2D"" title=""cure-t1-2000n-2D"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/cure-t2-4k.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/cure-t2-4k.png"" alt=""cure-t2-4k"" title=""cure-t2-4k"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/curves1.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/curves1.png"" alt=""curves1"" title=""curves1"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/curves2.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/curves2.png"" alt=""curves2"" title=""curves2"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/dartboard1.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/dartboard1.png"" alt=""dartboard1"" title=""dartboard1"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/dartboard2.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/dartboard2.png"" alt=""dartboard2"" title=""dartboard2"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/dense-disk-3000.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/dense-disk-3000.png"" alt=""dense-disk-3000"" title=""dense-disk-3000"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/dense-disk-5000.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/dense-disk-5000.png"" alt=""dense-disk-5000"" title=""dense-disk-5000"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/diamond9.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/diamond9.png"" alt=""diamond9"" title=""diamond9"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/disk-1000n.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/disk-1000n.png"" alt=""disk-1000n"" title=""disk-1000n"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/disk-3000n.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/disk-3000n.png"" alt=""disk-3000n"" title=""disk-3000n"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/disk-4000n.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/disk-4000n.png"" alt=""disk-4000n"" title=""disk-4000n"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/disk-4500n.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/disk-4500n.png"" alt=""disk-4500n"" title=""disk-4500n"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/disk-4600n.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/disk-4600n.png"" alt=""disk-4600n"" title=""disk-4600n"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/disk-5000n.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/disk-5000n.png"" alt=""disk-5000n"" title=""disk-5000n"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/disk-6000n.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/disk-6000n.png"" alt=""disk-6000n"" title=""disk-6000n"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/donut1.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/donut1.png"" alt=""donut1"" title=""donut1"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/donut2.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/donut2.png"" alt=""donut2"" title=""donut2"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/donut3.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/donut3.png"" alt=""donut3"" title=""donut3"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/donutcurves.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/donutcurves.png"" alt=""donutcurves"" title=""donutcurves"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/ds2c2sc13.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/ds2c2sc13.png"" alt=""ds2c2sc13"" title=""ds2c2sc13"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/ds3c3sc6.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/ds3c3sc6.png"" alt=""ds3c3sc6"" title=""ds3c3sc6"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/ds4c2sc8.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/ds4c2sc8.png"" alt=""ds4c2sc8"" title=""ds4c2sc8"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/elliptical_10_2.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/elliptical_10_2.png"" alt=""elliptical_10_2"" title=""elliptical_10_2"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/elly-2d10c13s.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/elly-2d10c13s.png"" alt=""elly-2d10c13s"" title=""elly-2d10c13s"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/engytime.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/engytime.png"" alt=""engytime"" title=""engytime"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/flame.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/flame.png"" alt=""flame"" title=""flame"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/fourty.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/fourty.png"" alt=""fourty"" title=""fourty"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/golfball.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/golfball.png"" alt=""golfball"" title=""golfball"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/hepta.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/hepta.png"" alt=""hepta"" title=""hepta"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/insect.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/insect.png"" alt=""insect"" title=""insect"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/jain.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/jain.png"" alt=""jain"" title=""jain"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/long1.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/long1.png"" alt=""long1"" title=""long1"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/long2.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/long2.png"" alt=""long2"" title=""long2"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/long3.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/long3.png"" alt=""long3"" title=""long3"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/longsquare.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/longsquare.png"" alt=""longsquare"" title=""longsquare"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/lsun.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/lsun.png"" alt=""lsun"" title=""lsun"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/mopsi-finland.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/mopsi-finland.png"" alt=""mopsi-finland"" title=""mopsi-finland"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/mopsi-joensuu.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/mopsi-joensuu.png"" alt=""mopsi-joensuu"" title=""mopsi-joensuu"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/pathbased.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/pathbased.png"" alt=""pathbased"" title=""pathbased"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/rings.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/rings.png"" alt=""rings"" title=""rings"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/s-set1.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/s-set1.png"" alt=""s-set1"" title=""s-set1"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/s-set2.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/s-set2.png"" alt=""s-set2"" title=""s-set2"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/s-set3.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/s-set3.png"" alt=""s-set3"" title=""s-set3"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/s-set4.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/s-set4.png"" alt=""s-set4"" title=""s-set4"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/sizes1.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/sizes1.png"" alt=""sizes1"" title=""sizes1"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/sizes2.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/sizes2.png"" alt=""sizes2"" title=""sizes2"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/sizes3.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/sizes3.png"" alt=""sizes3"" title=""sizes3"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/sizes4.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/sizes4.png"" alt=""sizes4"" title=""sizes4"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/sizes5.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/sizes5.png"" alt=""sizes5"" title=""sizes5"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/smile1.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/smile1.png"" alt=""smile1"" title=""smile1"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/smile2.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/smile2.png"" alt=""smile2"" title=""smile2"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/smile3.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/smile3.png"" alt=""smile3"" title=""smile3"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/spherical_4_3.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/spherical_4_3.png"" alt=""spherical_4_3"" title=""spherical_4_3"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/spherical_5_2.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/spherical_5_2.png"" alt=""spherical_5_2"" title=""spherical_5_2"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/spherical_6_2.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/spherical_6_2.png"" alt=""spherical_6_2"" title=""spherical_6_2"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/spiral.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/spiral.png"" alt=""spiral"" title=""spiral"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/spiralsquare.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/spiralsquare.png"" alt=""spiralsquare"" title=""spiralsquare"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/square1.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/square1.png"" alt=""square1"" title=""square1"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/square2.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/square2.png"" alt=""square2"" title=""square2"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/square3.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/square3.png"" alt=""square3"" title=""square3"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/square4.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/square4.png"" alt=""square4"" title=""square4"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/square5.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/square5.png"" alt=""square5"" title=""square5"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/st900.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/st900.png"" alt=""st900"" title=""st900"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/target.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/target.png"" alt=""target"" title=""target"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/tetra.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/tetra.png"" alt=""tetra"" title=""tetra"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/triangle1.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/triangle1.png"" alt=""triangle1"" title=""triangle1"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/triangle2.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/triangle2.png"" alt=""triangle2"" title=""triangle2"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/twenty.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/twenty.png"" alt=""twenty"" title=""twenty"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/twodiamonds.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/twodiamonds.png"" alt=""twodiamonds"" title=""twodiamonds"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/wingnut.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/wingnut.png"" alt=""wingnut"" title=""wingnut"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/xclara.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/xclara.png"" alt=""xclara"" title=""xclara"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synthetic/zelnik1.arff""><img src=""https://github.com/milaan9/Clustering-Datasets/blob/master/02.%20Synthetic/fig/zelnik1.png"" alt=""zelnik1"" title=""zelnik1"" width=""239px"" style=""max-width: 100%;float:left;""/></a>\n', '<a href=""https://github.com/milaan9/Clustering-Datasets/tree/master/02.%20Synt"
Synthetic+Data,mrtzh/PrivateMultiplicativeWeights.jl,mrtzh,https://api.github.com/repos/mrtzh/PrivateMultiplicativeWeights.jl,44,16,5,"['https://api.github.com/users/mrtzh', 'https://api.github.com/users/giladroyz', 'https://api.github.com/users/KristofferC', 'https://api.github.com/users/Quantisan', 'https://api.github.com/users/tkelman']",Julia,2023-01-26T12:19:09Z,https://raw.githubusercontent.com/mrtzh/PrivateMultiplicativeWeights.jl/master/README.md,"['# PrivateMultiplicativeWeights.jl\n', '\n', 'This package implements `MWEM`, a simple and practical algorithm for differentially private data release.\n', '\n', 'MIT Licensed. See `LICENSE.md`.\n', '\n', '## Installation\n', '\n', 'Install required packages, then open a Julia prompt and call: \n', '```\n', 'using Pkg\n', 'Pkg.add(""PrivateMultiplicativeWeights"")\n', '```\n', '\n', '## Main Features\n', '\n', '* Differentially private synthetic data preserving lower order marginals of an input data set\n', '* Optimized in-memory implementation for small number of data attributes\n', '* Scalable heuristic for large number of data attributes\n', '* Easy-to-use interfaces for custom query sets and data representations\n', '\n', '## Examples\n', '\n', '### Histogram approximations\n', '\n', '![Histogram approximation](https://github.com/mrtzh/PrivateMultiplicativeWeights.jl/blob/master/examples/histograms.png?raw=true)\n', '\n', 'Check out [`histograms.ipynb`](/examples/histograms.ipynb) for details on how to\n', 'use the algorithm to compute differentially private histogram approximations. \n', '\n', '### Marginal approximations\n', '\n', 'The package can also be used to create synthetic data that approximates the\n', 'lower order marginals of a data set with binary features.  For the sake of\n', 'illustration, we create a random data set with hidden correlations. Columns\n', 'correspond to data points.  \n', '\n', '```\n', 'd, n = 20, 1000\n', 'data_matrix = rand(0:1, d ,n)\n', 'data_matrix[3, :] = data_matrix[1, :] .* data_matrix[2, :]\n', '```\n', '\n', 'We can run MWEM to produce synthetic data accurate for 1st, 2nd, 3rd order marginals of the source data.\n', '```\n', 'using PrivateMultiplicativeWeights\n', 'mw = mwem(Parities(d, 3), Tabular(data_matrix))\n', '```\n', 'This will convert the data to its explicit histogram representation of size 2^d\n', 'and may not be useful when d is large. See section on factored histograms\n', 'for an alternative when the dimension d is large.\n', '\n', '### Convert histograms to matrices\n', '\n', 'We can convert synthetic data in histogram representation to a tabular \n', '(matrix) representation.\n', '```\n', 'table = Tabular(mw.synthetic, n)\n', '```\n', '\n', '### Compute error of approximation\n', 'Compute error achieved by MWEM:\n', '```\n', 'maximum_error(mw), mean_squared_error(mw)\n', '```\n', 'Note that these statistics are *not* differentially private.\n', '\n', '## Parameters\n', '\n', 'Parameters can be set flexibly with the `MWParameters` constructor:\n', '```\n', 'mw = mwem(Parities(d, 3),\n', '          Tabular(data_matrix),\n', '          MWParameters(epsilon=1.0,\n', '                       iterations=10,\n', '                       repetitions=10,\n', '                       verbose=false,\n', '                       noisy_init=false,\n', '                       init_budget=0.05,\n', '                       noisy_max_budget=0.5))\n', '```\n', 'Available parameters:\n', '\n', '| Name | Default | Description |\n', '| ---- | ------- | ----------- |\n', '| `epsilon` | `1.0` | Privacy parameter for the algorithm. Each iteration of MWEM is `epsilon`-differentially private. Total privacy guarantees follow via composition theorems.|\n', '| `iterations` | `10` | Number of iterations of MWEM. Each iteration corresponds to selecting one query via the exponential mechanism, evaluating the query on the data, and updating the internal state. |\n', '| `repetitions`| `10` | Number of times MWEM cycles through previously measured queries per iteration. This has no additional privacy cost. |\n', '| `noisy_init` | `false` | This requires part of the `epsilon` privacy cost.  When `noisy_init` is set to false, the initialization is uniform.  |\n', '| `init_budget` | `0.05` | In case the `noisy_init` flag is set to true, this flag decide what fraction of the `epsilon` privacy cost will be given for the noisy initialization. When `noisy_init` is set to false, all the budget will be used by the iterations. |\n', '| `noisy_max_budget` | `0.5` | Decise what fraction from the `epsion` privacy badget of every iteration will go to the ""noisy max"" step. (the rest is for the Exponential Mechanism)  |\n', '| `verbose` | `false` | print timing and error statistics per iteration (information is not differentially private)\n', '\n', 'The function `MWParameters` accepts any subset of parameters, e.g.,\n', '`MWParameter(epsilon=0.5, iterations=5)`.\n', '\n', '## Data representations\n', '\n', '### Histogram representation\n', '\n', 'By default, MWEM works with the histogram representation of a data sets. This\n', 'means that the data is represented by a vector whose length is equal to the size\n', 'of domain. For example, data consisting of `d` binary attributes would be\n', 'converted to an array of length `2^d`. MWEM needs to store and array of this\n', 'length in main memory, which is often the computational bottleneck.\n', '\n', '## Factored histograms\n', '\n', 'When the histogram representation is too large, try using factored histograms.\n', 'Factored histograms maintain a product distribution over clusters of attributes\n', 'of the data. Each component is represented using a single histogram. Components\n', 'are merged as it becomes necessary. This often allows to scale up MWEM by orders\n', 'of magnitude.  \n', '```\n', 'd, n = 100, 1000\n', 'data_matrix = rand(0:1, d, n)\n', 'data_matrix[3, :] = data_matrix[1, :] .* data_matrix[2, :]\n', 'mw = mwem(FactorParities(d, 3), Tabular(data_matrix))\n', '```\n', '\n', 'Also see `examples.jl`.\n', '\n', '## Query representations\n', '\n', 'There are two ways to define custom query sets.\n', '\n', '### Histogram queries\n', '\n', 'Histogram queries are linear functions in the histogram representation of the\n', 'data.  You can define custom query workloads by using\n', '`HistogramQueries(query_matrix)` instead of `Parities(d, 3)`. Here `query\n', 'matrix` is an `N x k` matrix specifying the query set in its Histogram\n', 'representation, `N` is the histogram length and `k` is the `k` is the number of\n', 'queries.\n', '\n', '### Custom query types\n', '\n', 'To build query sets with your own implicit representations, sub-type\n', '`Query` and `Queries`. Implement the functions specified in `src/interface.jl`.\n', '\n', 'See `src/parities.jl` for an example.\n', '\n', '### Available query sets\n', '\n', '- **Parities**(d, k)\n', '\n', '  Parities of `k` out of `d` attributes. This corresponds to approximating\n', '  `k`-way marginals of the original data.\n', '\n', '- **FactorParities**(d, k)\n', '\n', '  Parities of `k` out of `d` attributes for factored histogram representation.\n', '\n', '- **SeriesRangeQueries**(N)\n', '\n', '  Range queries corresponding to all interval queries over a histogram of length `N`.\n', '  \n', '  - *SeriesRangeQueries**(Intervals)\n', '\n', '  Range queries over histogram with length N, corresponding to intervals = {Interval1, Interval2, ...}\n', '  where Interval = (i, j) so that 1 <= i <= j <= N.\n', '\n', '## Contributing to this package\n', '\n', 'There are many ways to contribute to this repository:\n', '\n', '* Experiments\n', '* Additional query sets (e.g., two-dimensional range queries)\n', '* Additional tests, debugging, optimization\n', '* Additional documentation\n', '\n', '## Citing this package\n', '\n', 'The MWEM algorithm was presented in the following paper:\n', '```\n', '@inproceedings{HLM12,\n', '  author = ""Moritz Hardt and Katrina Ligett and Frank McSherry"",\n', '  title = ""A simple and practical algorithm for differentially-private data release"",\n', '  booktitle = {Proc.\\ $26$th Neural Information Processing Systems (NIPS)},\n', '  year = {2012},\n', '}\n', '```\n', '\n', '## Status\n', '\n', '[![Build\n', 'Status](https://travis-ci.org/mrtzh/PrivateMultiplicativeWeights.jl.svg?branch=master)](https://travis-ci.org/mrtzh/PrivateMultiplicativeWeights.jl)\n']"